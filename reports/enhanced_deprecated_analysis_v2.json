[
  {
    "extension": "airport",
    "repository": "https://github.com/query-farm/airport",
    "owner": "query-farm",
    "repo_name": "airpor",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": null,
    "description": "",
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:43:59.473480",
    "metadata": {
      "docs": {
        "extended_description": "For more information regarding usage, see the [documentation](https://query.farm/duckdb_extension_airport.html).\n"
      },
      "extension": {
        "build": "cmake",
        "description": "The Airport extension brings Arrow Flight support to DuckDB, enabling DuckDB to query, modify, and store data from Arrow Flight servers.",
        "excluded_platforms": "wasm_mvp;wasm_eh;wasm_threads",
        "language": "C++",
        "license": "MIT",
        "maintainers": [
          "rustyconover"
        ],
        "name": "airport",
        "requires_toolchains": "parser_tools",
        "test_config": "{\"test_env_variables\":\n  {\n    \"AIRPORT_TEST_SERVER\": \"grpc+tls://airport-ci.query.farm\"\n  }\n}\n",
        "version": 2025091801
      },
      "repo": {
        "github": "query-farm/airport",
        "ref": "0d7b873a0fdf276e9a42e5716fdd872497c4d048"
      }
    },
    "official_description": "The Airport extension brings Arrow Flight support to DuckDB, enabling DuckDB to query, modify, and store data from Arrow Flight servers.",
    "official_version": 2025091801,
    "language": "C++",
    "maintainers": [
      "rustyconover"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/airport/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "arrow",
    "repository": "https://github.com/duckdb/duckdb-extension-alias",
    "owner": "duckdb",
    "repo_name": "duckdb-extension-alias",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "## Example"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "As an example, assume you want to locally build an aliased exte"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "To execute the tests, you can run:"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "`RUN_TEST=1 make test_release`"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-05-09T08:56:07Z",
    "description": null,
    "readme_content": "# DuckDB Extension Alias\nThis DuckDB extension creates an alias for an existing community extension.\nIt does so by setting `EXTENSION_NAME` to the alias and `EXTENSION_CANONICAL` to the name of the original community extension.\n\nIt uses only the DuckDB C API, and when the aliased extension is loaded, it installs and loads the canonical community extension under the hood.\n\n\n## Example\nAs an example, assume you want to locally build an aliased extension on top of the `nanoarrow` community extension. To build it locally, you can run:\n`EXTENSION_CANONICAL=nanoarrow make`\n\nTo execute the tests, you can run:\n`RUN_TEST=1 make test_release`",
    "analysis_timestamp": "2025-09-27T14:43:59.575273",
    "metadata": {
      "extension": {
        "name": "arrow",
        "description": "This extension is an alias to the nanoarrow extension. Allows the consumption and production of the Apache Arrow interprocess communication (IPC) format, both from files and directly from stream buffers.",
        "version": "1.2.1",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "requires_toolchains": "python3",
        "maintainers": [
          "pdet"
        ]
      },
      "repo": {
        "github": "duckdb/duckdb-extension-alias",
        "ref": "dce7fb0831e2b83d41746381c1a99979eecbe401",
        "canonical_name": "nanoarrow"
      },
      "docs": {
        "hello_world": "-- Read from a file in Arrow IPC format\nFROM 'arrow_file.arrow';\nFROM 'arrow_file.arrows';\nFROM read_arrow('arrow_file.arrow');\n\n-- Write a file in Arrow IPC stream format\nCREATE TABLE arrow_libraries AS SELECT 'nanoarrow' as name, '0.6' as version;\nCOPY arrow_libraries TO 'test.arrows' (FORMAT ARROWS, BATCH_SIZE 100);\n\n-- Write to buffers: This returns IPC message BLOBs and indicates which one is the header.\nFROM to_arrow_ipc((FROM arrow_libraries));\n",
        "extended_description": "The Arrow IPC library allows users to read and write data in the Arrow IPC stream format. \nThis can be done by either reading and producing `.arrow` files or by directly reading buffers using their pointers and sizes. \nIt is important to note that reading buffers is dangerous, as an incorrect pointer can crash the database system. \nThis process is temporary and will be deprecated in the future, as clients (e.g., the Python DuckDB client) will have a function that internally extracts these buffers from an Arrow stream.\n"
      }
    },
    "official_description": "This extension is an alias to the nanoarrow extension. Allows the consumption and production of the Apache Arrow interprocess communication (IPC) format, both from files and directly from stream buffers.",
    "official_version": "1.2.1",
    "language": "C++",
    "maintainers": [
      "pdet"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/arrow/description.yml",
    "deprecation_score": 4.0,
    "recommendation": "REVIEW - Some deprecation indicators found"
  },
  {
    "extension": "bigquery",
    "repository": "https://github.com/hafenkran/duckdb-bigquery",
    "owner": "hafenkran",
    "repo_name": "duckdb-bigquery",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "experimental",
        "source": "readme",
        "context": "| `bq_experimental_filter_pushdown`         | [EXPERIMENTAL] - Whether or not to use filter pushdown"
      },
      {
        "keyword": "experimental",
        "source": "readme",
        "context": "| `bq_experimental_use_info_schema`         | [EXPERIMENTAL] - Use information schema to fetch catalog info ("
      },
      {
        "keyword": "experimental",
        "source": "readme",
        "context": "| `bq_experimental_enable_bigquery_options` | [EXPERIMENTAL] - Whether to enable BigQuery OPTIONS in CREATE s"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "TIALS` environment variable to the file path. For example:"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "e of your actual Google Cloud Project. Here is an example:"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "overview of supported functionalities and include examples for interacting with BigQuery:"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "ps://cloud.google.com/sdk/gcloud). Download the latest version from the [Google Cloud CLI installation p"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "ear_cache` to update the cache and retrieve the latest schema information:"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "## Install Latest Updates from Custom Repository"
      }
    ],
    "active_indicators": [
      {
        "keyword": "maintained",
        "source": "readme",
        "context": "\ufe0f Disclaimer**: This is an independent, community-maintained open-source project and is not affiliated with, e"
      },
      {
        "keyword": "stable",
        "source": "readme",
        "context": "h the [spatial extension](https://duckdb.org/docs/stable/core_extensions/spatial/overview.html) installed"
      }
    ],
    "repository_archived": false,
    "last_push": "2025-09-21T12:30:17Z",
    "description": "Integrates DuckDB with Google BigQuery, allowing direct querying and management of BigQuery datasets",
    "readme_content": "# DuckDB BigQuery Extension\n\nThis community extension allows [DuckDB](https://duckdb.org) to query data from Google BigQuery using a mix of BigQuery Storage (Read/Write) and REST API. It enables users to access, manage, and manipulate their BigQuery datasets/tables directly from DuckDB using standard SQL queries. Inspired by official DuckDB RDBMS extensions like [MySQL](https://duckdb.org/docs/extensions/mysql.html), [PostgreSQL](https://github.com/duckdb/postgres_scanner), and [SQLite](https://github.com/duckdb/sqlite_scanner), this extension offers a similar feel. See [Important Notes](#important-notes-on-using-google-bigquery) for disclaimers and usage information.\n\n> This extension supports the following builds: `linux_amd64`, `linux_arm64`, `linux_amd64_musl`, `osx_amd64`, `osx_arm64`, and `windows_amd64`. The builds `wasm_mvp`, `wasm_eh`, `wasm_threads`, and `windows_amd64_mingw` are not supported.\n\n## Preliminaries\n\n### Authentication Option 1: Configure ADC with your Google Acc",
    "analysis_timestamp": "2025-09-27T14:43:59.677639",
    "metadata": {
      "extension": {
        "name": "bigquery",
        "description": "Integrates DuckDB with Google BigQuery, allowing direct querying and management of BigQuery datasets",
        "version": "0.5.0",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "excluded_platforms": "wasm_mvp;wasm_eh;wasm_threads;windows_amd64_mingw",
        "vcpkg_commit": "ef7dbf94b9198bc58f45951adcf1f041fcbc5ea0",
        "requires_toolchains": "parser_tools",
        "maintainers": [
          "hafenkran"
        ]
      },
      "repo": {
        "github": "hafenkran/duckdb-bigquery",
        "ref": "621dbb517c11d82c0d7693c362591d156ab3da0c"
      },
      "docs": {
        "hello_world": "-- Attach to your BigQuery Project\nD ATTACH 'project=my_gcp_project' AS bq (TYPE bigquery, READ_ONLY);\n\n-- Show all tables in all datasets in the attached BigQuery project\nD SHOW ALL TABLES;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 database \u2502      schema      \u2502   name   \u2502 column_names \u2502   column_types    \u2502 temporary \u2502\n\u2502 varchar  \u2502     varchar      \u2502  varchar \u2502  varchar[]   \u2502     varchar[]     \u2502  boolean  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 bq       \u2502 quacking_dataset \u2502 duck_tbl \u2502 [i, s]       \u2502 [BIGINT, VARCHAR] \u2502 false     \u2502\n| bq       | barking_dataset  | dog_tbl  | [i, s]       | [BIGINT, VARCHAR] \u2502 false     |\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- Select data from a specific table in BigQuery\nD SELECT * FROM bq.quacking_dataset.duck_tbl;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   i   \u2502       s        \u2502\n\u2502 int32 \u2502    varchar     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    12 \u2502 quack \ud83e\udd86       \u2502\n\u2502    13 \u2502 quack quack \ud83e\udd86 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
        "extended_description": "This community-maintained extension allows DuckDB to connect to Google BigQuery using the BigQuery Storage (read/write) and REST APIs. \nIt enables users to read, write, and manage their BigQuery datasets/tables directly from DuckDB using standard SQL queries.\nFor detailed setup and usage instructions, visit the [extension repository](https://github.com/hafenkran/duckdb-bigquery).\n"
      }
    },
    "official_description": "Integrates DuckDB with Google BigQuery, allowing direct querying and management of BigQuery datasets",
    "official_version": "0.5.0",
    "language": "C++",
    "maintainers": [
      "hafenkran"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/bigquery/description.yml",
    "deprecation_score": 5.0,
    "recommendation": "POSSIBLY DEPRECATED - Manual review recommended"
  },
  {
    "extension": "bitfilters",
    "repository": "https://github.com/query-farm/bitfilters",
    "owner": "query-farm",
    "repo_name": "bitfilters",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "test",
        "source": "official_description",
        "context": "fuse filters\u2014for fast approximate set membership testing with no false negatives and configurable false"
      },
      {
        "keyword": "test",
        "source": "repo_description",
        "context": "abilistic data structures for fast set membership testing and approximate duplicate detection. This exte"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-26T22:15:18Z",
    "description": "A high-performance DuckDB extension providing probabilistic data structures for fast set membership testing and approximate duplicate detection. This extension implements state-of-the-art filter algorithms including Quotient filters, XOR filters, Binary Fuse filters, and soon Bloom filters.",
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:43:59.821296",
    "metadata": {
      "docs": {
        "extended_description": "For more information regarding usage, see the [documentation](https://query.farm/duckdb_extension_bitfilters.html).\n"
      },
      "extension": {
        "build": "cmake",
        "description": "Provides high-performance, space-efficient probabilistic data structures\u2014including quotient, XOR, and binary fuse filters\u2014for fast approximate set membership testing with no false negatives and configurable false positive rates.",
        "language": "C++",
        "license": "MIT",
        "maintainers": [
          "rustyconover"
        ],
        "name": "bitfilters",
        "version": 2025091601
      },
      "repo": {
        "github": "query-farm/bitfilters",
        "ref": "cfcf8cf24d7299aa07d0a24c234e5c1f31d04065"
      }
    },
    "official_description": "Provides high-performance, space-efficient probabilistic data structures\u2014including quotient, XOR, and binary fuse filters\u2014for fast approximate set membership testing with no false negatives and configurable false positive rates.",
    "official_version": 2025091601,
    "language": "C++",
    "maintainers": [
      "rustyconover"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/bitfilters/description.yml",
    "deprecation_score": 2.0,
    "recommendation": "MONITOR - Minor concerns detected"
  },
  {
    "extension": "blockduck",
    "repository": "https://github.com/luohaha/BlockDuck",
    "owner": "luohaha",
    "repo_name": "BlockDuck",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-03-26T15:14:51Z",
    "description": "Live SQL Queries on Blockchain",
    "readme_content": "![image](https://github.com/user-attachments/assets/e3cc6ee3-9ed4-4841-9617-3aecbd5be4e5)\n                                                                 \n\n## What is BlockDuck\n\nBlockDuck's core design philosophy is: \n\n**Live SQL Queries on Blockchain**\n\nBlockDuck is a tool for blockchain data analysis based on DuckDB's flexible extension mechanism. BlockDuck allows users to query blockchain directly in a way that is similar to querying a traditional SQL database.\n\n## Data Pipeline\n\nBefore introducing BlockDuck, the current blockchain data pipeline is roughly as follows:\n\n![image](https://github.com/user-attachments/assets/a672d217-3c06-4b5f-8a8f-26e08f02bd04)\n\nAfter introducing BlockDuck, we can simplify the blockchain data pipeline:\n\n![image](https://github.com/user-attachments/assets/7403f71e-453f-4ef6-8b83-b7bd005a0b41)\nETL can be handled within BlockDuck using SQL. And also, since DuckDB supports an in-process execution mode, we can also run BlockDuck inside the API service.\n\n## ",
    "analysis_timestamp": "2025-09-27T14:43:59.924220",
    "metadata": {
      "extension": {
        "name": "blockduck",
        "description": "Live SQL Queries on Blockchain",
        "version": "0.7.0",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "excluded_platforms": "windows_amd64_rtools;windows_amd64;windows_amd64_mingw;wasm_mvp;wasm_eh;wasm_threads",
        "maintainers": [
          "luohaha"
        ]
      },
      "repo": {
        "github": "luohaha/BlockDuck",
        "ref": "074b7b1fe81fcc0464358636754cefc23d798cb5"
      },
      "docs": "https://yixins-organization.gitbook.io/blockduck-docs"
    },
    "official_description": "Live SQL Queries on Blockchain",
    "official_version": "0.7.0",
    "language": "C++",
    "maintainers": [
      "luohaha"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/blockduck/description.yml",
    "deprecation_score": 1.0,
    "recommendation": "MONITOR - Minor concerns detected"
  },
  {
    "extension": "cache_httpfs",
    "repository": "https://github.com/dentiny/duck-read-cache-fs",
    "owner": "dentiny",
    "repo_name": "duck-read-cache-fs",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "## Example usage"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "For more example usage, checkout [example usage](/doc/example_usage.md)"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "-- Or upgrade to latest version with `FORCE INSTALL cache_httpfs from com"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-23T10:09:53Z",
    "description": "This repository is made as read-only filesystem for remote access.",
    "readme_content": "# duck-read-cache-fs\n\nA DuckDB extension for remote filesystem access cache.\n\n## Loading cache httpfs\nSince DuckDB v1.0.0, cache httpfs can be loaded as a community extension without requiring the `unsigned` flag. From any DuckDB instance, the following two commands will allow you to install and load the extension:\n```sql\nINSTALL cache_httpfs from community;\n-- Or upgrade to latest version with `FORCE INSTALL cache_httpfs from community;`\nLOAD cache_httpfs;\n```\nSee the [cache httpfs community extension page](https://community-extensions.duckdb.org/extensions/cache_httpfs.html) for more information.\n\n## Introduction\n\nThis repository is made as read-only filesystem for remote access, which serves as cache layer above duckdb [httpfs](https://github.com/duckdb/duckdb-httpfs).\n\nKey features:\n- Caching for data, which adds support for remote file access to improve IO performance and reduce egress cost; several caching options and entities are supported\n  + in-memory, cache fetched file conte",
    "analysis_timestamp": "2025-09-27T14:44:00.027313",
    "metadata": {
      "extension": {
        "name": "cache_httpfs",
        "description": "Read cached filesystem for httpfs",
        "version": "0.7.0",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "excluded_platforms": "wasm_mvp;wasm_eh;wasm_threads;windows_amd64_rtools;windows_amd64;windows_amd64_mingw",
        "maintainers": [
          "dentiny",
          "DouEnergy"
        ]
      },
      "repo": {
        "github": "dentiny/duck-read-cache-fs",
        "ref": "1a4ec174571c0576bc5dadd7c7d261ca16a44f2e"
      },
      "docs": {
        "hello_world": "SELECT cache_httpfs_get_cache_size();\n",
        "extended_description": "This extension adds a read cache filesystem to DuckDB, which acts as a wrapper of httpfs extention. \nIt supports a few key features:\n- Supports both file metadata, glob, file handle and data block cache\n- Supports both on-disk cache and in-memory cache for data blocks, with cache mode, block size, cache directories tunable\n- Supports disk cache file eviction based on access timestamp or LRU, allows tunable disk space reservation\n- Supports parallel IO request, with request size and parallelism tunable\n- Supports profiling for IO latency and cache hit / miss ratio for a few operations (i.e open, read, glob), which provides an insight on workload characterization\n- Exposes function to get cache size and cleanup cache\n- Provides an option to disable / enable cache, which could act as a drop-in replacement for httpfs\n"
      }
    },
    "official_description": "Read cached filesystem for httpfs",
    "official_version": "0.7.0",
    "language": "C++",
    "maintainers": [
      "dentiny",
      "DouEnergy"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/cache_httpfs/description.yml",
    "deprecation_score": 3.0,
    "recommendation": "REVIEW - Some deprecation indicators found"
  },
  {
    "extension": "capi_quack",
    "repository": "https://github.com/duckdb/extension-template-c",
    "owner": "duckdb",
    "repo_name": "extension-template-c",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "demo",
        "source": "official_description",
        "context": "Provides a hello world example demo from the C/C++ C API template"
      },
      {
        "keyword": "example",
        "source": "official_description",
        "context": "Provides a hello world example demo from the C/C++ C API template"
      },
      {
        "keyword": "experimental",
        "source": "repo_description",
        "context": "(Experimental) C/C++ template for DuckDB extensions based on th"
      },
      {
        "keyword": "experimental",
        "source": "readme",
        "context": "This is an **experimental** template for C/C++ based extensions that link w"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "a Python venv is set up with DuckDB and DuckDB's test runner installed. Additionally, depending on conf"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "## Testing"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "This extension uses the DuckDB Python client for testing. This should be automatically installed in the"
      },
      {
        "keyword": "unstable",
        "source": "readme",
        "context": "### Using unstable Extension C API functionality"
      },
      {
        "keyword": "unstable",
        "source": "readme",
        "context": "e DuckDB Extension C API has a stable part and an unstable part. By default, this template only allows usage"
      },
      {
        "keyword": "unstable",
        "source": "readme",
        "context": "part of the API. To switch it to allow using the unstable part, take the following steps:"
      }
    ],
    "active_indicators": [
      {
        "keyword": "stable",
        "source": "readme",
        "context": "### Using unstable Extension C API functionality"
      },
      {
        "keyword": "stable",
        "source": "readme",
        "context": "The DuckDB Extension C API has a stable part and an unstable part. By default, this templ"
      },
      {
        "keyword": "stable",
        "source": "readme",
        "context": "ate only allows usage of the stable"
      }
    ],
    "repository_archived": false,
    "last_push": "2025-07-17T16:11:51Z",
    "description": "(Experimental) C/C++ template for DuckDB extensions based on the C API",
    "readme_content": "# DuckDB C/C++ extension template\nThis is an **experimental** template for C/C++ based extensions that link with the **C Extension API** of DuckDB. Note that this\nis different from https://github.com/duckdb/extension-template, which links against the C++ API of DuckDB.\n\nFeatures:\n- No DuckDB build required\n- CI/CD chain preconfigured\n- (Coming soon) Works with community extensions\n\n## Cloning\nClone the repo with submodules\n\n```shell\ngit clone --recurse-submodules <repo>\n```\n\n## Dependencies\nIn principle, compiling this template only requires a C/C++ toolchain. However, this template relies on some additional\ntooling to make life a little easier and to be able to share CI/CD infrastructure with extension templates for other languages:\n\n- Python3\n- Python3-venv\n- [Make](https://www.gnu.org/software/make)\n- CMake\n- Git\n- (Optional) Ninja + ccache\n\nInstalling these dependencies will vary per platform:\n- For Linux, these come generally pre-installed or are available through the distro-speci",
    "analysis_timestamp": "2025-09-27T14:44:00.132562",
    "metadata": {
      "extension": {
        "name": "capi_quack",
        "description": "Provides a hello world example demo from the C/C++ C API template",
        "version": "0.0.1",
        "language": "C/C++",
        "build": "CMake",
        "license": "MIT",
        "requires_toolchains": "python3",
        "maintainers": [
          "samansmink"
        ]
      },
      "repo": {
        "github": "duckdb/extension-template-c",
        "ref": "7f71365c5ce61b2b346717af07c9d448cfc9d3c3"
      },
      "docs": {
        "extended_description": "The capi_quack extension is based on DuckDB's [C/C++ C API template](https://github.com/duckdb/extension-template-c/).\n"
      }
    },
    "official_description": "Provides a hello world example demo from the C/C++ C API template",
    "official_version": "0.0.1",
    "language": "C/C++",
    "maintainers": [
      "samansmink"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/capi_quack/description.yml",
    "deprecation_score": 4.0,
    "recommendation": "REVIEW - Some deprecation indicators found"
  },
  {
    "extension": "chaos",
    "repository": "https://github.com/taniabogatsch/duckdb-chaos",
    "owner": "taniabogatsch",
    "repo_name": "duckdb-chaos",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "work in progress",
        "source": "readme",
        "context": "### \ud83d\udea7 WORK IN PROGRESS \ud83d\udea7"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "this will depend on the client you're using. Some examples:"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "./build/release/test/unittest"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "- `unittest` is the test runner of duckdb. Again, the extension is already"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "## Running the tests"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-19T11:42:23Z",
    "description": null,
    "readme_content": "# DuckdbChaos\n\nThis repository is based on https://github.com/duckdb/extension-template, check it out if you want to build and ship your own DuckDB extension.\n\n---\n\n### \ud83d\udea7 WORK IN PROGRESS \ud83d\udea7\n\nDuckDBChaos allow you to invoke exceptions and signals.\n\n#### Exceptions\n\n```sql\nSELECT chaos_exception('hello', 'CATALOG');\nCatalog Error:\nhello\n```\n\n```sql\nSELECT chaos_exception('hello', 'INTERNAL');\nINTERNAL Error:\nhello\n\nStack Trace:\n\n0        duckdb::Exception::Exception(duckdb::ExceptionType, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>> const&) + 64\n1        duckdb::DuckDBChaosExceptionFun(duckdb::DataChunk&, duckdb::ExpressionState&, duckdb::Vector&)::'lambda'(duckdb::string_t, duckdb::string_t)::operator()(duckdb::string_t, duckdb::string_t) const + 376\n...\n```\n\n```sql\nSELECT chaos_exception('hello', 'FATAL');\nFATAL Error:\nFailed: database has been invalidated because of a previous fatal error. The database must be restarted prior to being used again",
    "analysis_timestamp": "2025-09-27T14:44:00.238031",
    "metadata": {
      "extension": {
        "name": "chaos",
        "description": "Creates chaos! \u22c6\u2734\ufe0e\u02da\uff61\u22c6 Chaos allows you to throw any type of DuckDB exception, or to raise a SIGSEGV, SIGABRT, or SIGBUS signal.",
        "version": "0.0.1",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "taniabogatsch"
        ]
      },
      "repo": {
        "github": "taniabogatsch/duckdb-chaos",
        "ref": "e112242b794466d2a4a577af0a92fce836708a71"
      },
      "docs": {
        "hello_world": "-- Throw exceptions!\nSELECT chaos_exception('hello', 'CATALOG');\nSELECT chaos_exception('hello', 'INTERNAL');\nSELECT chaos_exception('hello', 'FATAL');\n\n-- Raise signals!\nSELECT chaos_signal('SIGSEGV');\nSELECT chaos_signal('SIGABRT');\nSELECT chaos_signal('SIGBUS');\n",
        "extended_description": "Creates chaos! \u22c6\u2734\ufe0e\u02da\uff61\u22c6 Chaos allows you to throw any type of DuckDB exception, or to raise a SIGSEGV, SIGABRT, or SIGBUS signal.\nSignals do not work on Windows.\n"
      }
    },
    "official_description": "Creates chaos! \u22c6\u2734\ufe0e\u02da\uff61\u22c6 Chaos allows you to throw any type of DuckDB exception, or to raise a SIGSEGV, SIGABRT, or SIGBUS signal.",
    "official_version": "0.0.1",
    "language": "C++",
    "maintainers": [
      "taniabogatsch"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/chaos/description.yml",
    "deprecation_score": 5.0,
    "recommendation": "POSSIBLY DEPRECATED - Manual review recommended"
  },
  {
    "extension": "chsql",
    "repository": "https://github.com/quackscience/duckdb-extension-clickhouse-sql",
    "owner": "quackscience",
    "repo_name": "duckdb-extension-clickhouse-sql",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": null,
    "description": null,
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:00.343194",
    "metadata": {
      "extension": {
        "name": "chsql",
        "description": "ClickHouse SQL Macros for DuckDB",
        "version": "1.0.132",
        "language": "SQL & C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "lmangani",
          "akvlad"
        ],
        "excluded_platforms": "windows_amd64_rtools;windows_amd64_mingw;windows_amd64;"
      },
      "repo": {
        "github": "quackscience/duckdb-extension-clickhouse-sql",
        "ref": "f056022f4a9d20e280059d66458d907f4a080cdd"
      },
      "docs": {
        "hello_world": "-- Use 100+ boring ClickHouse SQL function macros in DuckDB SQL queries.\n\nD SELECT toString('world') AS hello, toInt8OrZero('world') AS zero;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  hello  \u2502 zero  \u2502\n\u2502 varchar \u2502 int64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 world   \u2502     0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nD SELECT IPv4NumToString(167772161), IPv4StringToNum('10.0.0.1');\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 ipv4numtostring(167772161) \u2502 ipv4stringtonum('10.0.0.1') \u2502\n\u2502          varchar           \u2502            int32            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 10.0.0.1                   \u2502                   167772161 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- Query a remote ClickHouse instance via HTTP/S API using multiple formats\n\nD SELECT * FROM ch_scan(\"SELECT number * 100 FROM numbers(3)\",\"https://play.clickhouse.com\", format := 'Parquet');\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 multiply(number, 100) \u2502\n\u2502        varchar        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 0                     \u2502\n\u2502 100                   \u2502\n\u2502 200                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- Query the emulated system tables to explore columns, rows, types, storage, etc\nD SELECT * FROM system.tables;\nD SELECT * FROM system.columns;\nD SELECT * FROM system.functions;\nD SELECT * FROM system.uptime;\nD SELECT * FROM system.disks;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   name   \u2502     path     \u2502 free_space \u2502 total_space \u2502 unreserved_space \u2502 keep_free_space \u2502  type   \u2502 object_storage_type \u2502 metadata_type \u2502 is_encrypted \u2502 is_read_only \u2502 is_write_once \u2502 is_remote \u2502 is_broken \u2502 cache_path \u2502\n\u2502 varchar  \u2502   varchar    \u2502   int64    \u2502    int64    \u2502      int64       \u2502      int64      \u2502 varchar \u2502       varchar       \u2502    varchar    \u2502   boolean    \u2502   boolean    \u2502    boolean    \u2502  boolean  \u2502  boolean  \u2502  varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 localdb  \u2502 test.db      \u2502          0 \u2502      262144 \u2502                0 \u2502               0 \u2502 Local   \u2502 None                \u2502 None          \u2502 false        \u2502 false        \u2502 false         \u2502 false     \u2502 false     \u2502            \u2502\n\u2502 memory   \u2502 NULL         \u2502          0 \u2502           0 \u2502                0 \u2502               0 \u2502 Local   \u2502 None                \u2502 None          \u2502 false        \u2502 false        \u2502 false         \u2502 false     \u2502 false     \u2502            \u2502\n\u2502 testduck \u2502 /tmp/duck.db \u2502     262144 \u2502      786432 \u2502           262144 \u2502               0 \u2502 Local   \u2502 None                \u2502 None          \u2502 false        \u2502 false        \u2502 false         \u2502 false     \u2502 false     \u2502            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
        "extended_description": "\n## DuckDB ClickHouse SQL extension    \nThe DuckDB chsql community extension implements 100+ popular [ClickHouse SQL Macros](https://duckdb.org/community_extensions/extensions/chsql#added-functions), functions and helpers making it easier for users to transition between OLAP systems \u2b50 \n\n### Motivation\nDuckDB is our favourite OLAP engine but ClickHouse has lots of integrations and users. This extension is dedicated to ClickHouse refugeess.\n\n```\n\u2714 DuckDB SQL is awesome and full of great functions.<br>\n\u2714 ClickHouse SQL is awesome and full of great functions.\n\n\u2714 The DuckDB library is ~51M and modular. Can LOAD extensions.<br>\n\u274c The ClickHouse monolith is ~551M and growing. No extensions.\n\n\u2714 DuckDB is open source and protected by a no-profit foundation.<br>\n\u274c ClickHouse is open core and controlled by for-profit corporation.\n\n\u2714 DuckDB embedded is fast, mature and elegantly integrated in many languages.<br>\n\u274c chdb is still experimental, unstable and currently only supports Python.\n``` \n\n### Extensions\n- [chsql_native](https://duckdb.org/community_extensions/extensions/chsql_native) provides a native clickhouse client (binary) and a reader for ClickHouse Native format files\n\n#### Legal Disclaimer\n> DuckDB \u00ae is a trademark of DuckDB Foundation. ClickHouse\u00ae is a trademark of ClickHouse Inc. All trademarks, service marks, and logos mentioned or depicted are the property of their respective owners. The use of any third-party trademarks, brand names, product names, and company names is purely informative or intended as parody and does not imply endorsement, affiliation, or association with the respective owners.\n"
      }
    },
    "official_description": "ClickHouse SQL Macros for DuckDB",
    "official_version": "1.0.132",
    "language": "SQL & C++",
    "maintainers": [
      "lmangani",
      "akvlad"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/chsql/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "chsql_native",
    "repository": "https://github.com/quackscience/duckdb-extension-clickhouse-native",
    "owner": "quackscience",
    "repo_name": "duckdb-extension-clickhouse-native",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": null,
    "description": null,
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:00.853563",
    "metadata": {
      "extension": {
        "name": "chsql_native",
        "description": "ClickHouse Native Client & File Reader for chsql",
        "version": "0.1.3",
        "language": "Rust",
        "build": "cmake",
        "license": "MIT",
        "excluded_platforms": "windows_amd64_rtools;windows_amd64_mingw;windows_amd64;wasm_threads;wasm_eh;wasm_mvp;linux_amd64_musl;",
        "requires_toolchains": "rust;python3",
        "maintainers": [
          "lmangani",
          "adubovikov"
        ]
      },
      "repo": {
        "github": "quackscience/duckdb-extension-clickhouse-native",
        "ref": "2674d67f6715b4fb7d49f9a7f12c382a5f013f33"
      },
      "docs": {
        "hello_world": "\n--- Simple Query Example\n--- export CLICKHOUSE_URL=\"tcp://user:pass@remote:9440/?secure=true&skip_verify=true\"\nD SELECT * FROM clickhouse_scan(\"SELECT version(), 'hello', 123\");\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 version()  \u2502 'hello' \u2502  123   \u2502\n\u2502  varchar   \u2502 varchar \u2502 uint32 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 24.10.2.80 \u2502 hello   \u2502    123 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n--- Wide Query Example\nD SELECT * FROM clickhouse_scan(\"SELECT * FROM system.functions WHERE alias_to != '' LIMIT 10\");\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502        name        \u2502 is_aggregate \u2502 case_insensitive \u2502       alias_to       \u2502 \u2026 \u2502 arguments \u2502 returned_value \u2502 examples \u2502 categories \u2502\n\u2502      varchar       \u2502    uint32    \u2502      uint32      \u2502       varchar        \u2502   \u2502  varchar  \u2502    varchar     \u2502 varchar  \u2502  varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 connection_id      \u2502            0 \u2502                1 \u2502 connectionID         \u2502 \u2026 \u2502           \u2502                \u2502          \u2502            \u2502\n\u2502 rand32             \u2502            0 \u2502                0 \u2502 rand                 \u2502 \u2026 \u2502           \u2502                \u2502          \u2502            \u2502\n\u2502 INET6_ATON         \u2502            0 \u2502                1 \u2502 IPv6StringToNum      \u2502 \u2026 \u2502           \u2502                \u2502          \u2502            \u2502\n\u2502 INET_ATON          \u2502            0 \u2502                1 \u2502 IPv4StringToNum      \u2502 \u2026 \u2502           \u2502                \u2502          \u2502            \u2502\n\u2502 truncate           \u2502            0 \u2502                1 \u2502 trunc                \u2502 \u2026 \u2502           \u2502                \u2502          \u2502            \u2502\n\u2502 ceiling            \u2502            0 \u2502                1 \u2502 ceil                 \u2502 \u2026 \u2502           \u2502                \u2502          \u2502            \u2502\n\u2502 replace            \u2502            0 \u2502                1 \u2502 replaceAll           \u2502 \u2026 \u2502           \u2502                \u2502          \u2502            \u2502\n\u2502 from_utc_timestamp \u2502            0 \u2502                1 \u2502 fromUTCTimestamp     \u2502 \u2026 \u2502           \u2502                \u2502          \u2502            \u2502\n\u2502 mapFromString      \u2502            0 \u2502                0 \u2502 extractKeyValuePairs \u2502 \u2026 \u2502           \u2502                \u2502          \u2502            \u2502\n\u2502 str_to_map         \u2502            0 \u2502                1 \u2502 extractKeyValuePairs \u2502 \u2026 \u2502           \u2502                \u2502          \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 10 rows                                                                                                         12 columns (8 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\n--- Native File Reader for chsql\n--- Test files can be generated with clickhouse-local. File reads are full-scans.\n\n--- Simple Example\nD SELECT * FROM clickhouse_native('/tmp/numbers.clickhouse');\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  version()   \u2502 number  \u2502\n\u2502   varchar    \u2502  int32  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 24.12.1.1273 \u2502 0       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n--- Long Example\nD SELECT count(*), max(number) FROM clickhouse_native('/tmp/100000.clickhouse');\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 count_star() \u2502 max(number) \u2502\n\u2502    int64     \u2502    int32    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502       100000 \u2502       99999 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n--- Wide Example\nD SELECT * FROM clickhouse_native('/tmp/functions.clickhouse') WHERE alias_to != '' LIMIT 10;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502        name        \u2502 is_aggregate \u2502 case_insensitive \u2502       alias_to       \u2502 create_query \u2502 origin  \u2502 \u2026 \u2502 syntax  \u2502 arguments \u2502 returned_value \u2502 examples \u2502 categories \u2502\n\u2502      varchar       \u2502    int32     \u2502      int32       \u2502       varchar        \u2502   varchar    \u2502 varchar \u2502   \u2502 varchar \u2502  varchar  \u2502    varchar     \u2502 varchar  \u2502  varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 connection_id      \u2502            0 \u2502                1 \u2502 connectionID         \u2502              \u2502 System  \u2502 \u2026 \u2502         \u2502           \u2502                \u2502          \u2502            \u2502\n\u2502 rand32             \u2502            0 \u2502                0 \u2502 rand                 \u2502              \u2502 System  \u2502 \u2026 \u2502         \u2502           \u2502                \u2502          \u2502            \u2502\n\u2502 INET6_ATON         \u2502            0 \u2502                1 \u2502 IPv6StringToNum      \u2502              \u2502 System  \u2502 \u2026 \u2502         \u2502           \u2502                \u2502          \u2502            \u2502\n\u2502 INET_ATON          \u2502            0 \u2502                1 \u2502 IPv4StringToNum      \u2502              \u2502 System  \u2502 \u2026 \u2502         \u2502           \u2502                \u2502          \u2502            \u2502\n\u2502 truncate           \u2502            0 \u2502                1 \u2502 trunc                \u2502              \u2502 System  \u2502 \u2026 \u2502         \u2502           \u2502                \u2502          \u2502            \u2502\n\u2502 ceiling            \u2502            0 \u2502                1 \u2502 ceil                 \u2502              \u2502 System  \u2502 \u2026 \u2502         \u2502           \u2502                \u2502          \u2502            \u2502\n\u2502 replace            \u2502            0 \u2502                1 \u2502 replaceAll           \u2502              \u2502 System  \u2502 \u2026 \u2502         \u2502           \u2502                \u2502          \u2502            \u2502\n\u2502 from_utc_timestamp \u2502            0 \u2502                1 \u2502 fromUTCTimestamp     \u2502              \u2502 System  \u2502 \u2026 \u2502         \u2502           \u2502                \u2502          \u2502            \u2502\n\u2502 mapFromString      \u2502            0 \u2502                0 \u2502 extractKeyValuePairs \u2502              \u2502 System  \u2502 \u2026 \u2502         \u2502           \u2502                \u2502          \u2502            \u2502\n\u2502 str_to_map         \u2502            0 \u2502                1 \u2502 extractKeyValuePairs \u2502              \u2502 System  \u2502 \u2026 \u2502         \u2502           \u2502                \u2502          \u2502            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 10 rows                                                                                                                                           12 columns (11 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
        "extended_description": "## chsql_native\nThis experimental community extension implements a Native Clickhouse client for DuckDB.\n\n### Client Configuration\nThe extension can be configured the following using ENV variables\n```\nCLICKHOUSE_URL\nCLICKHOUSE_USER\nCLICKHOUSE_PASSWORD\n```\n\nAuthentication and connection parameters can be included in the URL\n```\nexport CLICKHOUSE_URL=\"tcp://user:pass@remote:9440/?secure=true&skip_verify=true\"\n-- export CLICKHOUSE_URL=\"tcp://localhost:9000\"\n```\n\n> This extension is experimental and potentially unstable. Do not use in production. See README for full examples.\n"
      }
    },
    "official_description": "ClickHouse Native Client & File Reader for chsql",
    "official_version": "0.1.3",
    "language": "Rust",
    "maintainers": [
      "lmangani",
      "adubovikov"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/chsql_native/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "cronjob",
    "repository": "https://github.com/quackscience/duckdb-extension-cronjob",
    "owner": "quackscience",
    "repo_name": "duckdb-extension-cronjob",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": null,
    "description": null,
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:01.663908",
    "metadata": {
      "extension": {
        "name": "cronjob",
        "description": "DuckDB HTTP Cronjob Extension",
        "version": "0.0.1",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "lmangani"
        ]
      },
      "repo": {
        "github": "quackscience/duckdb-extension-cronjob",
        "ref": "719904edf23617da02dfb599643452abf51db30e"
      },
      "docs": {
        "hello_world": "-- Every 15 seconds during hours 1-4\nSELECT cron('SELECT now()', '*/15 * 1-4 * * *');\n\n-- Every 2 hours (at minute 0, second 0) during hours 1-4\nSELECT cron('SELECT version()', '0 0 */2 1-4 * *');\n\n-- Every 5 minute (wipe old data)\nSELECT cron('DELETE FROM somewhere WHERE ts < NOW() - INTERVAL ''1 hour''', '* /5 * * * *');\n\n-- Inspect running Jobs\nSELECT * FROM cron_jobs();\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 job_id  \u2502      query       \u2502    schedule    \u2502         next_run         \u2502 status  \u2502         last_run         \u2502 last_result \u2502\n\u2502 varchar \u2502     varchar      \u2502    varchar     \u2502         varchar          \u2502 varchar \u2502         varchar          \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 task_0  \u2502 SELECT version() \u2502 */15 * * * * * \u2502 Fri Nov 15 20:44:30 2024 \u2502 Active  \u2502 Fri Nov 15 20:44:15 2024 \u2502 Success     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- Inspect running Jobs\nSELECT cron_delete('task_0');\n\n-- Supported Patterns\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 second (0 - 59)\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 minute (0 - 59)\n\u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 hour (0 - 23)\n\u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of month (1 - 31)\n\u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 month (1 - 12)\n\u2502 \u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 day of week (0 - 6) (Sunday to Saturday)\n\u2502 \u2502 \u2502 \u2502 \u2502 \u2502\n* * * * * *\n",
        "extended_description": "This extension is experimental and potentially unstable. Do not use it in production.\n"
      }
    },
    "official_description": "DuckDB HTTP Cronjob Extension",
    "official_version": "0.0.1",
    "language": "C++",
    "maintainers": [
      "lmangani"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/cronjob/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "crypto",
    "repository": "https://github.com/query-farm/crypto",
    "owner": "query-farm",
    "repo_name": "crypto",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "this will depend on the client you're using. Some examples:"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "select crypto_hash('sha2-256', 'test');"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "\u2502                 crypto_hash('sha2-256', 'test')                  \u2502"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "select crypto_hash('md5', 'test');"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-26T22:15:27Z",
    "description": "DuckDB Extension for cryptographic hash functions and HMAC",
    "readme_content": "# Crypto Hash/HMAC Extension for DuckDB\n\nThis extension, `crypto`, adds cryptographic hash functions and the ability to calculate HMAC codes to DuckDB.\n\nDuckDB already includes a few functions to calculate hash values, but this extension adds additional hashing algorithms.\n\n## Installation\n\n**`crypto` is a [DuckDB Community Extension](https://github.com/duckdb/community-extensions).**\n\nYou can now use this by using this SQL:\n\n```sql\ninstall crypto from community;\nload crypto;\n```\n\n## Hash Digests\n\n```sql\n-- Calculate some hash digest values.\n select crypto_hash('sha2-256', 'test');\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 crypto_hash('sha2-256', 'test')                  \u2502\n\u2502                             varchar                              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 9f86d081884c7d659a2feaa0c55ad015a3bf4f1b2b0b822cd15d6c15b0f00a08 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500",
    "analysis_timestamp": "2025-09-27T14:44:02.181156",
    "metadata": {
      "docs": {
        "extended_description": "For more information regarding usage, see the [documentation](https://query.farm/duckdb_extension_crypto.html).\n"
      },
      "extension": {
        "build": "cmake",
        "description": "Cryptographic hash functions and HMAC",
        "language": "C++",
        "license": "MIT",
        "maintainers": [
          "rustyconover"
        ],
        "name": "crypto",
        "requires_toolchains": "rust",
        "version": 2025091601,
        "excluded_platforms": "windows_amd64_rtools;windows_amd64_mingw"
      },
      "repo": {
        "github": "query-farm/crypto",
        "ref": "790c098c3ce8be48cfb50e215947580bed6d16c9"
      }
    },
    "official_description": "Cryptographic hash functions and HMAC",
    "official_version": 2025091601,
    "language": "C++",
    "maintainers": [
      "rustyconover"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/crypto/description.yml",
    "deprecation_score": 4.0,
    "recommendation": "REVIEW - Some deprecation indicators found"
  },
  {
    "extension": "cwiqduck",
    "repository": "https://github.com/cwiq-os/cwiqduck",
    "owner": "cwiq-os",
    "repo_name": "cwiqduck",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-22T02:39:48Z",
    "description": "DuckDB extensions for CWIQ",
    "readme_content": "# cwiqduck\n\n## What is cwiqduck?\ncwiqduck extension overrides DuckDB's Filesystem Interface. When loaded, this extension changes the behavior of read operations within [CWIQ FS](https://www.codewilling.com/product/cwiq-fs/).\n\n## How does cwiqduck work?\nOnce loaded, cwiqduck checks if the file in question is within CWIQ FS. If so, the extension redirects DuckDB to the blob storage URL for that file. Then, the httpfs module does the read for that file instead. Diagram below visualizes the extension's capabilities.\n\n<img width=\"1238\" height=\"715\" alt=\"duckdb_illustration\" src=\"https://github.com/user-attachments/assets/4ca55517-d811-45be-849e-84251856e559\" />\n\n## Getting Started\ncwiqduck currently does not add any user-defined function. Instead, it tries to convert DuckDB's reads within CWIQ FS to a URL provided by the blob storage provider (such as Amazon S3).\n\n<pre> \nINSTALL httpfs;\nINSTALL cwiqduck FROM community;\nLOAD cwiqduck;\ncwiqduck extension enabled\n</pre>\n\n## Dependencies\n- http",
    "analysis_timestamp": "2025-09-27T14:44:02.286390",
    "metadata": {
      "extension": {
        "name": "cwiqduck",
        "description": "DuckDB filesystem extension for CWIQ FS",
        "version": "0.0.2",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "excluded_platforms": "windows_amd64_rtools;windows_amd64;windows_amd64_mingw;wasm_mvp;wasm_eh;wasm_threads;osx_amd64;osx_arm64",
        "maintainers": [
          "ph-maxinechang"
        ]
      },
      "repo": {
        "github": "cwiq-os/cwiqduck",
        "ref": "81bb6a0c509ef91919560cbcddaf8e489e0ac8eb"
      }
    },
    "official_description": "DuckDB filesystem extension for CWIQ FS",
    "official_version": "0.0.2",
    "language": "C++",
    "maintainers": [
      "ph-maxinechang"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/cwiqduck/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "datasketches",
    "repository": "https://github.com/query-farm/datasketches",
    "owner": "query-farm",
    "repo_name": "datasketches",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-26T22:15:36Z",
    "description": "Integrates DuckDB with the high-performance Apache DataSketches library. This extension enables users to perform approximate analytics on large-scale datasets using state-of-the-art streaming algorithms, all from within DuckDB.",
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:02.388649",
    "metadata": {
      "docs": {
        "extended_description": "For more information regarding usage, see the [documentation](https://query.farm/duckdb_extension_datasketches.html).\n"
      },
      "extension": {
        "build": "cmake",
        "description": "By utilizing the Apache DataSketches library this extension can efficiently compute approximate distinct item counts and estimations of quantiles, while allowing the sketches to be serialized.",
        "language": "C++",
        "license": "MIT",
        "maintainers": [
          "rustyconover"
        ],
        "name": "datasketches",
        "version": 2025091601
      },
      "repo": {
        "github": "query-farm/datasketches",
        "ref": "1b1090ca4850f9049c904b2ec27937f5417ddc36"
      }
    },
    "official_description": "By utilizing the Apache DataSketches library this extension can efficiently compute approximate distinct item counts and estimations of quantiles, while allowing the sketches to be serialized.",
    "official_version": 2025091601,
    "language": "C++",
    "maintainers": [
      "rustyconover"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/datasketches/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "duck_tails",
    "repository": "https://github.com/teaguesterling/duck_tails",
    "owner": "teaguesterling",
    "repo_name": "duck_tails",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "## \ud83d\udccb Examples"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "and diff analysis capabilities with comprehensive test coverage."
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "# Run tests to verify everything works"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "make test"
      }
    ],
    "active_indicators": [
      {
        "keyword": "new features",
        "source": "readme",
        "context": "All new features should include comprehensive tests. Our test suit"
      }
    ],
    "repository_archived": false,
    "last_push": "2025-07-19T17:26:47Z",
    "description": "A DuckDB extension for exploring and reading git history.",
    "readme_content": "# Duck Tails \ud83e\udd86\n\n**Smart Development Intelligence for DuckDB**\n\nDuck Tails is a DuckDB extension that brings git-aware data analysis capabilities to your database. Query your git history, access files at any revision, and perform version-aware data analysis - all with SQL.\n\n**Status: Functional** - Git filesystem access and diff analysis capabilities with comprehensive test coverage.\n\n## \u2728 Features\n\n### \ud83d\uddc2\ufe0f Git Filesystem\nAccess any file in your git repository at any commit, branch, or tag using the `git://` protocol:\n\n```sql\n-- Read a CSV file from the current HEAD\nSELECT * FROM read_csv('git://data/sales.csv@HEAD');\n\n-- Compare data between commits\nSELECT * FROM read_csv('git://data/sales.csv@HEAD~1');\n\n-- Access files from a specific branch\nSELECT * FROM read_csv('git://config.json@feature-branch');\n\n-- Load data from a tagged release\nSELECT * FROM read_csv('git://metrics.csv@v1.0.0');\n```\n\n### \ud83d\udcca Git Table Functions\nQuery your git repository metadata directly with clean, simple syntax",
    "analysis_timestamp": "2025-09-27T14:44:02.490812",
    "metadata": {
      "extension": {
        "name": "duck_tails",
        "description": "Smart Development Intelligence for DuckDB - Git-aware data analysis capabilities that allow querying git history, accessing files at any revision, and performing version-aware data analysis with SQL.",
        "version": "1.0.0",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "requires_toolchains": "vcpkg",
        "excluded_platforms": "wasm_mvp;wasm_eh;wasm_threads",
        "maintainers": [
          "teaguesterling"
        ]
      },
      "repo": {
        "github": "teaguesterling/duck_tails",
        "ref": "main"
      },
      "docs": {
        "hello_world": "-- Load the extension\nLOAD 'duck_tails';\n\n-- Query git history (defaults to current directory)\nSELECT commit_hash, author_name, message, author_date \nFROM git_log() LIMIT 5;\n\n-- Access files from git repository at specific revisions\nSELECT * FROM read_csv('git://data/sales.csv@HEAD');\n\n-- Compare data between commits\nSELECT COUNT(*) FROM read_csv('git://data/sales.csv@HEAD') AS current_count,\n       COUNT(*) FROM read_csv('git://data/sales.csv@HEAD~1') AS previous_count;\n\n-- Analyze text differences\nSELECT * FROM read_git_diff('git://README.md@HEAD', 'git://README.md@HEAD~1');\n",
        "extended_description": "Duck Tails brings git-aware data analysis capabilities to DuckDB, enabling sophisticated version-controlled data workflows. The extension provides three core capabilities:\n\n**Git Filesystem Access**: Use the `git://` protocol to access any file in your git repository at any commit, branch, or tag. This allows you to query historical data states, compare versions, and perform temporal analysis directly in SQL.\n\n**Repository Metadata Queries**: Query git repository information directly with table functions like `git_log()`, `git_branches()`, and `git_tags()`. Analyze commit histories, track development patterns, and integrate repository metadata into your analytical workflows.\n\n**Text Diff Analysis**: Comprehensive text diffing capabilities with functions like `diff_text()`, `read_git_diff()`, and `text_diff_stats()`. Analyze changes between file versions, track configuration drift, and perform code change analysis.\n\nKey functions include:\n- `git_log([path])` - Query commit history\n- `git_branches([path])` - List repository branches  \n- `git_tags([path])` - List repository tags\n- `diff_text(old, new)` - Compute text differences\n- `read_git_diff(file1, [file2])` - Structured diff analysis\n- `text_diff_lines(diff)` - Parse diff into line-by-line changes\n- `text_diff_stats(old, new)` - Diff statistics and metrics\n\nThe extension supports mixed file systems, allowing you to combine git://, local files, S3, and other DuckDB-supported protocols in a single query. Built with libgit2 for robust git operations and comprehensive error handling."
      }
    },
    "official_description": "Smart Development Intelligence for DuckDB - Git-aware data analysis capabilities that allow querying git history, accessing files at any revision, and performing version-aware data analysis with SQL.",
    "official_version": "1.0.0",
    "language": "C++",
    "maintainers": [
      "teaguesterling"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/duck_tails/description.yml",
    "deprecation_score": 2.0,
    "recommendation": "MONITOR - Minor concerns detected"
  },
  {
    "extension": "duckdb_mcp",
    "repository": "https://github.com/teaguesterling/duckdb_mcp",
    "owner": "teaguesterling",
    "repo_name": "duckdb_mcp",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "## Configuration Examples"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "## Testing"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "# Run test suite"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "make test"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-07-26T16:26:59Z",
    "description": "A simple MCP server extension for DuckDB",
    "readme_content": "# DuckDB MCP Extension\n\nA Model Context Protocol (MCP) extension for DuckDB that enables seamless integration between SQL databases and MCP servers. This extension allows DuckDB to both consume MCP resources and serve as an MCP server.\n\n## Overview\n\nThe DuckDB MCP Extension bridges SQL databases with MCP servers, enabling:\n- Direct SQL access to remote resources via MCP protocol\n- Tool execution from within SQL queries \n- Database serving as an MCP resource provider\n- Flexible security models for development and production\n\n## Core Capabilities\n\n### Client Features\n- **Resource Access**: Query remote data sources using `mcp://` URIs with standard SQL functions\n- **Tool Execution**: Execute MCP tools directly from SQL with `mcp_call_tool()`\n- **Multiple Transports**: Connect via stdio, TCP, and WebSocket protocols\n- **Security Modes**: Permissive mode for development, strict allowlists for production\n- **Configuration Support**: JSON-based server configuration files\n\n### Server Features",
    "analysis_timestamp": "2025-09-27T14:44:02.598928",
    "metadata": {
      "extension": {
        "name": "duckdb_mcp",
        "description": "Model Context Protocol (MCP) extension for DuckDB that enables seamless integration between SQL databases and MCP servers. Provides both client capabilities for accessing remote MCP resources via SQL and server capabilities for exposing database content as MCP resources.",
        "version": "1.0.0",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "requires_toolchains": "",
        "maintainers": [
          "teaguesterling"
        ]
      },
      "repo": {
        "github": "teaguesterling/duckdb_mcp",
        "ref": "main"
      },
      "docs": {
        "hello_world": "-- Load the MCP extension\nLOAD 'duckdb_mcp';\n\n-- Connect to an MCP server using stdio transport\nATTACH 'python3' AS data_server (\n    TYPE mcp, \n    TRANSPORT 'stdio', \n    ARGS '[\"path/to/server.py\"]'\n);\n\n-- Access remote data via MCP protocol\nSELECT * FROM read_csv('mcp://data_server/file:///data.csv');\nSELECT * FROM read_json('mcp://data_server/api://endpoint');\n\n-- List available resources on the server\nSELECT mcp_list_resources('data_server');\n\n-- Execute tools on the MCP server\nSELECT mcp_call_tool('data_server', 'process_data', '{\"table\": \"sales\"}');\n\n-- Server mode: Start an MCP server to expose database content\nSELECT mcp_server_start('stdio', 'localhost', 0, '{}');\n\n-- Publish database tables as MCP resources\nCREATE TABLE products AS SELECT 'Widget' as name, 10.99 as price;\nSELECT mcp_publish_table('products', 'data://tables/products', 'json');\n",
        "extended_description": "DuckDB MCP Extension bridges SQL databases with the Model Context Protocol (MCP), enabling bidirectional integration between DuckDB and MCP servers. The extension operates in dual modes: as an MCP client for accessing remote resources and as an MCP server for exposing database content.\n\n**MCP Client Capabilities**: Connect to MCP servers using multiple transport protocols (stdio, TCP, WebSocket) and access remote resources directly in SQL queries. Use the `mcp://` URI scheme with standard DuckDB functions like `read_csv()`, `read_parquet()`, and `read_json()` to seamlessly query remote data sources. Execute remote tools with `mcp_call_tool()` and discover available resources with `mcp_list_resources()`.\n\n**MCP Server Capabilities**: Transform DuckDB into an MCP resource provider by exposing tables, views, and query results as MCP resources. Start an MCP server with `mcp_server_start()`, publish static table snapshots with `mcp_publish_table()`, and create dynamic resources with `mcp_publish_query()` that refresh at configurable intervals.\n\n**Security Framework**: Flexible security models supporting both development and production environments. Development mode offers permissive access for rapid prototyping, while production mode enforces strict allowlists for commands and URLs. Configure security through settings like `allowed_mcp_commands`, `allowed_mcp_urls`, and JSON configuration files.\n\n**Key Client Functions**:\n- `mcp_list_resources(server)` - Discover available resources\n- `mcp_get_resource(server, uri)` - Retrieve specific resource content\n- `mcp_call_tool(server, tool, args)` - Execute remote tools\n- `read_csv('mcp://server/uri')` - Read CSV data via MCP\n- `read_parquet('mcp://server/uri')` - Read Parquet data via MCP\n- `read_json('mcp://server/uri')` - Read JSON data via MCP\n\n**Key Server Functions**:\n- `mcp_server_start(transport, host, port, config)` - Start MCP server\n- `mcp_server_stop()` - Stop MCP server\n- `mcp_server_status()` - Check server status\n- `mcp_publish_table(table, uri, format)` - Publish table as resource\n- `mcp_publish_query(sql, uri, format, interval)` - Publish query results\n\nThe extension implements the complete JSON-RPC 2.0 MCP protocol with support for multiple transport mechanisms. It enables powerful use cases including database federation, remote data access, tool orchestration, and exposing database insights to external MCP-compatible systems. Perfect for integration with AI agents, data pipelines, and distributed analytical workflows."
      }
    },
    "official_description": "Model Context Protocol (MCP) extension for DuckDB that enables seamless integration between SQL databases and MCP servers. Provides both client capabilities for accessing remote MCP resources via SQL and server capabilities for exposing database content as MCP resources.",
    "official_version": "1.0.0",
    "language": "C++",
    "maintainers": [
      "teaguesterling"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/duckdb_mcp/description.yml",
    "deprecation_score": 4.0,
    "recommendation": "REVIEW - Some deprecation indicators found"
  },
  {
    "extension": "duckpgq",
    "repository": "https://github.com/cwida/duckpgq-extension",
    "owner": "cwida",
    "repo_name": "duckpgq-extension",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "work in progress",
        "source": "readme",
        "context": "repository is currently a research project and a work in progress. Feel free to play around with it and give us fee"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "cy management, just skip this step. Note that the example extension uses VCPKG to build with a dependency f"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "this will depend on the client you're using. Some examples:"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "- Unit tests: `./build/release/test/unittest`"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "- Unit tests: `./build/debug/test/unittest`"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "- `unittest` is the test runner of duckdb. Again, the extension is already"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-07-22T10:16:14Z",
    "description": "DuckDB extension that adds support for SQL/PGQ and graph algorithms",
    "readme_content": "# DuckPGQ\nA DuckDB extension for graph workloads that supports the SQL/PGQ standard. For more information, please see the [documentation page](https://duckpgq.org/).\n\n[![Discord](https://discordapp.com/api/guilds/1225369321077866496/widget.png?style=banner3)](https://discord.gg/8X95XHhQB7)\n## WIP Disclaimer\nThis repository is currently a research project and a work in progress. Feel free to play around with it and give us feedback.\n\n---\n\n## Loading DuckPGQ \nSince DuckDB v1.0.0, DuckPGQ can be loaded as a community extension without requiring the `unsigned` flag. From any DuckDB instance, the following two commands will allow you to install and load DuckPGQ:\n```sql\ninstall duckpgq from community;\nload duckpgq;\n```\nSee the [DuckPGQ community extension page](https://community-extensions.duckdb.org/extensions/duckpgq.html) for more information.\n\nFor older DuckDB versions there are two ways to install the DuckPGQ extension. \nBoth ways require DuckDB to be launched in the `unsigned` mode.\nTh",
    "analysis_timestamp": "2025-09-27T14:44:02.704189",
    "metadata": {
      "extension": {
        "name": "duckpgq",
        "description": "Extension that adds support for SQL/PGQ and graph algorithms",
        "version": "0.2.5",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "Dtenwolde"
        ]
      },
      "repo": {
        "github": "cwida/duckpgq-extension",
        "ref": "942455f5e99c2ed9caa1b654785e87ef7aa82949"
      },
      "docs": {
        "hello_world": "CREATE TABLE Person AS SELECT * FROM 'https://gist.githubusercontent.com/Dtenwolde/2b02aebbed3c9638a06fda8ee0088a36/raw/8c4dc551f7344b12eaff2d1438c9da08649d00ec/person-sf0.003.csv';\nCREATE TABLE Person_knows_person AS SELECT * FROM 'https://gist.githubusercontent.com/Dtenwolde/81c32c9002d4059c2c3073dbca155275/raw/8b440e810a48dcaa08c07086e493ec0e2ec6b3cb/person_knows_person-sf0.003.csv';\n\nCREATE PROPERTY GRAPH snb\n  VERTEX TABLES (\n    Person\n  )\n  EDGE TABLES (\n    Person_knows_person SOURCE KEY (Person1Id) REFERENCES Person (id)\n                        DESTINATION KEY (Person2Id) REFERENCES Person (id)\n    LABEL knows\n  );\n\nFROM GRAPH_TABLE (snb\n  MATCH (a:Person)-[k:knows]->(b:Person)\n  COLUMNS (a.id, b.id)\n)\nLIMIT 1;\n\nFROM GRAPH_TABLE (snb \n  MATCH p = ANY SHORTEST (a:person)-[k:knows]->{1,3}(b:Person) \n  COLUMNS (a.id, b.id, path_length(p))\n) \nLIMIT 1;\n\nFROM local_clustering_coefficient(snb, person, knows);\n\nDROP PROPERTY GRAPH snb; \n",
        "extended_description": "The DuckPGQ extension supports the SQL/PGQ syntax as part of the official SQL:2023 standard developed by ISO.\n\nIt introduces visual graph pattern matching and a more concise syntax for path-finding. For more information, please see the [DuckPGQ documentation](https://duckpgq.org).\n\n*Disclaimer:* As this extension is part of an ongoing research project by the Database Architectures group at CWI, some features may still be under development. We appreciate your understanding and patience as we continue to improve it.\n"
      }
    },
    "official_description": "Extension that adds support for SQL/PGQ and graph algorithms",
    "official_version": "0.2.5",
    "language": "C++",
    "maintainers": [
      "Dtenwolde"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/duckpgq/description.yml",
    "deprecation_score": 6.0,
    "recommendation": "POSSIBLY DEPRECATED - Manual review recommended"
  },
  {
    "extension": "eeagrid",
    "repository": "https://github.com/ahuarte47/duckdb-eeagrid",
    "owner": "ahuarte47",
    "repo_name": "duckdb-eeagrid",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "## Example Usage"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "this will depend on the client you're using. Some examples:"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "### Running the tests"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "Different tests can be created for DuckDB extensions. The primar"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "y way of testing DuckDB extensions should be the SQL tests in `"
      }
    ],
    "active_indicators": [
      {
        "keyword": "maintained",
        "source": "readme",
        "context": "environmental data analysis and reporting. It is maintained by the [European Environment Agency](https://www."
      }
    ],
    "repository_archived": false,
    "last_push": "2025-09-10T20:27:02Z",
    "description": "Functions for transforming XY coordinates to and from the EEA Reference Grid (EPSG:3035)",
    "readme_content": "# DuckDB EEA Reference Grid Extension\n\n## What is this?\n\nThis is an extension for DuckDB that adds support for working with the [EEA Reference Grid System](https://sdi.eea.europa.eu/catalogue/srv/api/records/aac8379a-5c4e-445c-b2ef-23a6a2701ef0/attachments/eea_reference_grid_v1.pdf).\n\nThe **EEA Reference Grid** is a standardized spatial grid system used across Europe for environmental data analysis and reporting. It is maintained by the [European Environment Agency](https://www.eea.europa.eu/en) (EEA) and forms the basis for aggregating and exchanging geospatial data in a consistent format:\n\n* `Coordinate Reference System (CRS)`: ETRS89 / LAEA Europe ([EPSG:3035](https://epsg.io/3035)), which minimizes area distortion across Europe. The Geodetic Datum is the European Terrestrial Reference System 1989 (EPSG:6258). The Lambert Azimuthal Equal Area (LAEA) projection is\ncentred at 10\u00b0E, 52\u00b0N. Coordinates are based on a false Easting of 4321000 meters, and a false Northing of 3210000 meters",
    "analysis_timestamp": "2025-09-27T14:44:02.819330",
    "metadata": {
      "extension": {
        "name": "eeagrid",
        "description": "Extension that adds support for working with the EEA Reference Grid System.",
        "version": "1.3.1",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "ahuarte47"
        ]
      },
      "repo": {
        "github": "ahuarte47/duckdb-eeagrid",
        "ref": "7baa632d47cb58830b82eb515eb01c34a0d2cb25"
      },
      "docs": {
        "hello_world": "SELECT EEA_CoordXY2GridNum(5078600, 2871400);\n----\n23090257455218688\n\nSELECT EEA_GridNum2CoordX(23090257455218688);\n----\n5078600\n\nSELECT EEA_GridNum2CoordY(23090257455218688);\n----\n2871400\n\nSELECT EEA_GridNumAt100m(23090257455218688);\n----\n23090257455218688\n\nSELECT EEA_GridNumAt1km(23090257455218688);\n----\n23090257448665088\n\nSELECT EEA_GridNumAt10km(23090257455218688);\n----\n23090255284404224\n",
        "extended_description": "The EEA Reference Grid extension adds support for working with the [EEA Reference Grid System](https://sdi.eea.europa.eu/catalogue/srv/api/records/aac8379a-5c4e-445c-b2ef-23a6a2701ef0/attachments/eea_reference_grid_v1.pdf).\n\nThe **EEA Reference Grid** is a standardized spatial grid system used across Europe for environmental data analysis and reporting. It is maintained by the [European Environment Agency](https://www.eea.europa.eu/en) (EEA) and forms the basis for aggregating and exchanging geospatial data in a consistent format:\n\n  * `Coordinate Reference System (CRS)`: ETRS89 / LAEA Europe ([EPSG:3035](https://epsg.io/3035)), which minimizes area distortion across Europe. The Geodetic Datum is the European Terrestrial Reference System 1989 (EPSG:6258). The Lambert Azimuthal Equal Area (LAEA) projection is centred at 10\u00b0E, 52\u00b0N. Coordinates are based on a false Easting of 4321000 meters, and a false Northing of 3210000 meters.\n  * `Supported resolutions`: Typically available at 10 km, 1 km, and 100 m resolutions.\n  * `Structure`: Regular square grid with unique cell codes and identifiers assigned based on position and resolution.\n  * `Purpose`: Enables harmonized spatial analysis, mapping, and cross-border environmental assessments.\n\nThis grid system is widely used in European environmental datasets, including air quality, land use, biodiversity, and climate change indicators.\n\nThe extension provides functions to calculate grid cell identifiers (`INT64`) from XY coordinates based on the `EPSG:3035` coordinate reference system, and vice versa. Please see the [function table](docs/functions.md) for the current implementation status.\n"
      }
    },
    "official_description": "Extension that adds support for working with the EEA Reference Grid System.",
    "official_version": "1.3.1",
    "language": "C++",
    "maintainers": [
      "ahuarte47"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/eeagrid/description.yml",
    "deprecation_score": 3.0,
    "recommendation": "REVIEW - Some deprecation indicators found"
  },
  {
    "extension": "evalexpr_rhai",
    "repository": "https://github.com/query-farm/evalexpr_rhai",
    "owner": "query-farm",
    "repo_name": "evalexpr_rha",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": null,
    "description": "",
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:02.924666",
    "metadata": {
      "docs": {
        "extended_description": "For more information regarding usage, see the [documentation](https://query.farm/duckdb_extension_evalexpr_rhai.html).\n"
      },
      "extension": {
        "build": "cmake",
        "description": "Evaluate the Rhai scripting language in DuckDB",
        "excluded_platforms": "windows_amd64_rtools;windows_amd64_mingw;windows_amd64",
        "language": "C++",
        "license": "Apache-2.0",
        "maintainers": [
          "rustyconover"
        ],
        "name": "evalexpr_rhai",
        "requires_toolchains": "rust",
        "version": 2025091601
      },
      "repo": {
        "github": "query-farm/evalexpr_rhai",
        "ref": "4b5e3c6ae750c223025a9a20919856090c60d675"
      }
    },
    "official_description": "Evaluate the Rhai scripting language in DuckDB",
    "official_version": 2025091601,
    "language": "C++",
    "maintainers": [
      "rustyconover"
    ],
    "license": "Apache-2.0",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/evalexpr_rhai/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "faiss",
    "repository": "https://github.com/duckdb-faiss-ext/duckdb-faiss-ext",
    "owner": "duckdb-faiss-ext",
    "repo_name": "duckdb-faiss-ex",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": null,
    "description": "",
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:03.026443",
    "metadata": {
      "extension": {
        "name": "faiss",
        "description": "Provides access to faiss indices from DuckDB.",
        "version": "0.12.0",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "JAicewizard",
          "arjenpdevries"
        ],
        "excluded_platforms": "osx_amd64;wasm_mvp;wasm_eh;wasm_threads;linux_amd64_musl",
        "requires_toolchains": "fortran;omp",
        "vcpkg_url": "https://github.com/jaicewizard/vcpkg.git",
        "vcpkg_commit": "3f1a0e1b63fc4c1fb811f17c9c79d985cd42e732"
      },
      "repo": {
        "github": "duckdb-faiss-ext/duckdb-faiss-ext",
        "ref": "v0.12.0"
      },
      "docs": {
        "hello_world": "-- Generate semi-random input data and queries\n-- Note that the dimensionality of our data will be 5\nCREATE TABLE input AS SELECT i AS id, apply(generate_series(1, 5), j-> CAST(hash(i*1000+j) AS FLOAT)/18446744073709551615) AS data FROM generate_series(1, 1000) s(i);\nCREATE TABLE queries AS SELECT i AS id, apply(generate_series(1, 5), j-> CAST(hash(i*1000+j+8047329823) AS FLOAT)/18446744073709551615) AS data FROM generate_series(1, 10) s(i);\n-- Create the index and insert data into it\nCALL FAISS_CREATE('name', 5, 'IDMap,HNSW32');\nCALL FAISS_ADD((SELECT id, data FROM input), 'name');\n-- On linux, with cuda, we can move the index to the GPU\n-- CALL FAISS_TO_GPU('name', 0);\n-- Get 10 results with uneven id\nSELECT id, UNNEST(FAISS_SEARCH_FILTER('name', 10, data, 'id%2==1', 'rowid', 'input')) FROM queries;\n-- Get 10 results with even id\nSELECT id, UNNEST(FAISS_SEARCH_FILTER('name', 10, data, 'id%2==0', 'rowid', 'input')) FROM queries;\n-- Get 10 results\nSELECT id, UNNEST(FAISS_SEARCH('name', 10, data)) FROM queries;\n",
        "extended_description": "The FAISS extension allows DuckDB users to store vector data in faiss, and query this data, making reliable vector search more accessible. On all linux platforms, this platform also supports GPU indexes, you can move a supported index to the GPU using `CALL FAISS_MOVE_GPU({index_name}, {gpu number})`. Currently only CUDA is supported, note that GPU support may be split into a seperate extension in the future.\n\nSome (most) indices are not supported for gpus, however this is very easily resolvable. Please open an issue over at our repository in order to get this resolved!\n"
      }
    },
    "official_description": "Provides access to faiss indices from DuckDB.",
    "official_version": "0.12.0",
    "language": "C++",
    "maintainers": [
      "JAicewizard",
      "arjenpdevries"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/faiss/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "file_dialog",
    "repository": "https://github.com/yutannihilation/duckdb-ext-file-dialog",
    "owner": "yutannihilation",
    "repo_name": "duckdb-ext-file-dialo",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": null,
    "description": "",
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:03.129172",
    "metadata": {
      "extension": {
        "name": "file_dialog",
        "description": "Choose a file via native file dialog",
        "version": "0.0.3",
        "language": "Rust",
        "build": "cargo",
        "license": "MIT",
        "excluded_platforms": "wasm_mvp;wasm_eh;wasm_threads;linux_amd64_musl",
        "requires_toolchains": "rust;python3",
        "maintainers": [
          "yutannihilation"
        ]
      },
      "repo": {
        "github": "yutannihilation/duckdb-ext-file-dialog",
        "ref": "a1f0700cf79830e361148a92f7bce9bcf874dcd1"
      },
      "docs": {
        "hello_world": "FROM read_csv(choose_file());\n\n-- Optionally, you can filter files by the extension. For example, this\n-- makes the dialog list CSV files only\nFROM read_csv(choose_file('csv'));\n",
        "extended_description": "This extension is a tiny utility to choose a file interactively.\n"
      }
    },
    "official_description": "Choose a file via native file dialog",
    "official_version": "0.0.3",
    "language": "Rust",
    "maintainers": [
      "yutannihilation"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/file_dialog/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "flock",
    "repository": "https://github.com/dais-polymtl/flock",
    "owner": "dais-polymtl",
    "repo_name": "flock",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "### \ud83d\udd27 Example Query"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "n semantic analysis tasks directly in DuckDB. For example:"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "Explore more usage examples in the [documentation](https://dais-polymtl.gith"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-19T15:11:32Z",
    "description": "Flock: multimodal querying for DuckDB",
    "readme_content": "<a id=\"readme-top\"></a>\n\n<br />\n\n<div align=\"center\">\n  <a href=\"https://dais-polymtl.github.io/flock/\">\n    <img src=\"docs/static/flock-square-readme.png\" alt=\"Logo\" height=\"300\">\n  </a>\n  <br /><br />\n  <p align=\"center\">\n    DBMS extension for multimodal query processing and optimization.\n    <br />\n    <a href=\"https://dais-polymtl.github.io/flock/docs/what-is-flock\"><strong>Explore the docs \u00bb</strong></a>\n    <br />\n    <br />\n    <a href=\"https://dais-polymtl.github.io/flock/\">Landing Page</a>\n    |\n    <a href=\"https://github.com/dais-polymtl/flock/issues/new?labels=bug&template=bug-report.md\">Report Bug</a>\n    |\n    <a href=\"https://github.com/dais-polymtl/flock/issues/new?labels=enhancement&template=feature-request.md\">Request Feature</a>\n  </p>\n</div>\n\n<details>\n  <summary>\n    <h2>Table of Contents</h2>\n  </summary>\n  <ol>\n    <li><a href=\"#-about-the-project\">About The Project</a></li>\n    <li><a href=\"#-features\">Features</a></li>\n    <li>\n      <a href=\"#-getting-started",
    "analysis_timestamp": "2025-09-27T14:44:03.231207",
    "metadata": {
      "extension": {
        "name": "flock",
        "description": "LLM & RAG extension to combine analytics and semantic analysis",
        "version": "0.5.0",
        "language": "SQL & C++",
        "build": "cmake",
        "license": "MIT",
        "excluded_platforms": "windows_amd64_rtools;wasm_mvp;wasm_eh;wasm_threads",
        "maintainers": [
          "anasdorbani",
          "queryproc"
        ]
      },
      "repo": {
        "github": "dais-polymtl/flock",
        "ref": "7f1c36abe481b97c9e2c6e7303f36005c8d242fa"
      },
      "docs": {
        "hello_world": "-- After loading, any function call will throw an error if the provider's secret doesn't exist\n\n-- Create your provider secret by following the [documentation](https://dais-polymtl.github.io/flock/docs/what-is-flock/). For example, you can create a default OpenAI API key as follows:\nD CREATE SECRET (TYPE OPENAI, API_KEY 'your-api-key');\n\n-- Call an OpenAI model with a predefined prompt ('Tell me hello world') and default model ('gpt-4o-mini')\nD SELECT llm_complete({'model_name': 'default'}, {'prompt_name': 'hello-world'});\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 llm_complete(hello_world, default_model) \u2502\n\u2502                 varchar                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                Hello world               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- Check the prompts and supported models\nD GET PROMPTS;\nD GET MODELS;\n\n-- Create a new prompt for summarizing text\nD CREATE PROMPT('summarize', 'summarize the text into 1 word: {{text}}');\n\n-- Create a variable name for the model to do the summarizing\nD CREATE MODEL('summarizer-model', 'gpt-4o', 'openai');\n\n-- Summarize text and pass it as parameter \nD SELECT llm_complete({'model_name': 'summarizer-model'}, {'prompt_name': 'summarize','context_columns': [{'data': 'We support more functions and approaches to combine relational analytics and semantic analysis. Check our repo for documentation and examples.'}}]);\n",
        "extended_description": "**Flock** is an experimental DuckDB extension that enables seamless integration of large language models (LLMs) and retrieval-augmented generation (RAG) directly within SQL.\n\nIt introduces `MODEL` and `PROMPT` objects as first-class SQL entities, making it easy to define, manage, and reuse LLM interactions. Core functions like `llm_complete`, `llm_filter`, and `llm_rerank` allow you to perform generation, semantic filtering, and ranking\u2014all from SQL.\n\nFlock is designed for rapid prototyping of LLM-based analytics and is optimized with batching and caching features for better performance.\n\n\ud83d\udcc4 For more details and examples, see the [Flock documentation](https://dais-polymtl.github.io/flock/docs/what-is-flock).\n\n> *Note:* Flock is part of ongoing research by the [Data & AI Systems (DAIS) Laboratory @ Polytechnique Montr\u00e9al](https://dais-polymtl.github.io/). It is under active development, and some features may evolve. Feedback and contributions are welcome!\n"
      }
    },
    "official_description": "LLM & RAG extension to combine analytics and semantic analysis",
    "official_version": "0.5.0",
    "language": "SQL & C++",
    "maintainers": [
      "anasdorbani",
      "queryproc"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/flock/description.yml",
    "deprecation_score": 3.0,
    "recommendation": "REVIEW - Some deprecation indicators found"
  },
  {
    "extension": "fuzzycomplete",
    "repository": "https://github.com/query-farm/fuzzycomplete",
    "owner": "query-farm",
    "repo_name": "fuzzycomplete",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "this will depend on the client you're using. Some examples:"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "./build/release/test/unittest"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "- `unittest` is the test runner of duckdb. Again, the extension is already"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "bucket.s3.us-east-1.amazonaws.com/fuzzycomplete/latest';"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-26T22:17:51Z",
    "description": "DuckDB Extension for fuzzy string matching based autocompletion",
    "readme_content": "# fuzzycomplete Extension for DuckDB\n\n![A duck trying to complete a crossword puzzle](./docs/duckdb-fuzzycompletion.jpeg)\n\nThis `fuzzycomplete` extension serves as an alternative to DuckDB's [autocomplete](https://duckdb.org/docs/api/cli/autocomplete.html) extension, with several key differences:\n\n**Algorithm:** Unlike the [autocomplete extension](https://duckdb.org/docs/extensions/autocomplete.html), which uses edit distance as its metric, the fuzzycomplete extension employs a fuzzy string matching algorithm derived from Visual Studio Code. This provides more intuitive and flexible completion suggestions.\n\n**Scope:** The `fuzzycomplete` extension can complete table names across different databases and schemas. It respects the current search path and offers suggestions accordingly, even when multiple databases are attached.\n\nIt may not yet be the best solution for SQL completion, but it has proven to be useful to the author.\n\n## Installation\n\n**`fuzzycomplete` is a [DuckDB Community Ex",
    "analysis_timestamp": "2025-09-27T14:44:03.335049",
    "metadata": {
      "docs": {
        "extended_description": "For more information regarding usage, see the [documentation](https://query.farm/duckdb_extension_fuzzycomplete.html).\n"
      },
      "extension": {
        "build": "cmake",
        "description": "Fuzzy matching based autocompletion",
        "language": "C++",
        "license": "Apache-2.0",
        "maintainers": [
          "rustyconover"
        ],
        "name": "fuzzycomplete",
        "requires_toolchains": "rust",
        "version": "1.0.0",
        "excluded_platforms": "linux_amd64_musl"
      },
      "repo": {
        "github": "query-farm/fuzzycomplete",
        "ref": "2ac9b48856c6cf0bdbc9411805596526943a2f56"
      }
    },
    "official_description": "Fuzzy matching based autocompletion",
    "official_version": "1.0.0",
    "language": "C++",
    "maintainers": [
      "rustyconover"
    ],
    "license": "Apache-2.0",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/fuzzycomplete/description.yml",
    "deprecation_score": 4.0,
    "recommendation": "REVIEW - Some deprecation indicators found"
  },
  {
    "extension": "gcs",
    "repository": "https://github.com/northpolesec/duckdb-gcs",
    "owner": "northpolesec",
    "repo_name": "duckdb-gcs",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "examples:"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "./build/release/test/unittest"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "- `unittest` is the test runner of duckdb. Again, the extension is already"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "D SELECT COUNT(*) FROM 'gcss://duckdb-gcs-testing/taxi_2019_04.parquet';"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-18T20:49:06Z",
    "description": "A GCS-native extension for DuckDB",
    "readme_content": "# duckdb-gcs\n\n---\n\nThis DuckDB extension allows you to read files from Google Cloud Storage,\nnatively, using the Google Cloud C++ SDK.\n\nDuckDB's core httpfs extension allows reading files from GCS, but it does so\nusing the S3 compatibility API. This is not as fast as the native API and it\nrequires using HMAC keys. HMAC keys are, by default, disabled by organization\npolicy for service accounts.\n\nNote: Because the core `httpfs` extension registers itself as a handler for\n`gs://` and `gcs://` URLs, this extension also supports `gcss://` as a way to\nforce its usage.\n\n## Building\n\n### Managing dependencies\n\nDuckDB extensions uses VCPKG for dependency management. Enabling VCPKG is very\nsimple: follow the\n[installation instructions](https://vcpkg.io/en/getting-started) or just run the\nfollowing:\n\n```shell\ngit clone https://github.com/Microsoft/vcpkg.git\n./vcpkg/bootstrap-vcpkg.sh\nexport VCPKG_TOOLCHAIN_PATH=`pwd`/vcpkg/scripts/buildsystems/vcpkg.cmake\n\n```\n\n### Build steps\n\nNow to build the e",
    "analysis_timestamp": "2025-09-27T14:44:03.439842",
    "metadata": {
      "extension": {
        "name": "gcs",
        "description": "DuckDB GCS Extension",
        "extended_description": "A native GCS extension with support for standard Google auth methods",
        "version": "0.0.1",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "excluded_platforms": "wasm_mvp;wasm_eh;wasm_threads;windows_amd64_mingw;windows_amd64",
        "maintainers": [
          "northpolesec"
        ]
      },
      "repo": {
        "github": "northpolesec/duckdb-gcs",
        "ref": "b0b3bd3e896417308800a04116cf60a129de7e0c"
      },
      "docs": {
        "hello_world": "-- Add auth credentials using Application Default Creds\nD CREATE SECRET secret (TYPE gcp, PROVIDER credential_chain);\n\n-- Read a file from GCS\nD SELECT * FROM read_text('gcss://rah-public-gcs-testing/quack.txt');\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                filename                 \u2502 content \u2502 size  \u2502      last_modified       \u2502\n\u2502                 varchar                 \u2502 varchar \u2502 int64 \u2502 timestamp with time zone \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 gcss://rah-public-gcs-testing/quack.txt \u2502 \ud83e\udd86      \u2502   4   \u2502 2025-09-23 16:20:03-04   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"
      }
    },
    "official_description": "DuckDB GCS Extension",
    "official_version": "0.0.1",
    "language": "C++",
    "maintainers": [
      "northpolesec"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/gcs/description.yml",
    "deprecation_score": 4.0,
    "recommendation": "REVIEW - Some deprecation indicators found"
  },
  {
    "extension": "geography",
    "repository": "https://github.com/paleolimbot/duckdb-geography",
    "owner": "paleolimbot",
    "repo_name": "duckdb-geography",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "work in progress",
        "source": "readme",
        "context": "](docs/function-reference.md). Documentation is a work in progress!"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "./build/release/test/unittest"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "- `unittest` is the test runner of duckdb. Again, the extension is already"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "## Running the tests"
      }
    ],
    "active_indicators": [
      {
        "keyword": "stable",
        "source": "readme",
        "context": "be documented when stable such that other libraries can decode the value"
      },
      {
        "keyword": "stable",
        "source": "readme",
        "context": "Note that all types listed above are implicitly castable to `GEOGRAPHY` such that"
      }
    ],
    "repository_archived": false,
    "last_push": "2025-08-19T14:12:08Z",
    "description": null,
    "readme_content": "# DuckDB Geography\n\nThis repository is based on https://github.com/duckdb/extension-template, check it out if you want to build and ship your own DuckDB extension.\n\n---\n\nThis extension, geography, allows you leverage [Google's s2geometry library](https://github.com/google/s2geometry) via the [s2geography wrapper library](https://github.com/paleolimbot/s2geography) that also powers S2 integration as an [R package](https://r-spatial.github.io/s2) and a [Python library](https://github.com/benbovy/spherely). It is preliminary and not currently published as a community extension.\n\nIn general, the functions are the same as those implemented in the [spatial extension](https://duckdb.org/docs/extensions/spatial/functions.html) except they are prefixed with `s2_` instead of `st_`. See [the function reference](docs/function-reference.md) for a complete list with documentation.\n\n```\nLOAD geography;\n\nD CREATE TABLE countries as SELECT name, s2_prepare(geog) as geog FROM s2_data_countries();\nD SELE",
    "analysis_timestamp": "2025-09-27T14:44:03.543795",
    "metadata": {
      "extension": {
        "name": "geography",
        "description": "Global spatial data processing on the sphere",
        "version": "0.1.0",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "excluded_platforms": "wasm_mvp;wasm_eh;wasm_threads",
        "maintainers": [
          "paleolimbot"
        ]
      },
      "repo": {
        "github": "paleolimbot/duckdb-geography",
        "ref": "e83725eb4ea245db9d2a5e02887dacfda3eb59a7"
      },
      "docs": {
        "hello_world": "SELECT * FROM s2_data_countries();\n",
        "extended_description": "The geography extension provides global spatial indexing and analysis on the sphere\nusing Google's s2geometry library. For full documentation, see the\n[README](https://github.com/paleolimbot/duckdb-geography/blob/main/README.md)\nand [function documentation](https://github.com/paleolimbot/duckdb-geography/blob/main/docs/function-reference.md).\n"
      }
    },
    "official_description": "Global spatial data processing on the sphere",
    "official_version": "0.1.0",
    "language": "C++",
    "maintainers": [
      "paleolimbot"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/geography/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "geotiff",
    "repository": "https://github.com/babaknaimi/duckdb-geotiff",
    "owner": "babaknaimi",
    "repo_name": "duckdb-geotiff",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "### R example:"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-08-20T05:12:15Z",
    "description": "Duckdb extension to read GeoTiffs directly with duckdb database",
    "readme_content": "# geotiff (DuckDB Community Extension)\n\n`geotiff` lets DuckDB read GeoTIFF rasters via GDAL and expose them as a table function.\n\n## Install\n\n```sql\nINSTALL geotiff FROM community;\nLOAD geotiff;\n```\n\n\n(If you installed an older copy locally and want to refresh:)\n\n```sql\nFORCE INSTALL geotiff FROM community;\nLOAD geotiff;\n```\n\n# Usage\n\n## Single band (long form)\n\nReturns two columns:\n\n- cell_id BIGINT \u2014 0-based linear index in row-major order (row * width + col)\n\n- value DOUBLE \u2014 pixel value (NULL for NoData)\n\n```sql\nSELECT * FROM read_geotiff('cea.tif', band := 1) LIMIT 5;\n```\n\n## Multiple bands (wide form)\n\nReturns one row per cell with one column per requested band:\n\n```sql\nSELECT * FROM read_geotiff('cea.tif', band := [1,2,3]) LIMIT 5;\n-- schema: (cell_id BIGINT, band1 DOUBLE, band2 DOUBLE, band3 DOUBLE)\n\n```\n\n## Typical patterns\n\n### Create a wide table from a multi-band raster:\n\n```sql\nCREATE TABLE r_chelsa AS\nSELECT * FROM read_geotiff('cea.tif', band := [1,2,3]);\nCREATE INDEX id",
    "analysis_timestamp": "2025-09-27T14:44:03.655723",
    "metadata": {
      "extension": {
        "name": "geotiff",
        "description": "Read GeoTIFF rasters as (cell_id, value) via GDAL",
        "version": "0.1.2",
        "language": "C++",
        "build": "cmake",
        "licence": "MIT",
        "maintainers": [
          "babaknaimi"
        ],
        "excluded_platforms": "windows_amd64_mingw"
      },
      "repo": {
        "github": "babaknaimi/duckdb-geotiff",
        "ref": "3fa51dbe85cb890dea8416c07c90f30147b9d6a4"
      },
      "docs": {
        "hello_world": "-- one band -> (cell_id, value)\nINSTALL geotiff FROM community;\nLOAD geotiff;\nSELECT * FROM read_geotiff('cea.tif', band := 1) LIMIT 5;\n\n-- multiple bands -> (cell_id, band1, band2, ...)\nSELECT * FROM read_geotiff('cea.tif', band := [1,2,3]) LIMIT 5;\n",
        "extended_description": "The geotiff extension streams GeoTIFF rasters using GDAL and exposes them as\nDuckDB table functions. For a single band it returns (cell_id BIGINT, value DOUBLE).\nIf you pass multiple bands (e.g., band := [1,2,3]) it returns a wide schema:\n(cell_id, band1, band2, \u2026). This is optimized for fast CTAS/UPDATE patterns\nwhen building \u201cwide\u201d raster tables inside DuckDB."
      }
    },
    "official_description": "Read GeoTIFF rasters as (cell_id, value) via GDAL",
    "official_version": "0.1.2",
    "language": "C++",
    "maintainers": [
      "babaknaimi"
    ],
    "license": "",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/geotiff/description.yml",
    "deprecation_score": 1.0,
    "recommendation": "MONITOR - Minor concerns detected"
  },
  {
    "extension": "gsheets",
    "repository": "https://github.com/evidence-dev/duckdb_gsheets",
    "owner": "evidence-dev",
    "repo_name": "duckdb_gsheets",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "experimental",
        "source": "readme",
        "context": "**\ud83d\udea7 Experimental \ud83d\udea7** Here be dragons"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "The latest version of [DuckDB](https://duckdb.org/docs/insta"
      }
    ],
    "active_indicators": [
      {
        "keyword": "maintained",
        "source": "readme",
        "context": "ith Google or DuckDB, it is a community extension maintained by [Evidence](https://evidence.dev)._"
      }
    ],
    "repository_archived": false,
    "last_push": "2025-09-09T21:14:54Z",
    "description": "DuckDB extension to read and write Google Sheets using SQL",
    "readme_content": "---\ntitle: DuckDB GSheets\ndescription: A DuckDB extension for reading and writing Google Sheets with SQL.\nhide_title: true\n---\n\n<h1 class=\"markdown flex items-center gap-2\"><img src=\"icon-512.png\" style=\"height: 1em;\"/> DuckDB GSheets</h1>\n\n<Alert status=\"warning\">\n\n**\ud83d\udea7 Experimental \ud83d\udea7** Here be dragons\n \n</Alert>\n\n\nA DuckDB extension for reading and writing Google Sheets with SQL.\n\n_Note: This project is not affliated with Google or DuckDB, it is a community extension maintained by [Evidence](https://evidence.dev)._\n\n## Install\n\n```sql\nINSTALL gsheets FROM community;\nLOAD gsheets;\n```\n\nThe latest version of [DuckDB](https://duckdb.org/docs/installation) (currently 1.4.0) is supported.\n\n## Usage \n\n### Authenticate\n\n```sql\n-- Authenticate with Google Account in the browser (default)\nCREATE SECRET (TYPE gsheet);\n\n\n-- OR create a secret with your Google API access token (boring, see below guide)\nCREATE SECRET (\n    TYPE gsheet, \n    PROVIDER access_token, \n    TOKEN '<your_token>'\n);\n\n\n-- ",
    "analysis_timestamp": "2025-09-27T14:44:03.758966",
    "metadata": {
      "extension": {
        "name": "gsheets",
        "description": "Read and write Google Sheets using SQL",
        "version": "0.0.7",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "excluded_platforms": "windows_amd64_rtools;windows_amd64_mingw;wasm_mvp;wasm_eh;wasm_threads",
        "maintainers": [
          "archiewood",
          "mharrisb1"
        ]
      },
      "repo": {
        "github": "evidence-dev/duckdb_gsheets",
        "ref": "f44cfdd97c83489a5ffea15712fc24d0e257ff44"
      },
      "docs": {
        "hello_world": "-- Authenticate with Google Account in the browser (easiest)\nCREATE SECRET (TYPE gsheet);\n\n-- OR create a secret with your Google API access token (boring, see extension docs)\nCREATE SECRET (\n  TYPE gsheet, \n  PROVIDER access_token, \n  TOKEN '<your_token>'\n);\n\n-- Read a spreadsheet by full URL\nFROM read_gsheet('https://docs.google.com/spreadsheets/d/11QdEasMWbETbFVxry-SsD8jVcdYIT1zBQszcF84MdE8/edit');\n\n-- Read a spreadsheet by full URL, implicitly\nFROM 'https://docs.google.com/spreadsheets/d/11QdEasMWbETbFVxry-SsD8jVcdYIT1zBQszcF84MdE8/edit';\n\n-- Read a spreadsheet by spreadsheet id\nFROM read_gsheet('11QdEasMWbETbFVxry-SsD8jVcdYIT1zBQszcF84MdE8');\n\n-- Read a spreadsheet with no header row\nSELECT * FROM read_gsheet('11QdEasMWbETbFVxry-SsD8jVcdYIT1zBQszcF84MdE8', headers=false);\n\n-- Read all values in as varchar, skipping type inference\nSELECT * FROM read_gsheet('11QdEasMWbETbFVxry-SsD8jVcdYIT1zBQszcF84MdE8', all_varchar=true);\n\n-- Read a sheet other than the first sheet using the sheet name\nSELECT * FROM read_gsheet('11QdEasMWbETbFVxry-SsD8jVcdYIT1zBQszcF84MdE8', sheet='Sheet2');\n\n-- Read a sheet other than the first sheet using the sheet id in the URL\nSELECT * FROM read_gsheet('https://docs.google.com/spreadsheets/d/11QdEasMWbETbFVxry-SsD8jVcdYIT1zBQszcF84MdE8/edit?gid=644613997#gid=644613997');\n\n-- Write a spreadsheet from a table by spreadsheet id\nCOPY <table_name> TO '11QdEasMWbETbFVxry-SsD8jVcdYIT1zBQszcF84MdE8' (FORMAT gsheet);\n\n-- Write a spreadsheet from a table by full URL\nCOPY <table_name> TO 'https://docs.google.com/spreadsheets/d/11QdEasMWbETbFVxry-SsD8jVcdYIT1zBQszcF84MdE8/edit?usp=sharing' (FORMAT gsheet);\n\n-- Write a spreadsheet to a specific sheet using the sheet id in the URL\nCOPY <table_name> TO 'https://docs.google.com/spreadsheets/d/11QdEasMWbETbFVxry-SsD8jVcdYIT1zBQszcF84MdE8/edit?gid=1295634987#gid=1295634987' (FORMAT gsheet);\n",
        "extended_description": "The DuckDB GSheets Extension allows reading and writing of data in Google Sheets from DuckDB.\nFor detailed setup and usage instructions, visit the docs at [duckdb-gsheets.com](https://duckdb-gsheets.com).\n"
      }
    },
    "official_description": "Read and write Google Sheets using SQL",
    "official_version": "0.0.7",
    "language": "C++",
    "maintainers": [
      "archiewood",
      "mharrisb1"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/gsheets/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "h3",
    "repository": "https://github.com/isaacbrodsky/h3-duckdb",
    "owner": "isaacbrodsky",
    "repo_name": "h3-duckdb",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "experimental",
        "source": "readme",
        "context": "| `h3_polygon_wkt_to_cells_experimental` | Convert polygon WKT to a set of cells, new alg"
      },
      {
        "keyword": "experimental",
        "source": "readme",
        "context": "| `h3_polygon_wkt_to_cells_experimental_string` | Convert polygon WKT to a set of cells,"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "[![Extension Test](https://github.com/isaacbrodsky/h3-duckdb/action"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "s/workflows/test.yml/badge.svg)](https://github.com/isaacbrodsky/h"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "3-duckdb/actions/workflows/test.yml)"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-26T22:15:45Z",
    "description": "Bindings for H3 to DuckDB",
    "readme_content": "[![Extension Test](https://github.com/isaacbrodsky/h3-duckdb/actions/workflows/test.yml/badge.svg)](https://github.com/isaacbrodsky/h3-duckdb/actions/workflows/test.yml)\n[![DuckDB Version](https://img.shields.io/static/v1?label=duckdb&message=v1.4.0&color=blue)](https://github.com/duckdb/duckdb/releases/tag/v1.4.0)\n[![H3 Version](https://img.shields.io/static/v1?label=h3&message=v4.3.0&color=blue)](https://github.com/uber/h3/releases/tag/v4.3.0)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)\n\nThis is a [DuckDB](https://duckdb.org) extension that adds support for the [H3 discrete global grid system](https://github.com/uber/h3/), so you can index points and geometries to hexagons in SQL.\n\n# Get started\n\nLoad from the [community extensions repository](https://community-extensions.duckdb.org/extensions/h3.html):\n```SQL\nINSTALL h3 FROM community;\nLOAD h3;\n```\n\nTest running an H3 function:\n```SQL\nSELECT h3_cell_to_latlng('822d57fffffffff');\n```\n\nOr, using t",
    "analysis_timestamp": "2025-09-27T14:44:03.868975",
    "metadata": {
      "extension": {
        "name": "h3",
        "description": "Hierarchical hexagonal indexing for geospatial data",
        "version": "1.4.0",
        "language": "C++",
        "build": "cmake",
        "license": "Apache-2.0",
        "maintainers": [
          "isaacbrodsky"
        ]
      },
      "repo": {
        "github": "isaacbrodsky/h3-duckdb",
        "ref": "48eeccef14178bce67a3e0e72189277534a8a382"
      },
      "docs": {
        "hello_world": "SELECT h3_latlng_to_cell(37.7887987, -122.3931578, 9);\n",
        "extended_description": "The H3 extension adds support for the [H3 hierarchical hexagonal grid system](https://h3geo.org/).\n"
      }
    },
    "official_description": "Hierarchical hexagonal indexing for geospatial data",
    "official_version": "1.4.0",
    "language": "C++",
    "maintainers": [
      "isaacbrodsky"
    ],
    "license": "Apache-2.0",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/h3/description.yml",
    "deprecation_score": 5.0,
    "recommendation": "POSSIBLY DEPRECATED - Manual review recommended"
  },
  {
    "extension": "hashfuncs",
    "repository": "https://github.com/query-farm/hashfuncs",
    "owner": "query-farm",
    "repo_name": "hashfuncs",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-26T22:18:01Z",
    "description": "A DuckDB extension that supplies non-cryptographic hash functions.",
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:03.974634",
    "metadata": {
      "docs": {
        "extended_description": "For more information regarding usage, see the [documentation](https://query.farm/duckdb_extension_hashfuncs.html).\n"
      },
      "extension": {
        "build": "cmake",
        "description": "Non-cryptographic hash functions, xxHash, rapidhash and Murmurhash3",
        "language": "C++",
        "license": "Apache-2.0",
        "maintainers": [
          "rustyconover"
        ],
        "name": "hashfuncs",
        "version": 2025091601
      },
      "repo": {
        "github": "query-farm/hashfuncs",
        "ref": "a4d74bb68e9fab243d257326a6e9da9945884c19"
      }
    },
    "official_description": "Non-cryptographic hash functions, xxHash, rapidhash and Murmurhash3",
    "official_version": 2025091601,
    "language": "C++",
    "maintainers": [
      "rustyconover"
    ],
    "license": "Apache-2.0",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/hashfuncs/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "hdf5",
    "repository": "https://github.com/Berrysoft/duckdb-hdf5",
    "owner": "Berrysoft",
    "repo_name": "duckdb-hdf5",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "FROM read_hdf5(\"example_file.h5\", \"dataset_name\");"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-08-07T07:29:26Z",
    "description": "HDF5 plugin for duckdb",
    "readme_content": "# DuckDB HDF5 extension\nThis is a community extension to read HDF5 files.\n\n## The `read_hdf5` function\nIt reads a dataset from an HDF5 file.\n```sql\nFROM read_hdf5(\"example_file.h5\", \"dataset_name\");\n```\n",
    "analysis_timestamp": "2025-09-27T14:44:04.077230",
    "metadata": {
      "extension": {
        "name": "hdf5",
        "description": "Read HDF5 files from DuckDB",
        "version": "0.1.3",
        "language": "Rust",
        "build": "cmake",
        "license": "MIT",
        "excluded_platforms": "windows_amd64_rtools;windows_amd64_mingw;linux_amd64_musl;wasm_mvp;wasm_eh;wasm_threads",
        "requires_toolchains": "rust;python3",
        "maintainers": [
          "Berrysoft"
        ]
      },
      "repo": {
        "github": "Berrysoft/duckdb-hdf5",
        "ref": "b814b5892ea233bed1544fbc4eec60cfebadea83"
      },
      "docs": {
        "hello_world": "FROM read_hdf5('some_file.h5', 'dataset');\n",
        "extended_description": "This extension provides a read function for HDF5 files.\n"
      }
    },
    "official_description": "Read HDF5 files from DuckDB",
    "official_version": "0.1.3",
    "language": "Rust",
    "maintainers": [
      "Berrysoft"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/hdf5/description.yml",
    "deprecation_score": 1.0,
    "recommendation": "MONITOR - Minor concerns detected"
  },
  {
    "extension": "highs",
    "repository": "https://github.com/fhk/highs-duckdb",
    "owner": "fhk",
    "repo_name": "highs-duckdb",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-08-16T06:41:18Z",
    "description": "Run the solver in the database!",
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:04.179480",
    "metadata": {
      "extension": {
        "name": "highs",
        "description": "HiGHS - High Performance Optimization Software",
        "version": "1.7.2",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "fhk"
        ]
      },
      "repo": {
        "github": "fhk/highs-duckdb",
        "ref": "0c343b5d3b54fb63231b445617eaff847dbdc719"
      },
      "docs": {
        "hello_world": "SELECT highs_version('Test');\n",
        "extended_description": "HiGHS is software for the definition, modification and solution of large scale sparse linear optimization models.\n\nHiGHS is freely available from [GitHub](https://github.com/ERGO-Code/HiGHS) under the MIT licence and has no third-party dependencies.\n"
      }
    },
    "official_description": "HiGHS - High Performance Optimization Software",
    "official_version": "1.7.2",
    "language": "C++",
    "maintainers": [
      "fhk"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/highs/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "hostfs",
    "repository": "https://github.com/gropaul/hostFS",
    "owner": "gropaul",
    "repo_name": "hostFS",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "Example 1: Navigate to the workspace and list the files."
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "Example 2: List the top 3 file types by total size, with"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "Example 3: Find the files you were working on last to con"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "./build/release/test/unittest"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "- `unittest` is the test runner of duckdb. Again, the extension is already"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "## Running the tests"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-03-10T22:28:46Z",
    "description": null,
    "readme_content": "\n<img src=\"https://github.com/user-attachments/assets/fa806574-9120-474f-8cb4-b17b1fbc3cd1\" width=250 />\n\n# HostFS\n![Dynamic JSON Badge](https://img.shields.io/badge/dynamic/json?url=https://tinyurl.com/duckstats&label=Downloads&color=blue&query=%24.hostfs)\n\nHostFS allows you to navigate and explore the host filesystem from DuckDB.\n\nInstall via \n```plaintext\nINSTALL hostfs FROM community;\nLOAD hostfs;\n```\n\nExample 1: Navigate to the workspace and list the files.\n```plaintext\nD PRAGMA cd('/Users/paul/workspace');\nD PRAGMA ls;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502             path              \u2502\n\u2502            varchar            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ./duckdb                      \u2502\n\u2502 ./playground                  \u2502\n\u2502 ./hostfs                      \u2502\n...\n```\nExample 2: List the top 3 file types by total size, with file count, ordered by size.\n```plaintext\nD SELECT size, count, file_extension AS \"type\"\n  FROM (\n      SELECT SUM(file_size(path)) AS size_raw, hsize(size_raw) AS si",
    "analysis_timestamp": "2025-09-27T14:44:04.282134",
    "metadata": {
      "extension": {
        "name": "hostfs",
        "description": "Navigate and explore the filesystem using SQL",
        "version": "0.0.2",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "Gropaul"
        ]
      },
      "repo": {
        "github": "gropaul/hostFS",
        "ref": "422dccbdbf5de509e03111ea78afe5f1c35fdde6"
      },
      "docs": {
        "hello_world": "-- Navigate to the workspace and list the files\nD PRAGMA cd('/Users/paul/workspace');\nD PRAGMA ls;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502             path              \u2502\n\u2502            varchar            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ./duckdb                      \u2502\n\u2502 ./playground                  \u2502\n\u2502 ./hostfs                      \u2502\n-- Find the files you were working on last\nD SELECT path, file_last_modified(path) AS date FROM ls() WHERE 'csv' IN file_extension(path) ORDER BY date LIMIT 1 ;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           path            \u2502        date         \u2502\n\u2502          varchar          \u2502      timestamp      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ./sketch_results_join.csv \u2502 2024-07-13 23:25:48 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n-- List the top 3 file types by total size, with file count, ordered by size.\nD SELECT size, count, file_extension AS \"type\"\nFROM (\nSELECT SUM(file_size(path)) AS size_raw, format_bytes(size_raw) AS size, COUNT(*) AS count, file_extension(path) AS file_extension\nFROM lsr('/Users/paul/workspace', 10)\nGROUP BY file_extension(path)\n) AS subquery\nORDER BY size_raw DESC LIMIT 3;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   size    \u2502 count \u2502  type   \u2502\n\u2502  varchar  \u2502 int64 \u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 246.95 GB \u2502    29 \u2502 .duckdb \u2502\n\u2502 90.33 GB  \u2502  3776 \u2502 .tmp    \u2502\n\u2502 26.17 GB  \u2502 28175 \u2502 .csv    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
        "extended_description": "The HostFS extension allows you to navigate and explore the filesystem using SQL. It provides a set of functions to list files, get file metadata, and more.  For more information, please see the [HostFS documentation](https://github.com/gropaul/hostFS)."
      }
    },
    "official_description": "Navigate and explore the filesystem using SQL",
    "official_version": "0.0.2",
    "language": "C++",
    "maintainers": [
      "Gropaul"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/hostfs/description.yml",
    "deprecation_score": 7.0,
    "recommendation": "POSSIBLY DEPRECATED - Manual review recommended"
  },
  {
    "extension": "http_client",
    "repository": "https://github.com/quackscience/duckdb-extension-httpclient",
    "owner": "quackscience",
    "repo_name": "duckdb-extension-httpclien",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": null,
    "description": "",
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:04.388400",
    "metadata": {
      "extension": {
        "name": "http_client",
        "description": "DuckDB HTTP Client Extension",
        "version": "0.0.8",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "excluded_platforms": "windows_amd64_mingw",
        "maintainers": [
          "lmangani",
          "ahuarte47",
          "Okabintaro"
        ]
      },
      "repo": {
        "github": "quackscience/duckdb-extension-httpclient",
        "ref": "d24cff6955d7d32cdcc12438b1deea9b6656be05"
      },
      "docs": {
        "hello_world": "-- GET Request Example w/ JSON Parsing\nWITH __input AS (\n  SELECT\n    http_get(\n        'https://httpbin.org/delay/0',\n        headers => MAP {\n          'accept': 'application/json',\n        },\n        params => MAP {\n          'limit': 1\n        }\n    ) AS res\n),\n__response AS (\n  SELECT\n    (res->>'status')::INT AS status,\n    (res->>'reason') AS reason,\n    unnest( from_json(((res->>'body')::JSON)->'headers', '{\"Host\": \"VARCHAR\"}') ) AS features\n  FROM\n    __input\n)\nSELECT\n  __response.status,\n  __response.reason,\n  __response.Host AS host\nFROM\n  __response\n;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 status \u2502 reason  \u2502    host     \u2502\n\u2502 int32  \u2502 varchar \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    200 \u2502 OK      \u2502 httpbin.org \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- POST Request Example w/ Headers and Parameters\nWITH __input AS (\nSELECT\n  http_post(\n      'https://httpbin.org/delay/0',\n      headers => MAP {\n        'accept': 'application/json',\n      },\n      params => MAP {\n        'limit': 1\n      }\n  ) AS res\n),\n__response AS (\n  SELECT\n    (res->>'status')::INT AS status,\n    (res->>'reason') AS reason,\n    unnest( from_json(((res->>'body')::JSON)->'headers', '{\"Host\": \"VARCHAR\"}') ) AS features\n  FROM\n    __input\n)\nSELECT\n  __response.status,\n  __response.reason,\n  __response.Host AS host,\nFROM\n  __response\n;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 status \u2502 reason  \u2502    host     \u2502\n\u2502 int32  \u2502 varchar \u2502   varchar   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    200 \u2502 OK      \u2502 httpbin.org \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
        "extended_description": "The HTTP Client Extension is experimental, use at your own risk!\n"
      }
    },
    "official_description": "DuckDB HTTP Client Extension",
    "official_version": "0.0.8",
    "language": "C++",
    "maintainers": [
      "lmangani",
      "ahuarte47",
      "Okabintaro"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/http_client/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "httpserver",
    "repository": "https://github.com/Query-farm/duckdb-extension-httpserver",
    "owner": "Query-farm",
    "repo_name": "duckdb-extension-httpserver",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": null,
    "description": null,
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:04.491127",
    "metadata": {
      "extension": {
        "name": "httpserver",
        "description": "DuckDB HTTP API Server Extension",
        "version": "0.1.9",
        "language": "SQL & C++",
        "build": "cmake",
        "license": "MIT",
        "excluded_platforms": "wasm_mvp;wasm_eh;wasm_threads",
        "maintainers": [
          "lmangani",
          "akvlad",
          "niclashaderer",
          "gropaul",
          "rustyconover"
        ]
      },
      "repo": {
        "github": "Query-farm/duckdb-extension-httpserver",
        "ref": "5ec9292017d03348cf4e91eb2f9cf23c9719a891"
      },
      "docs": {
        "hello_world": "-- Start a DuckDB HTTP API Server with parameters\nD SELECT httpserve_start('0.0.0.0', 9999, 'user:pass');\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 httpserve_start('0.0.0.0', 9999, 'user:pass') \u2502\n\u2502                    varchar                    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 HTTP server started on 0.0.0.0:9999           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- Browse to your DuckDB HTTP API endpoint to Query using the embedded interface\n\n-- Query your DuckDB HTTP API Server using curl or any other client w/ HTTP Basic Auth\ncurl -X POST -d \"LOAD chsql; SELECT *, uuid() FROM numbers(10)\" \"http://user:pass@localhost:9999/\"\n\n-- Query your DuckDB HTTP API Server using curl or any other client w/ X-API-Key header \ncurl -X POST --header \"X-API-Key: secretkey\" -d \"LOAD chsql; SELECT *, uuid() FROM numbers(10)\" \"http://localhost:9999/\"\n\n-- Query your DuckDB HTTP API Server using DuckDB HTTPFS extension w/ Header Authentication\nD CREATE SECRET extra_http_headers (\n  TYPE HTTP,\n  EXTRA_HTTP_HEADERS MAP{\n      'X-API-Key': 'secretkey'\n  }\n);\n\n-- DuckDB API Server settings\n* If you want no authentication, just pass an empty string as parameter.\n* If you want the API run in foreground set `DUCKDB_HTTPSERVER_FOREGROUND=1`\n* If you want logs set `DUCKDB_HTTPSERVER_DEBUG=1` or `DUCKDB_HTTPSERVER_SYSLOG=1`\n\n![image info](https://private-user-images.githubusercontent.com/1423657/376339324-e930a8d2-b3e4-454e-ba12-e5e91b30bfbe.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzMzNDI2MTksIm5iZiI6MTczMzM0MjMxOSwicGF0aCI6Ii8xNDIzNjU3LzM3NjMzOTMyNC1lOTMwYThkMi1iM2U0LTQ1NGUtYmExMi1lNWU5MWIzMGJmYmUucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MTIwNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDEyMDRUMTk1ODM5WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZjI5OTEwZGNhM2NhZGI4NDJiYTE5ZmM1ZWIzZDE4OTBkZDY3ODBkMTkxM2E1ZWNiMjRmZDAzNzlkOWEyMjVmMiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.iCK1p26RFbEjMWPyG5i8XmhPyzUn8J9cCsm1N1T8y5E)\n",
        "extended_description": "<img src=\"https://github.com/user-attachments/assets/46a5c546-7e9b-42c7-87f4-bc8defe674e0\" width=250 />\n\n# DuckDB HTTP Server Extension\nThis extension transforms **DuckDB** instances into tiny multi-player **HTTP OLAP API** services.<br>\nSupports Authentication _(Basic Auth or X-Token)_ and includes the _play_ SQL user interface.\n    \n### Features\n\n- Turn any [DuckDB](https://duckdb.org) instance into an **HTTP OLAP API** Server\n- Use the embedded **Web User Interface** to query and visualize data \n- Work with local and remote datasets including [MotherDuck](https://motherduck.com) \ud83d\udc24\n- _100% Opensource, ready to use and extend by the Community!_\n\n> This extension is experimental and potentially unstable. Use at your own risk.\n\n> This DuckDB extension was created by Query.Farm, where we develop and maintain many extensions that expand DuckDB\u2019s capabilities by connecting it to new data sources, formats, and features.\n"
      }
    },
    "official_description": "DuckDB HTTP API Server Extension",
    "official_version": "0.1.9",
    "language": "SQL & C++",
    "maintainers": [
      "lmangani",
      "akvlad",
      "niclashaderer",
      "gropaul",
      "rustyconover"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/httpserver/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "jwt",
    "repository": "https://github.com/GalvinGao/duckdb_jwt",
    "owner": "GalvinGao",
    "repo_name": "duckdb_jw",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": null,
    "description": "",
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:04.943449",
    "metadata": {
      "extension": {
        "name": "jwt",
        "description": "Decode and work with JWT (JSON Web Token) in SQL queries",
        "version": "0.0.1",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "GalvinGao"
        ]
      },
      "repo": {
        "github": "GalvinGao/duckdb_jwt",
        "ref": "9511967148dd532b45e4088182501187559f1829"
      },
      "docs": {
        "decode_jwt": "-- Decode a JWT token payload\nSELECT jwt_decode_payload('eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c') AS payload;\n",
        "extract_claim": "-- Extract the 'sub' claim from a JWT token\nSELECT \n  json_extract(\n    jwt_decode_payload('eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c'),\n    '$.sub'\n  ) AS subject;\n",
        "extended_description": "The JWT extension provides functionality to decode and work with JWT (JSON Web Token) directly in DuckDB SQL queries. \n\n## Features\n\n- `jwt_decode_payload(token)`: Decodes the payload part of a JWT token and returns it as a JSON string\n- Base64 URL-safe decoding for JWT token components\n\n## Use Cases\n\n- Analyzing JWT tokens in your data\n- Extracting claims from authentication tokens\n- Debugging JWT-based authentication systems\n- Working with JWT tokens in data pipelines\n\nYou can combine the JWT functions with DuckDB's built-in JSON functionality to extract specific claims from tokens. "
      }
    },
    "official_description": "Decode and work with JWT (JSON Web Token) in SQL queries",
    "official_version": "0.0.1",
    "language": "C++",
    "maintainers": [
      "GalvinGao"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/jwt/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "lindel",
    "repository": "https://github.com/query-farm/lindel",
    "owner": "query-farm",
    "repo_name": "lindel",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "TO 'example.parquet' (FORMAT PARQUET)"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": ") TO 'example.parquet' (FORMAT PARQUET)"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "### Encoding examples"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "./build/release/test/unittest"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "- `unittest` is the test runner of duckdb. Again, the extension is already"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "## Running the tests"
      }
    ],
    "active_indicators": [
      {
        "keyword": "stable",
        "source": "readme",
        "context": "rustup toolchain install stable"
      },
      {
        "keyword": "stable",
        "source": "readme",
        "context": "# Use rustc stable version by default"
      },
      {
        "keyword": "stable",
        "source": "readme",
        "context": "rustup default stable"
      }
    ],
    "repository_archived": false,
    "last_push": "2025-09-26T22:18:12Z",
    "description": "DuckDB Extension Linearization/Delinearization, Z-Order, Hilbert and Morton Curves",
    "readme_content": "# Lindel (linearizer-delinearizer) Extension for DuckDB\n\n![Ducks filling Space-Filling Curves](./docs/space-filling-curve-ducks.jpg)\n\nThis `lindel` extension adds functions for the [linearization](https://en.wikipedia.org/wiki/Linearization) and delinearization of numeric arrays in [DuckDB](https://www.duckdb.org).  It allows you to order multi-dimensional data using space-filling curves.\n\n## Installation\n\n**`lindel` is a [DuckDB Community Extension](https://github.com/duckdb/community-extensions).**\n\nYou can now use this by using this SQL:\n\n```sql\ninstall lindel from community;\nload lindel;\n```\n\n## What is linearization?\n\n<image align=\"right\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/7/7c/Hilbert-curve_rounded-gradient-animated.gif/440px-Hilbert-curve_rounded-gradient-animated.gif\" alt=\"An animation of the Hilbert Curve from Wikipedia\" width=\"200px\"/>\n\n[Linearization](https://en.wikipedia.org/wiki/Linearization) maps multi-dimensional data into a one-dimensional sequen",
    "analysis_timestamp": "2025-09-27T14:44:05.045919",
    "metadata": {
      "docs": {
        "extended_description": "For more information regarding usage, see the [documentation](https://query.farm/duckdb_extension_lindel.html).\n"
      },
      "extension": {
        "build": "cmake",
        "description": "Linearization/Delinearization, Z-Order, Hilbert and Morton Curves",
        "language": "C++",
        "license": "Apache-2.0",
        "maintainers": [
          "rustyconover"
        ],
        "name": "lindel",
        "requires_toolchains": "rust",
        "excluded_platforms": "wasm_mvp;wasm_eh;wasm_threads",
        "version": 2025091601
      },
      "repo": {
        "github": "query-farm/lindel",
        "ref": "8f7bf33a11062a071f129ec0ff9e8c8cda045d00"
      }
    },
    "official_description": "Linearization/Delinearization, Z-Order, Hilbert and Morton Curves",
    "official_version": 2025091601,
    "language": "C++",
    "maintainers": [
      "rustyconover"
    ],
    "license": "Apache-2.0",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/lindel/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "lua",
    "repository": "https://github.com/isaacbrodsky/duckdb-lua",
    "owner": "isaacbrodsky",
    "repo_name": "duckdb-lua",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "cy management, just skip this step. Note that the example extension uses VCPKG to build with a dependency f"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "[![Extension Test](https://github.com/isaacbrodsky/duckdb-lua/actio"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "./build/release/test/unittest"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "- `unittest` is the test runner of duckdb. Again, the extension is already"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-17T03:46:00Z",
    "description": "DuckDB extension to evaluate Lua expressions.",
    "readme_content": "[![Extension Test](https://github.com/isaacbrodsky/duckdb-lua/actions/workflows/MainDistributionPipeline.yml/badge.svg)](https://github.com/isaacbrodsky/duckdb-lua/actions/workflows/MainDistributionPipeline.yml)\n[![DuckDB Version](https://img.shields.io/static/v1?label=duckdb&message=v1.4.0&color=blue)](https://github.com/duckdb/duckdb/releases/tag/v1.4.0)\n[![Lua Version](https://img.shields.io/static/v1?label=lua&message=v5.4.8&color=blue)](https://lua.org/home.html)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)\n\n# Lua\n\nThis extension adds the embedded scripting language [Lua](https://lua.org) to [DuckDB](https://duckdb.org/). Lua is a powerful, small, embedded, and free scripting language.\n\nInstall via community extensions:\n\n```sql\nINSTALL lua FROM community; -- First time only\nLOAD loa;\n```\n\nEvaluate a Lua expression in SQL:\n```sql\nSELECT lua('return \"aa\" .. context', \"bb\");\n```\n\nReturns `\"aabb\"`.\n\nFor the context parameter, you can pass in string",
    "analysis_timestamp": "2025-09-27T14:44:05.159604",
    "metadata": {
      "extension": {
        "name": "lua",
        "description": "Evaluate Lua scripts within queries",
        "version": "1.4.0",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "isaacbrodsky"
        ]
      },
      "repo": {
        "github": "isaacbrodsky/duckdb-lua",
        "ref": "f37579669ddc8ba23fb3a9c0123dd448c72f0bf4"
      },
      "docs": {
        "hello_world": "SELECT lua('return \"Hello \" .. context', \"World\");\n",
        "extended_description": "Adds support for the Lua embedded scripting language to DuckDB.\n"
      }
    },
    "official_description": "Evaluate Lua scripts within queries",
    "official_version": "1.4.0",
    "language": "C++",
    "maintainers": [
      "isaacbrodsky"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/lua/description.yml",
    "deprecation_score": 4.0,
    "recommendation": "REVIEW - Some deprecation indicators found"
  },
  {
    "extension": "magic",
    "repository": "https://github.com/carlopi/duckdb_magic",
    "owner": "carlopi",
    "repo_name": "duckdb_magic",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "Example, discover which mime_types is a given [remote] fi"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "Example, read any file with autodetection (on the content"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "ubusercontent.com/duckdb/duckdb/main/data/parquet-testing/adam_genotypes.parquet');"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "ubusercontent.com/duckdb/duckdb/main/data/parquet-testing/adam_genotypes.parquet');"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-22T08:48:10Z",
    "description": "Auto-detect file types via `libmagic` (`file` utility)",
    "readme_content": "# magic\n\nThis extension, Magic, allow you to examine files and determine their type, based on https://man7.org/linux/man-pages/man3/libmagic.3.html linux utility.\n\n\n```sql\n--- Install (once)\nINSTALL magic FROM community;\n\n--- Update (to check for updates)\nUPDATE EXTENSIONS (magic);\n\n--- Load\nLOAD magic;\n```\n\nExample, discover which mime_types is a given [remote] file[s]:\n```sql\n--- Discover autodetected types for files in your current folder\nSELECT magic_mime(file), magic_type(file), file\n    FROM glob('*');\n\n--- Needs to be performed once per session to query remote files\nLOAD httpfs;\n\n--- Discover autodetected types for a remote file\nSELECT magic_mime(file), magic_type(file), file\n    FROM glob('https://raw.githubusercontent.com/duckdb/duckdb/main/data/parquet-testing/adam_genotypes.parquet');\n```\n\nExample, read any file with autodetection (on the content or the name):\n```sql\n--- Needs to be performed once per session to query remote files\nLOAD httpfs;\n\nFROM read_any('https://raw.git",
    "analysis_timestamp": "2025-09-27T14:44:05.264039",
    "metadata": {
      "extension": {
        "name": "magic",
        "description": "libmagic/file utilities ported to DuckDB",
        "version": "0.0.1",
        "language": "C++",
        "build": "cmake",
        "excluded_platforms": "linux_amd64_musl;windows_amd64_rtools;windows_amd64_mingw;windows_amd64",
        "license": "MIT",
        "maintainers": [
          "carlopi"
        ]
      },
      "repo": {
        "github": "carlopi/duckdb_magic",
        "ref": "6a214b48b6dc760e398c73131e00ee62f2c5f1bc"
      },
      "docs": {
        "hello_world": "--- Discover autodetected types for files in a local folder\nSELECT magic_mime(file), magic_type(file), file\n    FROM glob('path/to/folder/**');\n\n--- Discover autodetected types for a remote file\nLOAD httpfs;  --- this needs to currently be explcit once per session\nSELECT magic_mime(file), magic_type(file), file\n    FROM glob('https://raw.githubusercontent.com/duckdb/duckdb/main/data/parquet-testing/adam_genotypes.parquet');\n\n--- Read file without providing detail on type\nFROM read_any('https://raw.githubusercontent.com/duckdb/duckdb/main/data/parquet-testing/adam_genotypes.parquet');\n",
        "extended_description": "Very experimental port of libmagic (that powers file UNIX utility), allow to classify files based on the content of the header, accoring to the libmagic library.\nPackaged with version 5.45 of the magic library. The magic.mgc database is at the moment statically compiled in the library, so it's the same across platforms but immutable.\nCurrently not available in Windows and Wasm, due to different but likely solvable vc-packaging issue, to be sorted out independently.\n"
      }
    },
    "official_description": "libmagic/file utilities ported to DuckDB",
    "official_version": "0.0.1",
    "language": "C++",
    "maintainers": [
      "carlopi"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/magic/description.yml",
    "deprecation_score": 4.0,
    "recommendation": "REVIEW - Some deprecation indicators found"
  },
  {
    "extension": "marisa",
    "repository": "https://github.com/query-farm/marisa",
    "owner": "query-farm",
    "repo_name": "marisa",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-26T22:18:22Z",
    "description": "The Marisa extension by Query.Farm integrates the fast, space-efficient MARISA trie into DuckDB, enabling high-performance string lookups, prefix searches, and autocomplete functionality.",
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:05.367308",
    "metadata": {
      "docs": {
        "extended_description": "For more information regarding usage, see the [documentation](https://query.farm/duckdb_extension_marisa.html).\n"
      },
      "extension": {
        "build": "cmake",
        "description": "Adds MARISA (Matching Algorithm with Recursively Implemented StorAge) trie functionality for DuckDB. MARISA is a static and space-efficient trie data structure that enables fast string lookups, prefix searches, and predictive text operations.",
        "language": "C++",
        "license": "MIT",
        "maintainers": [
          "rustyconover"
        ],
        "name": "marisa",
        "version": 2025091601
      },
      "repo": {
        "github": "query-farm/marisa",
        "ref": "2092f5c0e46aa9fd896bbdd4ff385fb46cec1632"
      }
    },
    "official_description": "Adds MARISA (Matching Algorithm with Recursively Implemented StorAge) trie functionality for DuckDB. MARISA is a static and space-efficient trie data structure that enables fast string lookups, prefix searches, and predictive text operations.",
    "official_version": 2025091601,
    "language": "C++",
    "maintainers": [
      "rustyconover"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/marisa/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "markdown",
    "repository": "https://github.com/teaguesterling/duckdb_markdown",
    "owner": "teaguesterling",
    "repo_name": "duckdb_markdown",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "len(md_extract_code_blocks(content)) as code_examples,"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "### Document Processing Examples"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "-- Find all Python examples in documentation"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "make test"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "SELECT md_stats('# Test\\nContent');  -- VARCHAR automatically cast to MAR"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "- Full test suite with 218+ passing assertions"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-07-10T23:23:13Z",
    "description": "Heirarchical markdown parsing for DuckDB",
    "readme_content": "# DuckDB Markdown Extension\n\nThis extension adds Markdown processing capabilities to DuckDB, enabling structured analysis of Markdown documents and content extraction for documentation analysis, content auditing, and knowledge base processing.\n\n## Features\n\n- **Markdown Content Extraction**: Extract code blocks, links, images, and tables from Markdown text\n- **Documentation Analysis**: Analyze large documentation repositories with SQL queries\n- **Cross-Platform Support**: Works on Linux, macOS, and WebAssembly (Windows support in development)\n- **GitHub Flavored Markdown**: Uses cmark-gfm for accurate parsing of modern Markdown\n- **High Performance**: Process thousands of documents efficiently with robust glob pattern support\n\n## Installation\n\n### Loading the Extension\n\n```sql\n-- Install from community extensions (when available)\nINSTALL markdown FROM community;\nLOAD markdown;\n```\n\n### Building from Source\n\n```bash\ngit clone https://github.com/teaguesterling/duckdb_markdown\ncd duckdb_m",
    "analysis_timestamp": "2025-09-27T14:44:05.469991",
    "metadata": {
      "extension": {
        "name": "markdown",
        "description": "Read and analyze Markdown files with comprehensive content extraction and document processing capabilities",
        "version": "1.0.0",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "teaguesterling"
        ],
        "vcpkg_commit": "bffcbb75f71553824aa948a7e7b4f798662a6fa7"
      },
      "repo": {
        "github": "teaguesterling/duckdb_markdown",
        "ref": "main"
      },
      "docs": {
        "hello_world": "-- Load the extension\nLOAD markdown;\n\n-- Read Markdown files with glob patterns\nSELECT content FROM read_markdown('docs/**/*.md');\n\n-- Read documentation sections with hierarchy\nSELECT title, level, content \nFROM read_markdown_sections('README.md', include_content := true);\n\n-- Extract code blocks from Markdown text\nSELECT cb.language, cb.code \nFROM (\n  SELECT UNNEST(md_extract_code_blocks('```python\\nprint(\"Hello, World!\")\\n```')) as cb\n);\n\n-- Analyze documentation repositories\nSELECT \n  len(md_extract_code_blocks(content)) as code_examples,\n  len(md_extract_links(content)) as external_links,\n  len(md_extract_images(content)) as images\nFROM read_markdown('**/*.md');\n\n-- Use replacement scan syntax for convenience\nSELECT * FROM '*.md';\nSELECT * FROM 'docs/**/*.md';\n",
        "extended_description": "The Markdown extension adds comprehensive Markdown processing capabilities to DuckDB, enabling structured analysis of Markdown documents and content extraction for documentation analysis, content auditing, and knowledge base processing.\n\n**Key Features:**\n\n- **File Reading Functions**: Read Markdown files with `read_markdown()` and `read_markdown_sections()` supporting glob patterns, metadata extraction, and hierarchical section parsing\n- **Content Extraction**: Extract code blocks, links, images, and tables from Markdown content using structured LIST<STRUCT> return types\n- **Document Processing**: Convert markdown to HTML/text, validate content, extract metadata, and generate document statistics\n- **Replacement Scan Support**: Query Markdown files directly using `FROM '*.md'` syntax with full glob pattern support\n- **Native MARKDOWN Type**: Custom MARKDOWN type with automatic VARCHAR casting for seamless integration\n- **Cross-Platform Support**: Works on Linux, macOS, and WebAssembly (Windows support in development)\n- **GitHub Flavored Markdown**: Uses cmark-gfm for accurate parsing of modern Markdown features\n- **High Performance**: Process thousands of documents efficiently with 4,000+ sections/second processing rate\n- **Comprehensive Parameter System**: Flexible file processing with customizable options for content inclusion, size limits, and metadata extraction\n\n**Core Functions:**\n\n- `read_markdown()` - Read Markdown files with comprehensive parameter support\n- `read_markdown_sections()` - Parse files into hierarchical sections with filtering options\n- `md_extract_code_blocks()` - Extract code blocks with language and metadata\n- `md_extract_links()` - Extract links with text, URL, and title information\n- `md_extract_images()` - Extract images with alt text and metadata\n- `md_extract_tables_json()` - Extract tables as structured JSON\n- `md_to_html()` - Convert markdown content to HTML\n- `md_to_text()` - Convert markdown to plain text for full-text search\n- `md_stats()` - Get document statistics (word count, reading time, etc.)\n- `md_extract_metadata()` - Extract frontmatter metadata as JSON\n\n**Example Use Cases:**\n\n- Documentation analysis across entire repositories\n- Content quality assessment and auditing\n- Large-scale documentation search and indexing\n- Code example extraction and analysis\n- Link validation and external reference tracking\n- Knowledge base processing and content management\n- Technical writing analytics and reporting\n\n**Performance Benchmarks:**\n\nReal-world performance: Processing 287 Markdown files (2,699 sections, 1,137 code blocks, 1,174 links) in 603ms on typical hardware.\n\nThe extension is built using cmark-gfm and includes a comprehensive test suite with 218+ passing assertions, ensuring reliable performance and accuracy for production use.\n"
      }
    },
    "official_description": "Read and analyze Markdown files with comprehensive content extraction and document processing capabilities",
    "official_version": "1.0.0",
    "language": "C++",
    "maintainers": [
      "teaguesterling"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/markdown/description.yml",
    "deprecation_score": 6.0,
    "recommendation": "POSSIBLY DEPRECATED - Manual review recommended"
  },
  {
    "extension": "mooncake",
    "repository": "https://github.com/Mooncake-Labs/duckdb_mooncake",
    "owner": "Mooncake-Labs",
    "repo_name": "duckdb_mooncake",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "The example below attaches to the moonlink database `'postgre"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-19T03:19:58Z",
    "description": "Read Iceberg tables written by moonlink in real time",
    "readme_content": "# duckdb_mooncake\n\nduckdb_mooncake is a DuckDB extension to read Iceberg tables written by [moonlink][moonlink-link] in real time.\n\n## Installation\n\nduckdb_mooncake can be installed using the `INSTALL` command:\n```sql\nINSTALL duckdb_mooncake FROM community;\n```\n\n## Usage\n\nMooncake databases can be attached using the `ATTACH` command, after which tables can be queried using standard SQL.\n\nThe example below attaches to the moonlink database `'postgres'`, from a moonlink instance listening at `'/var/lib/postgresql/data/pg_mooncake/moonlink.sock'`. This moonlink instance comes prepopulated with a table named `public.c`:\n```sql\nD ATTACH DATABASE 'mooncake' (TYPE mooncake, URI '/var/lib/postgresql/data/pg_mooncake/moonlink.sock', DATABASE 'postgres');\nD SELECT * FROM mooncake.public.c;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  id   \u2502   val   \u2502\n\u2502 int32 \u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     1 \u2502 Hello   \u2502\n\u2502     2 \u2502 World   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n## Building\n\nTo build, type:\n```\ngit submodule update --init --r",
    "analysis_timestamp": "2025-09-27T14:44:05.579598",
    "metadata": {
      "extension": {
        "name": "mooncake",
        "description": "Read Iceberg tables written by moonlink in real time",
        "version": "0.0.1",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "dpxcc"
        ],
        "excluded_platforms": "windows_amd64;windows_amd64_mingw;wasm_mvp;wasm_eh;wasm_threads",
        "requires_toolchains": "rust"
      },
      "repo": {
        "github": "Mooncake-Labs/duckdb_mooncake",
        "ref": "d30535457a6a2fbdecb5b0cd869b543606902fc6"
      },
      "docs": {
        "hello_world": "ATTACH DATABASE 'mooncake' (TYPE mooncake, URI '/var/lib/postgresql/data/pg_mooncake/moonlink.sock', DATABASE 'postgres');\nSELECT * FROM mooncake.public.c;\n",
        "extended_description": "For more information regarding usage, see [README.md](https://github.com/Mooncake-Labs/duckdb_mooncake/blob/v0.0.1/README.md).\n"
      }
    },
    "official_description": "Read Iceberg tables written by moonlink in real time",
    "official_version": "0.0.1",
    "language": "C++",
    "maintainers": [
      "dpxcc"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/mooncake/description.yml",
    "deprecation_score": 1.0,
    "recommendation": "MONITOR - Minor concerns detected"
  },
  {
    "extension": "msolap",
    "repository": "https://github.com/Hugoberry/duckdb-msolap-extension",
    "owner": "Hugoberry",
    "repo_name": "duckdb-msolap-extension",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-24T16:33:46Z",
    "description": null,
    "readme_content": "# MSOLAP Scanner Extension for DuckDB\n\nThis extension allows DuckDB to connect to Microsoft SQL Server Analysis Services (SSAS) and other OLAP data sources using the MSOLAP provider. It enables querying multidimensional and tabular models with DAX queries directly from DuckDB.\n\n## Features\n\n- Connect to MSOLAP sources (SSAS, Power BI, etc.)\n- Scan tables/cubes from OLAP databases\n- Execute raw DAX queries\n\n## Requirements\n\n- Windows environment (due to MSOLAP COM dependencies)\n- Microsoft OLEDB provider for Analysis Services installed `MSOLAP.8`\n- DuckDB development environment\n\n## Building\n\n1. Clone this repository\n2. Make sure you have DuckDB development environment set up\n3. Build the extension using CMake:\n\n```bash\nmkdir build\ncd build\ncmake ..\ncmake --build . --config Release\n```\nor given repo location `c:/git/hub/duckdb-msolap-extension/`\n```bash\nmake release -e EXT_CONFIG='c:/git/hub/duckdb-msolap-extension/extension_config.cmake'\n```\n## Installation\n\n```sql\nINSTALL msolap FROM ",
    "analysis_timestamp": "2025-09-27T14:44:05.682117",
    "metadata": {
      "extension": {
        "name": "msolap",
        "description": "Extension that allows DuckDB to connect to Microsoft SQL Server Analysis Services (SSAS) and other OLAP data sources using the MSOLAP provider",
        "version": "0.1.2",
        "language": "C++",
        "build": "cmake",
        "excluded_platforms": "linux_arm64;linux_amd64_musl;osx_amd64;osx_arm64;wasm_mvp;wasm_eh;wasm_threads;windows_amd64_mingw",
        "license": "MIT",
        "maintainers": [
          "Hugoberry"
        ]
      },
      "repo": {
        "github": "Hugoberry/duckdb-msolap-extension",
        "ref": "84e1b00e2e42a905c0efd5eb55f8bef1cefa6173"
      },
      "docs": {
        "hello_world": "-- Execute a simple DAX query against a local SSAS instance\nSELECT * FROM msolap('Data Source=localhost;Catalog=AdventureWorks', 'EVALUATE DimProduct');\n\n-- Execute a more complex DAX query against PowerBI Desktop instance\nSELECT * FROM msolap('Data Source=localhost:61324;Catalog=0ec50266-bdf5-4582-bc8c-82584866bcb7', \n'EVALUATE\nSUMMARIZECOLUMNS(\n    DimProduct[Color],\n    \"Total Sales\", SUM(FactInternetSales[SalesAmount])\n)');\n",
        "extended_description": "The MSOLAP extension allows DuckDB to connect to Microsoft SQL Server Analysis Services (SSAS) and other OLAP data sources using the MSOLAP provider. It enables multidimensional and tabular models with DAX queries to be queried directly from DuckDB.\n\nThe extension provides one primary function: - `msolap(connection_string, dax_query)`: Execute a custom DAX query against an OLAP source\n\nThis extension is handy for data analysts who work with the Microsoft Business Intelligence stack (SSAS, Power BI) and want to incorporate this data into their DuckDB workflows.\n\n*Note:* Current limitations include Windows-only support due to COM dependencies, limited data type conversion for complex OLAP types, and limited support for calculated measures and hierarchies. The extension requires the installation of the Microsoft OLEDB provider for Analysis Services (MSOLAP.8).\n"
      }
    },
    "official_description": "Extension that allows DuckDB to connect to Microsoft SQL Server Analysis Services (SSAS) and other OLAP data sources using the MSOLAP provider",
    "official_version": "0.1.2",
    "language": "C++",
    "maintainers": [
      "Hugoberry"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/msolap/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "nanoarrow",
    "repository": "https://github.com/paleolimbot/duckdb-nanoarrow",
    "owner": "paleolimbot",
    "repo_name": "duckdb-nanoarrow",
    "status": "analyzed",
    "deprecation_indicators": [
      {
        "keyword": "deprecated",
        "source": "readme",
        "context": "and files. It serves a similar purpose as the now-deprecated [Arrow DuckDB core extension](https://github.com/"
      }
    ],
    "warning_indicators": [
      {
        "keyword": "demo",
        "source": "readme",
        "context": "In this section, we will demonstrate how to use the Python API, but you can fin"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "Below is a complete example of how to use our extension to read an Arrow IPC"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "s done using the COPY statement Below is a simple example of how you can use DuckDB to create such a file."
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "sume the file using the `read_arrow` scanner. For example, to read the file we just created, you could run:"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "ality to query Arrow IPC files and is much better tested. This extension is released as a DuckDB Communi"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "980\u2026  \u2502 GH-20127: [Python][CI] Remove legacy hdfs tests from hdfs and hypothesis setup (#40363)   \u2502"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "45ad491af98a5bf18\u2026  \u2502 GH-40153: [C++][Python] Fix test_gdb failures on 32-bit (#40293)"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-17T18:31:44Z",
    "description": null,
    "readme_content": "# nanoarrow for DuckDB\n\nThis extension, nanoarrow, allows you to read Arrow IPC streams and files. It serves a similar purpose as the now-deprecated [Arrow DuckDB core extension](https://github.com/duckdb/arrow).\nHowever, it comes with the added functionality to query Arrow IPC files and is much better tested. This extension is released as a DuckDB Community Extension.\nFor compatibility reasons with the previous Arrow core extension, this extension is also aliased as `arrow`.\n\nYou can install and load it as:\n\n```sql\n-- arrow would also be a suitable name\nINSTALL nanoarrow FROM community;\nLOAD nanoarrow;\n```\n\n## Usage\nBelow is a complete example of how to use our extension to read an Arrow IPC file.\nIn addition to our extension, you will also need the `httpfs` extension installed and loaded to fetch the data directly from GitHub.\n\n```sql\nLOAD httpfs;\nLOAD nanoarrow;\nSELECT\n    commit, message\n  FROM\n    'https://github.com/apache/arrow-experiments/raw/refs/heads/main/data/arrow-commits/",
    "analysis_timestamp": "2025-09-27T14:44:05.783667",
    "metadata": {
      "extension": {
        "name": "nanoarrow",
        "description": "Allows the consumption and production of the Apache Arrow interprocess communication (IPC) format, both from files and directly from stream buffers.",
        "version": "1.4.0",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "paleolimbot",
          "pdet",
          "evertlammerts"
        ]
      },
      "repo": {
        "github": "paleolimbot/duckdb-nanoarrow",
        "ref": "81ec79bc35090c65f6a7c9066bd373b5dd3b7e73"
      },
      "docs": {
        "hello_world": "-- Read from a file in Arrow IPC format\nFROM 'arrow_file.arrow';\nFROM 'arrow_file.arrows';\nFROM read_arrow('arrow_file.arrow');\n\n-- Write a file in Arrow IPC stream format\nCREATE TABLE arrow_libraries AS SELECT 'nanoarrow' as name, '0.6' as version;\nCOPY arrow_libraries TO 'test.arrows' (FORMAT ARROWS, BATCH_SIZE 100);\n\n-- Write to buffers: This returns IPC message BLOBs and indicates which one is the header.\nFROM to_arrow_ipc((FROM arrow_libraries));\n",
        "extended_description": "The Arrow IPC library allows users to read and write data in the Arrow IPC stream format. \nThis can be done by either reading and producing `.arrow` files or by directly reading buffers using their pointers and sizes. \nIt is important to note that reading buffers is dangerous, as an incorrect pointer can crash the database system. \nThis process is temporary and will be deprecated in the future, as clients (e.g., the Python DuckDB client) will have a function that internally extracts these buffers from an Arrow stream.\n"
      }
    },
    "official_description": "Allows the consumption and production of the Apache Arrow interprocess communication (IPC) format, both from files and directly from stream buffers.",
    "official_version": "1.4.0",
    "language": "C++",
    "maintainers": [
      "paleolimbot",
      "pdet",
      "evertlammerts"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/nanoarrow/description.yml",
    "deprecation_score": 10.0,
    "recommendation": "LIKELY DEPRECATED - High confidence"
  },
  {
    "extension": "nanodbc",
    "repository": "https://github.com/Hugoberry/duckdb-nanodbc-extension",
    "owner": "Hugoberry",
    "repo_name": "duckdb-nanodbc-extension",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-24T19:44:52Z",
    "description": null,
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:05.896703",
    "metadata": {
      "extension": {
        "name": "nanodbc",
        "description": "Connect to any ODBC-compatible database and query data directly from DuckDB",
        "version": "0.3.3",
        "language": "C++",
        "build": "cmake",
        "excluded_platforms": "linux_amd64_musl;osx_amd64;wasm_mvp;wasm_eh;wasm_threads",
        "license": "MIT",
        "maintainers": [
          "Hugoberry"
        ]
      },
      "repo": {
        "github": "Hugoberry/duckdb-nanodbc-extension",
        "ref": "22897668b2cca0fdf76d585afff3e9c8ba79be22"
      },
      "docs": {
        "hello_world": "-- Query a table using DSN\nSELECT * FROM odbc_scan(table_name='customers', connection='MyODBCDSN');\n\n-- Execute custom SQL with connection string\nSELECT * FROM odbc_query(\n    connection='Driver={SQL Server};Server=localhost;Database=mydb;',\n    query='SELECT id, name, amount FROM sales WHERE amount > 1000'\n);\n\n-- Attach all tables from an ODBC source\nCALL odbc_attach(connection='MyODBCDSN');\n",
        "extended_description": "The ODBC extension allows DuckDB to seamlessly connect to any database that provides an ODBC driver, enabling you to query and analyze data from a wide variety of data sources without leaving the DuckDB ecosystem.\n\nKey features: - `odbc_scan()`: Query tables from any ODBC data source - `odbc_query()`: Execute custom SQL queries against external databases - `odbc_exec()`: Execute DDL/DML statements without returning results - `odbc_attach()`: Attach all tables from an ODBC source as views in DuckDB - Cross-platform character encoding support - Automatic type conversion between ODBC and DuckDB types - Support for DSNs and direct connection strings\n\nThe extension works on Windows, macOS, and Linux platforms and has been tested with SQL Server, MySQL,  PostgreSQL, Snowflake, SQLite, and many other databases. All functions use named parameters for better  readability and flexibility.\n"
      }
    },
    "official_description": "Connect to any ODBC-compatible database and query data directly from DuckDB",
    "official_version": "0.3.3",
    "language": "C++",
    "maintainers": [
      "Hugoberry"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/nanodbc/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "netquack",
    "repository": "https://github.com/hatamiarash7/duckdb-netquack",
    "owner": "hatamiarash7",
    "repo_name": "duckdb-netquack",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "experimental",
        "source": "readme",
        "context": "> It's an experimental function."
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "- [Usage Examples \ud83d\udcda](#usage-examples-)"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "## Usage Examples \ud83d\udcda"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "D SELECT extract_domain('a.example.com') AS domain;"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "ithub.com/hatamiarash7/duckdb-netquack/releases/latest)"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "D SELECT extract_subdomain('test.example.com.ac') AS dns_record;"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "\u2502 test       \u2502"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-24T07:00:11Z",
    "description": "DuckDB extension for parsing, extracting, and analyzing domains, URIs, and paths with ease.",
    "readme_content": "# DuckDB Netquack Extension\n\n[![DuckDB Badge](https://img.shields.io/badge/Built_With-DuckDB-fff100)](https://duckdb.org/community_extensions/extensions/netquack.html) [![GitHub License](https://img.shields.io/github/license/hatamiarash7/duckdb-netquack)](https://github.com/hatamiarash7/duckdb-netquack/blob/main/LICENSE) [![GitHub Release](https://img.shields.io/github/v/release/hatamiarash7/duckdb-netquack)](https://github.com/hatamiarash7/duckdb-netquack/releases/latest)\n\n![logo](./.github/netquack.webp)\n\nThis extension is designed to simplify working with domains, URIs, and web paths directly within your database queries. Whether you're extracting top-level domains (TLDs), parsing URI components, or analyzing web paths, Netquack provides a suite of intuitive functions to handle all your network tasks efficiently. Built for data engineers, analysts, and developers.\n\nWith Netquack, you can unlock deeper insights from your web-related datasets without the need for external tools or com",
    "analysis_timestamp": "2025-09-27T14:44:05.998732",
    "metadata": {
      "extension": {
        "name": "netquack",
        "description": "DuckDB extension for parsing, extracting, and analyzing domains, URIs, and paths with ease.",
        "version": "1.4.0",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "hatamiarash7"
        ]
      },
      "repo": {
        "github": "hatamiarash7/duckdb-netquack",
        "ref": "c5b7ed449dca37e6824b5c8d8e671a129f5dd960"
      },
      "docs": {
        "extended_description": "This extension designed to simplify working with domains, URIs, IPs, and web paths directly within your database queries. Whether you're extracting top-level domains (TLDs), parsing URI components, or analyzing web paths, Netquack provides a suite of intuitive functions to handle all your network tasks efficiently. Built for data engineers, analysts, and developers.\n\nWith Netquack, you can unlock deeper insights from your web-related datasets without the need for external tools or complex workflows.\n\nCheck the [documentation](https://github.com/hatamiarash7/duckdb-netquack) for more details and examples on each function.\n"
      }
    },
    "official_description": "DuckDB extension for parsing, extracting, and analyzing domains, URIs, and paths with ease.",
    "official_version": "1.4.0",
    "language": "C++",
    "maintainers": [
      "hatamiarash7"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/netquack/description.yml",
    "deprecation_score": 7.0,
    "recommendation": "POSSIBLY DEPRECATED - Manual review recommended"
  },
  {
    "extension": "observefs",
    "repository": "https://github.com/dentiny/duckdb-filesystem-observability",
    "owner": "dentiny",
    "repo_name": "duckdb-filesystem-observability",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "Y filesystem which is compatible with duckdb, for example, azure filesystem."
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-23T10:07:15Z",
    "description": "Provides observability for duckdb filesystem.",
    "readme_content": "# ObserveFS - DuckDB Filesystem Observability Extension\n\n## What is ObserveFS?\n\n`observefs` is a powerful DuckDB extension that provides comprehensive **filesystem observability** for your data operations. It transparently wraps httpfs (HTTP, S3, Hugging Face) with monitoring capabilities, giving you detailed insights into I/O performance, latency patterns, and usage metrics.\n\nWhether you're optimizing data pipelines, debugging performance issues, or understanding access patterns, ObserveFS gives you the visibility you need.\n\n## Usage\n```sql\n-- Install and load the ObserveFS extension\nFORCE INSTALL observefs;\nLOAD observefs;\n\n-- Query remote data (automatically monitored)\nSELECT count(*) FROM 'https://huggingface.co/datasets/open-r1/OpenR1-Math-220k/resolve/main/data/train-00003-of-00010.parquet';\n\n-- View detailed performance metrics\nCOPY (SELECT observefs_get_profile()) TO '/tmp/output.txt';\n\n-- Clear metrics for fresh analysis\nSELECT observefs_clear();\n\n-- Wrap ANY filesystem which ",
    "analysis_timestamp": "2025-09-27T14:44:06.108483",
    "metadata": {
      "extension": {
        "name": "observefs",
        "description": "Provides IO observability to filesystem",
        "version": "0.1.0",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "excluded_platforms": "wasm_mvp;wasm_eh;wasm_threads;windows_amd64_rtools;windows_amd64;windows_amd64_mingw",
        "maintainers": [
          "dentiny"
        ]
      },
      "repo": {
        "github": "dentiny/duckdb-filesystem-observability",
        "ref": "d09d28a3e9f9b9b321de85c2754bca0a97852a2b"
      },
      "docs": {
        "hello_world": "COPY (SELECT observefs_get_profile()) TO '/tmp/output.txt';\n",
        "extended_description": "This extension provides observability to duckdb filesystems.\nIt supports a few key features:\n- 100% compatible with duckdb httpfs\n- Provides both process-wise and bucket-wise latency stats (including histogram and quantile estimation)\n- Allows registering ANY duckdb compatible filesystems (i.e., azure filesystem)\n"
      }
    },
    "official_description": "Provides IO observability to filesystem",
    "official_version": "0.1.0",
    "language": "C++",
    "maintainers": [
      "dentiny"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/observefs/description.yml",
    "deprecation_score": 1.0,
    "recommendation": "MONITOR - Minor concerns detected"
  },
  {
    "extension": "ofquack",
    "repository": "https://github.com/krokozyab/ofquack",
    "owner": "krokozyab",
    "repo_name": "ofquack",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "**username/password:** Credentials e.g. user@example.com / MySecretPass123."
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "cy management, just skip this step. Note that the example extension uses VCPKG to build with a dependency f"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "this will depend on the client you're using. Some examples:"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "./build/release/test/unittest"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "- `unittest` is the test runner of duckdb. Again, the extension is already"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "## Running the tests"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-04-22T12:24:17Z",
    "description": "Oracle Fusion DuckDB extension ",
    "readme_content": "# Ofquack Extension for DuckDB\n\nThis repository is based on https://github.com/duckdb/extension-template, check it out if you want to build and ship your own DuckDB extension.\n\n---\n\nThe **Ofquack** extension provides seamless integration between DuckDB and Oracle Fusion via WSDL-based SOAP calls. It allows you to run arbitrary SQL queries against Oracle Fusion database directly from DuckDB, inferring column names at runtime and returning all data as VARCHAR columns\u2014as native DuckDB tables and as resultsets that can be directly consumed by downstream applications.\n\n---\n## Features\n\n**Dynamic Schema Inference:** Automatically parses XML report output, inferring column names at runtime (all columns returned as VARCHAR).\n\n**Table Function Interface:** Exposes a simple table function oracle_fusion_wsdl_query(...) in DuckDB CLI and clients.\n\n**Credential Handling: Securely** sends Basic\u2011auth credentials over SOAP.\n\n**Chunked Results:** Efficiently streams large result sets in vectorized chun",
    "analysis_timestamp": "2025-09-27T14:44:06.211494",
    "metadata": {
      "extension": {
        "name": "ofquack",
        "description": "The Ofquack extension provides seamless integration between DuckDB and Oracle Fusion via WSDL-based SOAP calls.",
        "version": "0.0.1",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "krokozyab"
        ]
      },
      "repo": {
        "github": "krokozyab/ofquack",
        "ref": "4f71175a5c91526795a25e9ad6876608714eae6d"
      },
      "docs": {
        "extended_description": "The Ofquack extension provides seamless integration between DuckDB and Oracle Fusion via WSDL-based SOAP calls.\nIt allows you to run arbitrary SQL queries against Oracle Fusion database directly from DuckDB, inferring column names at runtime and returning all data as VARCHAR columns\u2014as native DuckDB tables and as resultsets that can be directly consumed by downstream applications."
      }
    },
    "official_description": "The Ofquack extension provides seamless integration between DuckDB and Oracle Fusion via WSDL-based SOAP calls.",
    "official_version": "0.0.1",
    "language": "C++",
    "maintainers": [
      "krokozyab"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/ofquack/description.yml",
    "deprecation_score": 6.0,
    "recommendation": "POSSIBLY DEPRECATED - Manual review recommended"
  },
  {
    "extension": "open_prompt",
    "repository": "https://github.com/quackscience/duckdb-extension-openprompt",
    "owner": "quackscience",
    "repo_name": "duckdb-extension-openpromp",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": null,
    "description": "",
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:06.315990",
    "metadata": {
      "extension": {
        "name": "open_prompt",
        "description": "Interact with LLMs with a simple DuckDB Extension",
        "version": "0.0.5",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "excluded_platforms": "windows_amd64_rtools",
        "maintainers": [
          "lmangani",
          "akvlad"
        ]
      },
      "repo": {
        "github": "quackscience/duckdb-extension-openprompt",
        "ref": "846b35872916cbcd866f992521a108d47393737d"
      },
      "docs": {
        "hello_world": "-- Configure the required parameters to access OpenAI Completions compatible APIs\nD CREATE SECRET IF NOT EXISTS open_prompt (\n      TYPE open_prompt,\n      PROVIDER config,\n      api_token 'your-api-token',\n      api_url 'http://localhost:11434/v1/chat/completions',\n      model_name 'qwen2.5:0.5b',\n      api_timeout '30'\n  );\n\n-- Prompt any OpenAI Completions API form your query\nD SELECT open_prompt('Write a one-line poem about ducks') AS response;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    response                    \u2502\n\u2502                    varchar                     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Ducks quacking at dawn, swimming in the light. \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- Prompt requesting JSON Structured Output for ChatGPT, LLama3, etc\nSET VARIABLE openprompt_model_name = 'llama3.2:3b';\nSELECT open_prompt('I want ice cream', json_schema := '{\n   \"type\": \"object\",\n   \"properties\": {\n     \"summary\": { \"type\": \"string\" },\n     \"sentiment\": { \"type\": \"string\", \"enum\": [\"pos\", \"neg\", \"neutral\"] }\n   },\n   \"required\": [\"summary\", \"sentiment\"],\n   \"additionalProperties\": false\n }');\n\n-- Use Custom System Prompt to request JSON Output in smaller models\nSET VARIABLE openprompt_model_name = 'qwen2.5:1.5b';\nSELECT open_prompt('I want ice cream.', system_prompt:='Response MUST be JSON with the following schema: {\n       \"type\": \"object\",\n       \"properties\": {\n         \"summary\": { \"type\": \"string\" },\n         \"sentiment\": { \"type\": \"string\", \"enum\": [\"pos\", \"neg\", \"neutral\"] }\n       },\n       \"required\": [\"summary\", \"sentiment\"],\n       \"additionalProperties\": false\n     }');\n",
        "extended_description": "## Open Prompt Extension\nThe `open_prompt()` community extension is shamelessly inspired by the Motherduck `prompt()` but focused on self-hosted usage.\n\n> For examples and instructions check out the `open_prompt()` [README](https://github.com/quackscience/duckdb-extension-openprompt)\n\n### Configuration\nSetup the completions API URL configuration w/ optional auth token and model name\n\n```\nSET VARIABLE openprompt_api_url = 'http://localhost:11434/v1/chat/completions';\nSET VARIABLE openprompt_api_token = 'your_api_key_here';\nSET VARIABLE openprompt_model_name = 'qwen2.5:0.5b';\n```\n\nAlternatively the following ENV variables can be used at runtime\n\n```\nOPEN_PROMPT_API_URL='http://localhost:11434/v1/chat/completions'\nOPEN_PROMPT_API_TOKEN='your_api_key_here'\nOPEN_PROMPT_MODEL_NAME='qwen2.5:0.5b'\nOPEN_PROMPT_API_TIMEOUT='30'\n```\n\nFor persistent usage, configure parameters using DuckDB `SECRETS`\n\n```sql\nCREATE PERSISTENT SECRET IF NOT EXISTS open_prompt (\n      TYPE open_prompt,\n      PROVIDER config,\n      api_token 'your-api-token',\n      api_url 'http://localhost:11434/v1/chat/completions',\n      model_name 'qwen2.5:0.5b',\n      api_timeout '30'\n  );\n```\n"
      }
    },
    "official_description": "Interact with LLMs with a simple DuckDB Extension",
    "official_version": "0.0.5",
    "language": "C++",
    "maintainers": [
      "lmangani",
      "akvlad"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/open_prompt/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "parser_tools",
    "repository": "https://github.com/zfarrell/duckdb_extension_parser_tools",
    "owner": "zfarrell",
    "repo_name": "duckdb_extension_parser_tools",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "experimental",
        "source": "readme",
        "context": "An experimental DuckDB extension that exposes functionality from"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "#### Simple example"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "#### CTE Example"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "##### Example"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "SELECT parse_table_names('with cte_test as(select 1) select * from MyTable, cte_test', fa"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "[cte_test, MyTable, cte_test]"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "SELECT parse_statements('SELECT 1; INSERT INTO test VALUES (2); SELECT 3;');"
      }
    ],
    "active_indicators": [
      {
        "keyword": "stable",
        "source": "readme",
        "context": "See [Writing Tests](https://duckdb.org/docs/stable/dev/sqllogictest/writing_tests.html) to learn mor"
      }
    ],
    "repository_archived": false,
    "last_push": "2025-09-24T17:46:33Z",
    "description": "Parse sql - with sql!",
    "readme_content": "# Parser Tools\n\nAn experimental DuckDB extension that exposes functionality from DuckDB's native SQL parser.\n\n## Overview\n\n`parser_tools` is a DuckDB extension designed to provide SQL parsing capabilities within the database. It allows you to analyze SQL queries and extract structural information directly in SQL. This extension provides parsing functions for tables, WHERE clauses, function calls, and statements.\n\n## Features\n\n- **Extract table references** from a SQL query with context information (e.g. `FROM`, `JOIN`, etc.)\n- **Extract function calls** from a SQL query with context information (e.g. `SELECT`, `WHERE`, `HAVING`, etc.)\n- **Parse WHERE clauses** to extract conditions and operators\n- **Parse multi-statement SQL** to extract individual statements or count the number of statements\n- Support for **window functions**, **nested functions**, and **CTEs**\n- Includes **schema**, **name**, and **context** information for all extractions\n- Built on DuckDB's native SQL parser\n- Simp",
    "analysis_timestamp": "2025-09-27T14:44:06.418507",
    "metadata": {
      "extension": {
        "name": "parser_tools",
        "description": "Exposes functions for parsing referenced tables and usage context from SQL queries using DuckDB's native parser.",
        "version": "0.5.0",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "zfarrell"
        ]
      },
      "repo": {
        "github": "zfarrell/duckdb_extension_parser_tools",
        "ref": "0c74f1b24610d324d6254fce6b32755f734e3df7"
      },
      "docs": {
        "hello_world": "-- Extract table references from a simple query\nSELECT * FROM parse_tables('SELECT * FROM my_table');\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 schema  \u2502  table    \u2502 context \u2502\n\u2502 varchar \u2502  varchar  \u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 main    \u2502 my_table  \u2502 from    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- Parse a query with a CTE and a join\nSELECT * FROM parse_tables($$\n    WITH recent_users AS (SELECT * FROM users WHERE created_at > now() - INTERVAL '7 days')\n    SELECT * FROM recent_users r JOIN logins l ON r.id = l.user_id\n$$);\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 schema  \u2502    table     \u2502 context    \u2502\n\u2502 varchar \u2502   varchar    \u2502 varchar    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502         \u2502 recent_users \u2502 cte        \u2502\n\u2502 main    \u2502 users        \u2502 from       \u2502\n\u2502 main    \u2502 logins       \u2502 join_right \u2502\n\u2502 main    \u2502 recent_users \u2502 from_cte   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- Return a list of table names from a query\nSELECT parse_table_names('SELECT * FROM orders JOIN customers ON orders.customer_id = customers.id');\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           parse_table_names        \u2502\n\u2502             varchar[]              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ['orders', 'customers']            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- Parse queries from a csv file\nSELECT parse_table_names(query) AS tables FROM 'user_queries.csv';\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502            tables             \u2502\n\u2502          varchar[]            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 ['users']                     \u2502\n\u2502 ['orders', 'customers']       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- Structured output as a list of table references\nSELECT parse_tables('SELECT * FROM products p JOIN inventory i ON p.sku = i.sku');\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                              parse_tables                                  \u2502\n\u2502 list<struct<schema: varchar, table: varchar, context: varchar>>            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 [{'schema': 'main', 'table': 'products',  'context': 'from'},              \u2502\n\u2502  {'schema': 'main', 'table': 'inventory', 'context': 'join_right'}]        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- Detect invalid sql\nSELECT query, is_parsable(query) AS valid\nFROM (VALUES\n    ('SELECT * FROM good_table'),\n    ('BAD SQL SELECT *'),\n    ('WITH cte AS (SELECT 1) SELECT * FROM cte')\n) AS t(query);\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    query                      \u2502 valid  \u2502\n\u2502                   varchar                     \u2502 boolean\u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 SELECT * FROM good_table                      \u2502 true   \u2502\n\u2502 BAD SQL SELECT *                              \u2502 false  \u2502\n\u2502 WITH cte AS (SELECT 1) SELECT * FROM cte      \u2502 true   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- Extract WHERE conditions from a query\nSELECT * FROM parse_where('SELECT * FROM MyTable WHERE time > 1 AND time < 100');\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   condition    \u2502 table_name \u2502 context \u2502\n\u2502    varchar     \u2502  varchar   \u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 (\"time\" > 1)   \u2502 MyTable    \u2502 WHERE   \u2502\n\u2502 (\"time\" < 100) \u2502 MyTable    \u2502 WHERE   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- Return detailed condition breakdown from a query\nSELECT * FROM parse_where_detailed('SELECT * FROM MyTable WHERE time > 1 AND time < 100');\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 column_name \u2502 operator_type \u2502  value  \u2502 table_name \u2502 context \u2502\n\u2502   varchar   \u2502    varchar    \u2502 varchar \u2502  varchar   \u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 time        \u2502 >             \u2502 1       \u2502 MyTable    \u2502 WHERE   \u2502\n\u2502 time        \u2502 <             \u2502 100     \u2502 MyTable    \u2502 WHERE   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- Parse a query with a BETWEEN condition\nSELECT * FROM parse_where('SELECT * FROM MyTable WHERE time BETWEEN 1 AND 100');\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         condition          \u2502 table_name \u2502 context \u2502\n\u2502          varchar           \u2502  varchar   \u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 (\"time\" BETWEEN 1 AND 100) \u2502 MyTable    \u2502 WHERE   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- Detailed parsing of a BETWEEN condition\nSELECT * FROM parse_where_detailed('SELECT * FROM MyTable WHERE time BETWEEN 1 AND 100');\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 column_name \u2502 operator_type \u2502  value  \u2502 table_name \u2502 context \u2502\n\u2502   varchar   \u2502    varchar    \u2502 varchar \u2502  varchar   \u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 time        \u2502 >=            \u2502 1       \u2502 MyTable    \u2502 WHERE   \u2502\n\u2502 time        \u2502 <=            \u2502 100     \u2502 MyTable    \u2502 WHERE   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- Extract function calls\nSELECT * FROM parse_functions('SELECT upper(name), count(*) FROM users WHERE length(email) > 0');\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 function_name \u2502 schema  \u2502 context \u2502\n\u2502    varchar    \u2502 varchar \u2502 varchar \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 upper         \u2502 main    \u2502 select  \u2502\n\u2502 count_star    \u2502 main    \u2502 select  \u2502\n\u2502 length        \u2502 main    \u2502 where   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- Parse multi-statement as table\nSELECT * from  parse_statements('SELECT 42; INSERT INTO log VALUES (1); SELECT 43;') as statements;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          statement           \u2502\n\u2502           varchar            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 SELECT 42                    \u2502\n\u2502 INSERT INTO log (VALUES (1)) \u2502\n\u2502 SELECT 43                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- Count statements\nSELECT num_statements('SELECT 1; SELECT 2; SELECT 3;');\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 num_statements \u2502\n\u2502     int64      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502       3        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
        "extended_description": "`parser_tools` is a DuckDB extension that enables SQL query introspection using DuckDB\u2019s native parser.\nIt allows you to analyze SQL queries and extract structural information directly in SQL. \nFuture versions may expose additional aspects of the parsed query structure.\nFor more details and examples, visit the [extension repository](https://github.com/zacMode/duckdb_extension_parser_tools).\n"
      }
    },
    "official_description": "Exposes functions for parsing referenced tables and usage context from SQL queries using DuckDB's native parser.",
    "official_version": "0.5.0",
    "language": "C++",
    "maintainers": [
      "zfarrell"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/parser_tools/description.yml",
    "deprecation_score": 5.0,
    "recommendation": "POSSIBLY DEPRECATED - Manual review recommended"
  },
  {
    "extension": "pbix",
    "repository": "https://github.com/Hugoberry/duckdb-pbix-extension",
    "owner": "Hugoberry",
    "repo_name": "duckdb-pbix-extension",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "this will depend on the client you're using. Some examples:"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "./build/release/test/unittest"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "- `unittest` is the test runner of duckdb. Again, the extension is already"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "## Running the tests"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-26T17:59:35Z",
    "description": "Duckdb extension for parsing the metadata and contents of the embedded data mode in PowerBI pbix files",
    "readme_content": "# pbix\n\nThis repository is based on https://github.com/duckdb/extension-template, check it out if you want to build and ship your own DuckDB extension.\n\n---\n\nThis duckdb extension, pbix, allows you to parse the data model embedded in PowerBI (pbix) files.\n\nFor a pure Python implementation of the pbix parser, check out this library \ud83d\udc49 [PBIXray](https://github.com/Hugoberry/pbixray).\n\n## Building\n### Build steps\nNow to build the extension, run:\n```sh\nmake\n```\nThe main binaries that will be built are:\n```sh\n./build/release/duckdb\n./build/release/test/unittest\n./build/release/extension/pbix/pbix.duckdb_extension\n```\n- `duckdb` is the binary for the duckdb shell with the extension code automatically loaded.\n- `unittest` is the test runner of duckdb. Again, the extension is already linked into the binary.\n- `pbix.duckdb_extension` is the loadable binary as it would be distributed.\n\n## Running the extension\nTo run the extension code, start the shell with `./build/release/duckdb`.\n\nNow we can u",
    "analysis_timestamp": "2025-09-27T14:44:06.532672",
    "metadata": {
      "extension": {
        "name": "pbix",
        "description": "Extension that allows parsing the data model embedded in PowerBI (pbix) files",
        "version": "0.3.0",
        "language": "C++",
        "build": "cmake",
        "excluded_platforms": "windows_amd64_rtools;windows_amd64_mingw;linux_amd64_musl",
        "license": "MIT",
        "maintainers": [
          "Hugoberry"
        ]
      },
      "repo": {
        "github": "Hugoberry/duckdb-pbix-extension",
        "ref": "92c60bb174285fad2bf105526c3d44319fe43ec1"
      },
      "docs": {
        "hello_world": "-- Get metadata tables from a PowerBI file\nSELECT Name FROM pbix_meta('Adventure Works DW 2020.pbix','table') WHERE isHidden=0;\n\n-- Read data from a specific table in the PowerBI file\nSELECT \n  ResellerKey, \n  \"Business Type\", \n  Reseller, \n  \"Reseller ID\" \nFROM pbix_read('Adventure Works DW 2020.pbix','Reseller') \nLIMIT 10;\n",
        "extended_description": "The PBIX extension allows you to parse the data model embedded in PowerBI (pbix) files directly in DuckDB.\n\nIt provides two main functions: - `pbix_meta()`: Returns metadata tables for a data model (consult [MS-SSAS-T](https://learn.microsoft.com/en-us/openspecs/sql_server_protocols/ms-ssas-t/f85cd3b9-690c-4bc7-a1f0-a854d7daecd8) for metadata structures) - `pbix_read()`: Returns the contents of a specific table from a pbix file\n\nFor a pure Python implementation of the pbix parser, check out the [PBIXray](https://github.com/Hugoberry/pbixray) library.\n\n*Note:* Current limitations include inability of the WASM version to parse `https` hosted files and that pbix_read() will decompress the entire model in memory. \n"
      }
    },
    "official_description": "Extension that allows parsing the data model embedded in PowerBI (pbix) files",
    "official_version": "0.3.0",
    "language": "C++",
    "maintainers": [
      "Hugoberry"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/pbix/description.yml",
    "deprecation_score": 4.0,
    "recommendation": "REVIEW - Some deprecation indicators found"
  },
  {
    "extension": "pcap_reader",
    "repository": "https://github.com/quackscience/duckdb-extension-pcap",
    "owner": "quackscience",
    "repo_name": "duckdb-extension-pcap",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": null,
    "description": null,
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:06.637661",
    "metadata": {
      "extension": {
        "name": "pcap_reader",
        "description": "Read PCAP files from DuckDB",
        "version": "0.1.3",
        "language": "Rust",
        "build": "cmake",
        "license": "MIT",
        "excluded_platforms": "wasm_mvp;wasm_eh;wasm_threads;windows_amd64_rtools;windows_amd64_mingw;linux_amd64_musl",
        "requires_toolchains": "rust;python3",
        "maintainers": [
          "lmangani",
          "glongo",
          "kYroL01"
        ]
      },
      "repo": {
        "github": "quackscience/duckdb-extension-pcap",
        "ref": "0a11ddc058beb2d480ccbfa83e16a68400c5d076"
      },
      "docs": {
        "hello_world": "-- Basic PCAP reader for local or remote files\nD SELECT * FROM pcap_reader('test.pcap') LIMIT 3;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      timestamp      \u2502     src_ip     \u2502     dst_ip     \u2502 src_port \u2502 dst_port \u2502 protocol \u2502 length \u2502                 payload                   \u2502\n\u2502      timestamp      \u2502    varchar     \u2502    varchar     \u2502 int32    \u2502 int32    \u2502 varchar  \u2502 int32  \u2502                 varchar                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 2024-12-06 19:30:2\u2026 \u2502 xx.xx.xx.xxx   \u2502 yyy.yyy.yy.yyy \u2502 64078    \u2502 5080     \u2502 UDP      \u2502 756    \u2502 INVITE sip:810442837619024@yyy.yyy.yy.y\u2026  \u2502\n\u2502 2024-12-06 19:30:2\u2026 \u2502 yyy.yyy.yy.yyy \u2502 xx.xx.xx.xxx   \u2502 5080     \u2502 64078    \u2502 UDP      \u2502 360    \u2502 SIP/2.0 100 Trying\\r\\nVia: SIP/2.0/UDP \u2026  \u2502\n\u2502 2024-12-06 19:30:2\u2026 \u2502 yyy.yyy.yy.yyy \u2502 xx.xx.xx.xxx   \u2502 5080     \u2502 64078    \u2502 UDP      \u2502 909    \u2502 SIP/2.0 480 Temporarily Unavailable\\r\\n\u2026  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 3 rows                                                                                                                            8 columns \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
        "extended_description": "## DuckDB PCAP Reader\n`pcap_reader` is a DuckDB community extension that empowers network analysts to directly query and analyze IPv4 and IPv6 PCAP files using SQL. \n\nBuilt with Rust for performance and safety, it leverages the `pcap-parser` crate to efficiently process packet capture data.\n\n#### Features\n- Direct PCAP Access: Load PCAP files directly into DuckDB without external tools.\n- SQL-PCAP Analysis: Use DuckDB to filter, aggregate, and analyze IPv4/IPv6 network traffic.\n\n> The PCAP Reader Extension is experimental, use at your own risk!\n"
      }
    },
    "official_description": "Read PCAP files from DuckDB",
    "official_version": "0.1.3",
    "language": "Rust",
    "maintainers": [
      "lmangani",
      "glongo",
      "kYroL01"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/pcap_reader/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "pivot_table",
    "repository": "https://github.com/Alex-Monahan/pivot_table",
    "owner": "Alex-Monahan",
    "repo_name": "pivot_table",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "For a full example, please see below."
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "s, so it is designed to be useful as more than an example, but it is brand new as of 2024-09-16 so please b"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "cy management, just skip this step. Note that the example extension uses VCPKG to build with a dependency f"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "This extension contains many tests, so it is designed to be useful as more than an"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "./build/release/test/unittest"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "- `unittest` is the test runner of duckdb. Again, the extension is already"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2024-09-22T21:18:45Z",
    "description": "Full spreadsheet-style pivot table through SQL macros. Just specify values, rows, columns, and filters!",
    "readme_content": "# Pivot_table\n\nThis repository is based on https://github.com/duckdb/extension-template, check it out if you want to build and ship your own DuckDB extension.\n\n---\n\nThis extension, pivot_table, allow you to pivot your data using a spreadsheet-like pivot API.\nIt is also similar to the Pandas `pivot_table` function. \nIt does this solely through SQL macros - there are no C++ functions as a part of this extension.\n\nSupporting this API means that depending on the parameters, sometimes the DuckDB `PIVOT` function is needed, and other times, a `GROUP BY` will suffice. \nThis extension will dynamically generate the required SQL (in a manner that is safe from SQL injection) and then produce the desired output.\n\nThe main function is `pivot_table`, but it also relies on the creation of an enum `columns_parameter_enum` using the `build_my_enum` function.\nFor a full example, please see below.\n\nThe `pivot_table` function accepts the parameters:\n* table_names\n* values \n* rows\n* columns\n* filters\n* sub",
    "analysis_timestamp": "2025-09-27T14:44:07.037847",
    "metadata": {
      "extension": {
        "name": "pivot_table",
        "description": "Provides a spreadsheet-style pivot_table function",
        "version": "0.0.2",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "Alex-Monahan"
        ]
      },
      "repo": {
        "github": "Alex-Monahan/pivot_table",
        "ref": "3e87d43b4c15a3640b26eb8942ce5e75335c879a"
      },
      "docs": {
        "hello_world": "FROM pivot_table(['duckdb_databases'], [], ['database_name'], [], []);\n",
        "extended_description": "This extension, pivot_table, allow you to pivot your data using a spreadsheet-like pivot API. It is also similar to the Pandas pivot_table function. It does this solely through SQL macros - there are no C++ functions as a part of this extension.\n"
      }
    },
    "official_description": "Provides a spreadsheet-style pivot_table function",
    "official_version": "0.0.2",
    "language": "C++",
    "maintainers": [
      "Alex-Monahan"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/pivot_table/description.yml",
    "deprecation_score": 8.0,
    "recommendation": "LIKELY DEPRECATED - High confidence"
  },
  {
    "extension": "prql",
    "repository": "https://github.com/ywelsch/duckdb-prql",
    "owner": "ywelsch",
    "repo_name": "duckdb-prql",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "or for example:"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "thubusercontent.com/PRQL/prql/0.8.0/prql-compiler/tests/integration/data/chinook/invoices.csv'\""
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "thubusercontent.com/PRQL/prql/0.8.0/prql-compiler/tests/integration/data/chinook/customers.csv'\""
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "thubusercontent.com/PRQL/prql/0.8.0/prql-compiler/tests/integration/data/chinook/invoices.csv'))"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-22T18:45:53Z",
    "description": "PRQL as a DuckDB extension",
    "readme_content": "# PRQL as a DuckDB extension\n\nExtension to [DuckDB](https://duckdb.org) that allows running [PRQL](https://prql-lang.org) commands directly within DuckDB.\n\n## Running the extension\n\nThe PRQL extension is a [DuckDB community extension](https://community-extensions.duckdb.org/extensions/prql.html), and can simply be installed with\n\n```sql\ninstall prql from community;\n```\n\nand subsequently loaded with\n\n```\nload prql;\n```\n\nAfter loading the extension you can directly query DuckDB using PRQL, the [Piped Relational Query Language](https://prql-lang.org). Both PRQL and SQL commands are supported within the same shell.\n\nLet's query using PRQL:\n\n```sql\nlet invoices = s\"select * from 'https://raw.githubusercontent.com/PRQL/prql/0.8.0/prql-compiler/tests/integration/data/chinook/invoices.csv'\"\nlet customers = s\"select * from 'https://raw.githubusercontent.com/PRQL/prql/0.8.0/prql-compiler/tests/integration/data/chinook/customers.csv'\"\n\nfrom invoices\nfilter invoice_date >= @1970-01-16\nderive {\n  t",
    "analysis_timestamp": "2025-09-27T14:44:07.144689",
    "metadata": {
      "extension": {
        "name": "prql",
        "description": "Support for PRQL, the Pipelined Relational Query Language",
        "version": "1.0.0",
        "language": "C++",
        "build": "cmake",
        "requires_toolchains": "rust",
        "license": "MIT",
        "excluded_platforms": "linux_amd64_musl",
        "maintainers": [
          "ywelsch"
        ]
      },
      "repo": {
        "github": "ywelsch/duckdb-prql",
        "ref": "0b411575bb454e96cd5bd8aa97ba1d73ed689a34"
      },
      "docs": {
        "hello_world": "let invoices = s\"select * from 'https://raw.githubusercontent.com/PRQL/prql/0.8.0/prql-compiler/tests/integration/data/chinook/invoices.csv'\"\nlet customers = s\"select * from 'https://raw.githubusercontent.com/PRQL/prql/0.8.0/prql-compiler/tests/integration/data/chinook/customers.csv'\"\nfrom invoices\nfilter invoice_date >= @1970-01-16\nderive {\n  transaction_fees = 0.8,\n  income = total - transaction_fees\n}\nfilter income > 1\ngroup customer_id (\n  aggregate {\n    average total,\n    sum_income = sum income,\n    ct = count total,\n  }\n)\nsort {-sum_income}\ntake 10\njoin c=customers (==customer_id)\nderive name = f\"{c.last_name}, {c.first_name}\"\nselect {\n  c.customer_id, name, sum_income\n}\nderive db_version = s\"version()\"\n",
        "extended_description": "The PRQL extension adds support for the [Pipelined Relational Query Language](https://prql-lang.org).\n"
      }
    },
    "official_description": "Support for PRQL, the Pipelined Relational Query Language",
    "official_version": "1.0.0",
    "language": "C++",
    "maintainers": [
      "ywelsch"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/prql/description.yml",
    "deprecation_score": 4.0,
    "recommendation": "REVIEW - Some deprecation indicators found"
  },
  {
    "extension": "psql",
    "repository": "https://github.com/ywelsch/duckdb-psql",
    "owner": "ywelsch",
    "repo_name": "duckdb-psql",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "o compose your SQL queries in a very natural way (example inspired by PRQL):"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "aw.githubusercontent.com/ywelsch/duckdb-psql/main/example/invoices.csv' |>"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "aw.githubusercontent.com/ywelsch/duckdb-psql/main/example/customers.csv'"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "./build/release/test/unittest"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "- `unittest` is the test runner of duckdb. Again, the extension is already"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-22T18:45:44Z",
    "description": "A piped SQL for DuckDB",
    "readme_content": "# PSQL: a piped SQL for DuckDB\n\nPSQL extends [DuckDB](https://duckdb.org)'s SQL with a pipe syntax to provide simple composable queries. It's a lightweight variant of piped languages such as [PRQL](https://prql-lang.org) and [Kusto](https://docs.microsoft.com/azure/data-explorer/kusto/query/samples?pivots=azuredataexplorer), yet leveraging the full power of DuckDB's SQL.\n\nPipes allow you to compose your SQL queries in a very natural way (example inspired by PRQL):\n\n```sql\nfrom 'https://raw.githubusercontent.com/ywelsch/duckdb-psql/main/example/invoices.csv' |>\nwhere invoice_date >= date '1970-01-16' |>\nselect\n  *, \n  0.8 as transaction_fees,\n  total - transaction_fees as income |>\nwhere income > 1 |>\nselect\n  customer_id, \n  avg(total), \n  sum(income) as sum_income, \n  count() as ct\n  group by customer_id |>\norder by sum_income desc |>\nlimit 10 |>\nas invoices\n  join 'https://raw.githubusercontent.com/ywelsch/duckdb-psql/main/example/customers.csv'\n    as customers\n  on invoices.custome",
    "analysis_timestamp": "2025-09-27T14:44:07.249267",
    "metadata": {
      "extension": {
        "name": "psql",
        "description": "Support for PSQL, a piped SQL dialect for DuckDB",
        "version": "1.0.0",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "ywelsch"
        ]
      },
      "repo": {
        "github": "ywelsch/duckdb-psql",
        "ref": "f0ee86e08020f4b7d7300da5be9c7a0f01c63dce"
      },
      "docs": {
        "hello_world": "from 'https://raw.githubusercontent.com/ywelsch/duckdb-psql/main/example/invoices.csv' |>\nwhere invoice_date >= date '1970-01-16' |>\nselect\n  *, \n  0.8 as transaction_fees,\n  total - transaction_fees as income |>\nwhere income > 1 |>\nselect\n  customer_id, \n  avg(total), \n  sum(income) as sum_income, \n  count() as ct\n  group by customer_id |>\norder by sum_income desc |>\nlimit 10 |>\nas invoices\n  join 'https://raw.githubusercontent.com/ywelsch/duckdb-psql/main/example/customers.csv'\n    as customers\n  on invoices.customer_id = customers.customer_id |>\nselect\n  customer_id,\n  last_name || ', ' || first_name as name,\n  sum_income,\n  version() as db_version;\n",
        "extended_description": "PSQL extends DuckDB's SQL with a pipe syntax to provide simple composable queries. It's a lightweight variant of piped languages such as PRQL and Kusto, yet leveraging the full power of DuckDB's SQL.\n"
      }
    },
    "official_description": "Support for PSQL, a piped SQL dialect for DuckDB",
    "official_version": "1.0.0",
    "language": "C++",
    "maintainers": [
      "ywelsch"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/psql/description.yml",
    "deprecation_score": 5.0,
    "recommendation": "POSSIBLY DEPRECATED - Manual review recommended"
  },
  {
    "extension": "pyroscope",
    "repository": "https://github.com/quackscience/duckdb-extension-pyroscope",
    "owner": "quackscience",
    "repo_name": "duckdb-extension-pyroscope",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": null,
    "description": null,
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:07.353825",
    "metadata": {
      "extension": {
        "name": "pyroscope",
        "description": "DuckDB Pyroscope Extension for Continuous Profiling",
        "version": "0.1.3",
        "language": "Rust",
        "build": "cmake",
        "license": "MIT",
        "excluded_platforms": "windows_amd64_rtools;windows_amd64_mingw;windows_amd64;wasm_threads;wasm_eh;wasm_mvp;linux_amd64_musl;",
        "requires_toolchains": "rust;python3",
        "maintainers": [
          "lmangani",
          "akvlad"
        ]
      },
      "repo": {
        "github": "quackscience/duckdb-extension-pyroscope",
        "ref": "e72cf4cdbfbe79476f55adb2a98aec2792d72f68"
      },
      "docs": {
        "hello_world": "---- Start the tracer, requires backend URL\nD SELECT * FROM trace_start('https://pyroscope:4000');\n\n---- Stop the tracer\nD SELECT * FROM trace_stop();\n",
        "extended_description": "### Pyroscope Continuous Profiling\nThis experimental community extension adds pyroscope continuous profiling features to DuckDB\n\n#### Grafana\nCreate a `Free` account on [Grafana Cloud](https://grafana.com/auth/sign-up/create-user?pg=prod-cloud&plcmt=hero-btn-1) create a Token for Pyroscope profile sending and use the extension:\n```sql\n---- Start the tracer to Grafana Cloud Pyroscope\nD SELECT * FROM trace_start('https://user:token@profiles-prod-xxx.grafana.net');\n```\n\n#### Gigapipe\nCreate a `Free` account on [Gigapipe](https://gigapipe.com) create a Token for Pyroscope profile sending and use the extension:\n```sql\n---- Start the tracer to Grafana Cloud Pyroscope\nD SELECT * FROM trace_start('https://user:token@your-account.gigapipe.com');\n```\n    \n![pyroscope_duckdb_large](https://github.com/user-attachments/assets/74fad3ec-3bc3-4880-be4b-8149c5431115)\n"
      }
    },
    "official_description": "DuckDB Pyroscope Extension for Continuous Profiling",
    "official_version": "0.1.3",
    "language": "Rust",
    "maintainers": [
      "lmangani",
      "akvlad"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/pyroscope/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "quack",
    "repository": "https://github.com/duckdb/extension-template",
    "owner": "duckdb",
    "repo_name": "extension-template",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "demo",
        "source": "official_description",
        "context": "Provides a hello world example demo"
      },
      {
        "keyword": "example",
        "source": "official_description",
        "context": "Provides a hello world example demo"
      },
      {
        "keyword": "test",
        "source": "repo_description",
        "context": "mplate for DuckDB extensions to help you develop, test and deploy a custom extension"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-26T07:47:31Z",
    "description": "Template for DuckDB extensions to help you develop, test and deploy a custom extension",
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:07.750626",
    "metadata": {
      "extension": {
        "name": "quack",
        "description": "Provides a hello world example demo",
        "version": "0.0.2",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "hannes"
        ],
        "requires_toolchains": "rust",
        "vcpkg_commit": "ce613c41372b23b1f51333815feb3edd87ef8a8b",
        "custom_toolchain_script": true
      },
      "repo": {
        "github": "duckdb/extension-template",
        "ref": "e52f46eeca9157124cbc910f52ea8637c95084a1"
      },
      "docs": {
        "hello_world": "SELECT quack('world');\n",
        "extended_description": "The quack extension is based on DuckDB's [Extension Template](https://github.com/duckdb/extension-template/), and it's a great starting point to get started building more advanced extensions.\n"
      }
    },
    "official_description": "Provides a hello world example demo",
    "official_version": "0.0.2",
    "language": "C++",
    "maintainers": [
      "hannes"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/quack/description.yml",
    "deprecation_score": 3.0,
    "recommendation": "REVIEW - Some deprecation indicators found"
  },
  {
    "extension": "quackformers",
    "repository": "https://github.com/martin-conur/quackformers",
    "owner": "martin-conur",
    "repo_name": "quackformers",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "work in progress",
        "source": "readme",
        "context": "edding functionality. This feature is currently a work in progress (WIP) and will be available soon."
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "### Example: RAG with Just DUCKDB"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "For more examples, check out the [examples folder](examples/)."
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "a Python venv is set up with DuckDB and DuckDB's test runner installed. Additionally, depending on conf"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "## Testing"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "This extension uses the DuckDB Python client for testing. This should be automatically installed in the"
      },
      {
        "keyword": "broken",
        "source": "readme",
        "context": "ons produced by this template may (or may not) be broken on windows on python3.11"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-05-31T18:22:45Z",
    "description": "DuckDB NLP extension.",
    "readme_content": "# Quackformers: A DuckDB Extension for LLM-Related Functionality\n\n**Quackformers**, a DuckDB extension for LLM-related tasks. For embedding and RAG-like features on DuckDB:\n\n```sql\nLOAD 'build/debug/quackformers.duckdb_extension'; -- IF BUILDING LOCALLY\n\n-- IMPORTING FROM DUCKDB COMMUNITY\nINSTALL quackformers fROM  community;\nLOAD quackformers;\n\n-- IMPORTING FROM GITHUB REPO\nLOAD quackformers FROM 'https://github.com/martin-conur/quackformers';\n\nCREATE TEMP TABLE QUESTIONS(random_questions) AS\nVALUES\n    ('What is the capital of France?'),\n    ('How does a car engine work?'),\n    ('What is the tallest mountain in the world?'),\n    ('How do airplanes stay in the air?'),\n    ('What is the speed of light?')\n;\n\nSELECT embed(RANDOM_QUESTIONS)::FLOAT[384] embedded_questions FROM QUESTIONS;\n```\n\n### Example: RAG with Just DUCKDB\n\n```sql\nINSTALL quackformers FROM  community;\nLOAD quackformers;\n\nINSTALL vss;\nLOAD vss;\n\nCREATE TABLE vector_table AS\nSELECT *, embed(text)::FLOAT[384] as embedded_t",
    "analysis_timestamp": "2025-09-27T14:44:07.852303",
    "metadata": {
      "extension": {
        "name": "quackformers",
        "description": "Bert-based embedding extension.",
        "version": "0.1.3",
        "language": "Rust",
        "build": "cargo",
        "license": "MIT",
        "excluded_platforms": "wasm_mvp;wasm_eh;wasm_threads;windows_amd64_mingw;linux_amd64_musl",
        "requires_toolchains": "rust;python3",
        "maintainers": [
          "martin-conur"
        ]
      },
      "repo": {
        "github": "martin-conur/quackformers",
        "ref": "b77a7939f290a6feb3e218d9a5f4f8cb18e11426"
      },
      "docs": {
        "hello_world": "SELECT embed('this is an embeddable sentence'); -- This is vanilla BERT (https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)\nSELECT embed_jina('this is an embeddable sentence'); -- This is Jina BERT \n",
        "extended_description": "Quackformers, a DuckDB extension embeddings. Intended to be used alongside VSS vector search for RAG-type functionalities.\nQuackformers is based on DuckDB's [Rust Extension Template](https://github.com/duckdb/extension-template-rs/)\n"
      }
    },
    "official_description": "Bert-based embedding extension.",
    "official_version": "0.1.3",
    "language": "Rust",
    "maintainers": [
      "martin-conur"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/quackformers/description.yml",
    "deprecation_score": 7.0,
    "recommendation": "POSSIBLY DEPRECATED - Manual review recommended"
  },
  {
    "extension": "quickjs",
    "repository": "https://github.com/quackscience/duckdb-quickjs",
    "owner": "quackscience",
    "repo_name": "duckdb-quickjs",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": null,
    "description": null,
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:07.959371",
    "metadata": {
      "extension": {
        "name": "quickjs",
        "description": "DuckDB QuickJS Runtime Extension",
        "version": "0.0.1",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "excluded_platforms": "windows_amd64_mingw",
        "maintainers": [
          "lmangani"
        ]
      },
      "repo": {
        "github": "quackscience/duckdb-quickjs",
        "ref": "83906e2486de7823b10aabcca931533feadfe23c"
      },
      "docs": {
        "hello_world": "-- Quack JS with QuickJS\n-- Scalar\nD SELECT quickjs('2+2');\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 quickjs('2+2') \u2502\n\u2502    varchar     \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 4              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- Scalar Eval\nD SELECT quickjs_eval('(a, b) => a + b', 5, 3);\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 quickjs_eval('(a, b) => a + b', 5, 3) \u2502\n\u2502                 json                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 8                                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- Table Eval\nD SELECT * FROM quickjs('parsed_arg0.map(x => x * arg1)', '[1, 2, 3, 4, 5]', 3);\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 result \u2502\n\u2502  json  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 3      \u2502\n\u2502 6      \u2502\n\u2502 9      \u2502\n\u2502 12     \u2502\n\u2502 15     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
        "extended_description": "## QuickJS DuckDB Extension\nThis extension provides an embedded QuickJS-NG engine for DuckDB. It allows executing JavaScript code directly within your SQL queries. \n> QuickJS-NG is a small, fast, and embeddable JavaScript engine that supports modern JavaScript features including ES2020.\n\nThis extension is experimental and potentially unstable. Do not use it in production.\n"
      }
    },
    "official_description": "DuckDB QuickJS Runtime Extension",
    "official_version": "0.0.1",
    "language": "C++",
    "maintainers": [
      "lmangani"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/quickjs/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "radio",
    "repository": "https://github.com/query-farm/radio",
    "owner": "query-farm",
    "repo_name": "radio",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-26T22:18:34Z",
    "description": "Radio is a DuckDB extension by Query.Farm that brings real-time event streams into your SQL workflows. It enables DuckDB to receive and send events over systems like WebSocket and Redis Pub/Sub.",
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:08.423516",
    "metadata": {
      "docs": {
        "extended_description": "For more information regarding usage, see the [documentation](https://query.farm/duckdb_extension_radio.html).\n"
      },
      "extension": {
        "build": "cmake",
        "description": "Allow interaction with event buses like Websocket and Redis publish/subscribe servers.",
        "excluded_platforms": "wasm_mvp;wasm_eh;wasm_threads;windows_amd64;windows_amd64_mingw;windows_amd64_rtools",
        "language": "C++",
        "license": "MIT",
        "maintainers": [
          "rustyconover"
        ],
        "name": "radio",
        "version": 2025092401
      },
      "repo": {
        "github": "query-farm/radio",
        "ref": "bcff9e16f949d9d1980336f890650ab9dfac131d"
      }
    },
    "official_description": "Allow interaction with event buses like Websocket and Redis publish/subscribe servers.",
    "official_version": 2025092401,
    "language": "C++",
    "maintainers": [
      "rustyconover"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/radio/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "rapidfuzz",
    "repository": "https://github.com/query-farm/rapidfuzz",
    "owner": "query-farm",
    "repo_name": "rapidfuzz",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-26T22:18:45Z",
    "description": "DuckDB Community Extension adding RapidFuzz algorithms for search, deduplication, and record linkage.",
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:08.526133",
    "metadata": {
      "docs": {
        "extended_description": "For more information regarding usage, see the [documentation](https://query.farm/duckdb_extension_rapidfuzz.html).\n"
      },
      "extension": {
        "build": "cmake",
        "description": "Provides adds high-performance fuzzy string matching functions, powered by the RapidFuzz C++ library.",
        "language": "C++",
        "license": "MIT",
        "maintainers": [
          "rustyconover"
        ],
        "name": "rapidfuzz",
        "version": 2025091701
      },
      "repo": {
        "github": "query-farm/rapidfuzz",
        "ref": "1b9ff6c365b05998548e58c0b19310dc810af07c"
      }
    },
    "official_description": "Provides adds high-performance fuzzy string matching functions, powered by the RapidFuzz C++ library.",
    "official_version": 2025091701,
    "language": "C++",
    "maintainers": [
      "rustyconover"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/rapidfuzz/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "read_stat",
    "repository": "https://github.com/mettekou/duckdb-read-stat",
    "owner": "mettekou",
    "repo_name": "duckdb-read-sta",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": null,
    "description": "",
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:08.628011",
    "metadata": {
      "extension": {
        "name": "read_stat",
        "description": "Read data sets from SAS, Stata, and SPSS with ReadStat",
        "version": "0.2.3",
        "language": "C",
        "build": "cmake",
        "license": "MIT",
        "requires_toolchains": "python3",
        "maintainers": [
          "mettekou"
        ]
      },
      "repo": {
        "github": "mettekou/duckdb-read-stat",
        "ref": "5253f0b6d9ef56f7ee26c37f555ee7a4881578e6"
      },
      "docs": {
        "hello_world": "-- Read a SAS `.sas7bdat` or `.xpt` file\nFROM read_stat('sas_data.sas7bdat');\nFROM read_stat('sas_data.xpt');\n-- Read an SPSS `.sav`, `.zsav`, or `.por` file\nFROM read_stat('spss_data.sav');\nFROM read_stat('compressed_spss_data.zsav');\nFROM read_stat('portable_spss_data.por');\n-- Read a Stata .dta file\nFROM read_stat('stata_data.dta');\n\n-- If the file extension is not `.sas7bdat`, `.xpt`, `.sav`, `.zsav`, `.por`, or `.dta`,\n-- use the `read_stat` function for the right file type with the `format` parameter:\nFROM read_stat('sas_data.other_extension', format = 'sas7bdat');\nFROM read_stat('sas_data.other_extension', format = 'xpt');\n-- SPSS `.sav` and `.zsav` can both be read through the format `'sav'`\nFROM read_stat(\n    'spss_data_possibly_compressed.other_extension',\n    format = 'sav'\n);\nFROM read_stat('portable_spss_data.other_extension', format = 'por');\nFROM read_stat('stata_data.other_extension', format = 'dta');\n\n-- Override the character encoding with an `iconv`` encoding name,\n-- see https://www.gnu.org/software/libiconv/\nCREATE TABLE other_data AS FROM read_stat('latin1_encoded.sas7bdat', encoding = 'iso-8859-1');\n",
        "extended_description": "## Usage\n\n### Parameters\n\n| Name | Description | Type | Default |\n|:----|:-----------|:----:|:-------|\n| `format` | The format of the input file, when its extension does not indicate it, either `'sas7bdat'`, `'xpt'`, `'sav'`, `'por'`, or `'dta'` | `VARCHAR` | `NULL` |\n| `encoding` | The character encoding of the input file, as defined by `iconv`, see https://www.gnu.org/software/libiconv/ | `VARCHAR` | `NULL` |\n"
      }
    },
    "official_description": "Read data sets from SAS, Stata, and SPSS with ReadStat",
    "official_version": "0.2.3",
    "language": "C",
    "maintainers": [
      "mettekou"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/read_stat/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "redis",
    "repository": "https://github.com/quackscience/duckdb-extension-redis",
    "owner": "quackscience",
    "repo_name": "duckdb-extension-redis",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": null,
    "description": null,
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:08.730066",
    "metadata": {
      "extension": {
        "name": "redis",
        "description": "Redis compatible Client for DuckDB",
        "version": "1.0.1",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "excluded_platforms": "wasm_mvp;wasm_eh;wasm_threads",
        "maintainers": [
          "lmangani",
          "gigapi"
        ]
      },
      "repo": {
        "github": "quackscience/duckdb-extension-redis",
        "ref": "03bb83c5d1f50ac9f085f49c6415ccb6d0854517"
      },
      "docs": {
        "hello_world": "-- Create a local Redis connection secret\nCREATE SECRET IF NOT EXISTS redis (\n        TYPE redis,\n        PROVIDER config,\n        host 'localhost',\n        port '6379',\n        password 'optional_password'\n    );\n\n-- Create a Redis cloud connection secret\nCREATE SECRET IF NOT EXISTS redis (\n        TYPE redis,\n        PROVIDER config,\n        host 'redis-1234.ec2.redns.redis-cloud.com',\n        port '16959',\n        password 'xxxxxx'\n    );\n\n-- Set a value\nSELECT redis_set('user:1', 'John Doe', 'redis') as result;\n\n-- Get a value\nSELECT redis_get('user:1', 'redis') as user_name;\n\n-- Set hash fields\nSELECT redis_hset('user:1', 'email', 'john@example.com', 'redis');\nSELECT redis_hset('user:1', 'age', '30', 'redis');\n\n-- Get hash field\nSELECT redis_hget('user:1', 'email', 'redis') as email;\n\n-- Push items to list\nSELECT redis_lpush('mylist', 'first_item', 'redis');\nSELECT redis_lpush('mylist', 'second_item', 'redis');\n\n-- Get range from list (returns comma-separated values)\n-- Get all items (0 to -1 means start to end)\nSELECT redis_lrange('mylist', 0, -1, 'redis') as items;\n\n-- Get first 5 items\nSELECT redis_lrange('mylist', 0, 4, 'redis') as items;\n\n-- Push multiple items\nWITH items(value) AS (\n    VALUES ('item1'), ('item2'), ('item3')\n)\nSELECT redis_lpush('mylist', value, 'redis')\nFROM items;\n",
        "extended_description": "<img src=\"https://github.com/user-attachments/assets/46a5c546-7e9b-42c7-87f4-bc8defe674e0\" width=250 />\n\n# DuckDB Redis Client Extension\nThis extension provides Redis-compatible client functionality for DuckDB\n\n> Experimental: USE AT YOUR OWN RISK!\n\n## Features\nCurrently supported Redis operations:\n- String operations: `GET`, `SET`, `MGET`\n- Hash operations: `HGET`, `HSET`, `HGETALL`, `HSCAN`, `HSCAN_OVER_SCAN`\n- List operations: `LPUSH`, `LRANGE`, `LRANGE_TABLE`\n- Key operations: `DEL`, `EXISTS`, `TYPE`, `SCAN`, `KEYS`\n- Batch and discovery operations: `SCAN`, `HSCAN_OVER_SCAN`, `KEYS`\n\n## Quick Reference: Available Functions\n\n| Function | Type | Description |\n|----------|------|-------------|\n| `redis_get(key, secret)` | Scalar | Get value of a string key |\n| `redis_set(key, value, secret)` | Scalar | Set value of a string key |\n| `redis_mget(keys_csv, secret)` | Scalar | Get values for multiple keys (comma-separated) |\n| `redis_hget(key, field, secret)` | Scalar | Get value of a hash field |\n| `redis_hset(key, field, value, secret)` | Scalar | Set value of a hash field |\n| `redis_lpush(key, value, secret)` | Scalar | Push value to a list |\n| `redis_lrange(key, start, stop, secret)` | Scalar | Get range from a list (comma-separated) |\n| `redis_del(key, secret)` | Scalar | Delete a key (returns TRUE if deleted) |\n| `redis_exists(key, secret)` | Scalar | Check if a key exists (returns TRUE if exists) |\n| `redis_type(key, secret)` | Scalar | Get the type of a key |\n| `redis_scan(cursor, pattern, count, secret)` | Scalar | Scan keys (returns cursor:keys_csv) |\n| `redis_hscan(key, cursor, pattern, count, secret)` | Scalar | Scan fields in a hash |\n| `redis_keys(pattern, secret)` | Table | List all keys matching a pattern |\n| `redis_hgetall(key, secret)` | Table | List all fields and values in a hash |\n| `redis_lrange_table(key, start, stop, secret)` | Table | List elements in a list as rows |\n| `redis_hscan_over_scan(scan_pattern, hscan_pattern, count, secret)` | Table | For all keys matching scan_pattern, HSCAN with hscan_pattern, return (key, field, value) rows |\n"
      }
    },
    "official_description": "Redis compatible Client for DuckDB",
    "official_version": "1.0.1",
    "language": "C++",
    "maintainers": [
      "lmangani",
      "gigapi"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/redis/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "rusty_quack",
    "repository": "https://github.com/duckdb/extension-template-rs",
    "owner": "duckdb",
    "repo_name": "extension-template-rs",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "demo",
        "source": "official_description",
        "context": "Provides a hello world example demo from the Rust-based extension template"
      },
      {
        "keyword": "example",
        "source": "official_description",
        "context": "Provides a hello world example demo from the Rust-based extension template"
      },
      {
        "keyword": "experimental",
        "source": "repo_description",
        "context": "(Experimental) Template for Rust-based DuckDB extensions"
      },
      {
        "keyword": "experimental",
        "source": "readme",
        "context": "This is an **experimental** template for Rust based extensions based on the"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "a Python venv is set up with DuckDB and DuckDB's test runner installed. Additionally, depending on conf"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "## Testing"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "This extension uses the DuckDB Python client for testing. This should be automatically installed in the"
      },
      {
        "keyword": "broken",
        "source": "readme",
        "context": "ons produced by this template may (or may not) be broken on windows on python3.11"
      }
    ],
    "active_indicators": [
      {
        "keyword": "stable",
        "source": "readme",
        "context": "turn this eventually into a stable basis for pure-Rust DuckDB extensions that can be"
      }
    ],
    "repository_archived": false,
    "last_push": "2025-09-18T09:13:21Z",
    "description": "(Experimental) Template for Rust-based DuckDB extensions",
    "readme_content": "# DuckDB Rust extension template\nThis is an **experimental** template for Rust based extensions based on the C Extension API of DuckDB. The goal is to\nturn this eventually into a stable basis for pure-Rust DuckDB extensions that can be submitted to the Community extensions\nrepository\n\nFeatures:\n- No DuckDB build required\n- No C++ or C code required\n- CI/CD chain preconfigured\n- (Coming soon) Works with community extensions\n\n## Cloning\n\nClone the repo with submodules\n\n```shell\ngit clone --recurse-submodules <repo>\n```\n\n## Dependencies\nIn principle, these extensions can be compiled with the Rust toolchain alone. However, this template relies on some additional\ntooling to make life a little easier and to be able to share CI/CD infrastructure with extension templates for other languages:\n\n- Python3\n- Python3-venv\n- [Make](https://www.gnu.org/software/make)\n- Git\n\nInstalling these dependencies will vary per platform:\n- For Linux, these come generally pre-installed or are available through t",
    "analysis_timestamp": "2025-09-27T14:44:09.117360",
    "metadata": {
      "extension": {
        "name": "rusty_quack",
        "description": "Provides a hello world example demo from the Rust-based extension template",
        "version": "0.0.1",
        "language": "Rust",
        "build": "cargo",
        "license": "MIT",
        "excluded_platforms": "wasm_mvp;wasm_eh;wasm_threads;windows_amd64_rtools;windows_amd64_mingw;linux_amd64_musl",
        "requires_toolchains": "rust;python3",
        "maintainers": [
          "samansmink",
          "mlafeldt"
        ]
      },
      "repo": {
        "github": "duckdb/extension-template-rs",
        "ref": "3dd3adbeb84f617ebc44619d8b1a8fe6416fd214"
      },
      "docs": {
        "hello_world": "FROM rusty_quack('world');\n",
        "extended_description": "The quack extension is based on DuckDB's [Rust Extension Template](https://github.com/duckdb/extension-template-rs/), and it's a great starting point to get started building DuckDB extensions in Rust.\n"
      }
    },
    "official_description": "Provides a hello world example demo from the Rust-based extension template",
    "official_version": "0.0.1",
    "language": "Rust",
    "maintainers": [
      "samansmink",
      "mlafeldt"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/rusty_quack/description.yml",
    "deprecation_score": 6.0,
    "recommendation": "POSSIBLY DEPRECATED - Manual review recommended"
  },
  {
    "extension": "rusty_sheet",
    "repository": "https://github.com/redraiment/rusty-sheet",
    "owner": "redraiment",
    "repo_name": "rusty-shee",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": null,
    "description": "",
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:09.222625",
    "metadata": {
      "extension": {
        "name": "rusty_sheet",
        "description": "An Excel/OpenDocument Spreadsheets file reader for DuckDB",
        "version": "0.1.0",
        "language": "Rust",
        "build": "cargo",
        "license": "MIT",
        "excluded_platforms": "wasm_mvp;wasm_eh;wasm_threads;windows_amd64_rtools;windows_amd64_mingw;linux_amd64_musl",
        "requires_toolchains": "rust;python3",
        "maintainers": [
          "redraiment"
        ]
      },
      "repo": {
        "github": "redraiment/rusty-sheet",
        "ref": "3cc700798071238763b9dc84ed0d16b42ab1e57d"
      },
      "docs": {
        "hello_world": "-- Read entire spreadsheet with headers\nFROM read_sheet('data.xlsx');\n\n-- Read specific worksheet\nFROM read_sheet('workbook.xlsx', sheet_name='Sheet2');\n\n-- Override specific column types (others auto-detected)\nFROM read_sheet('data.xlsx',\n  columns={'id': 'bigint'}\n);\n\n-- Read specific data range (Excel-style notation)\nFROM read_sheet('data.xlsx', range='A2:E100');\n\n-- Read without headers\nFROM read_sheet('data.xlsx',\n  header=false,\n  columns={'column1': 'varchar', 'column2': 'bigint'}\n);\n\n-- Analyze column types\nFROM analyze_sheet('data.xlsx', analyze_rows=20);\n",
        "extended_description": "The DuckDB rusty-sheet extension that enables reading Excel and OpenDocument spreadsheet files directly within SQL queries. This extension provides seamless integration for analyzing spreadsheet data using DuckDB's powerful SQL engine.\nFor detailed setup and usage instructions, visit the docs at [rusty-sheet](https://github.com/redraiment/rusty-sheet).\n"
      }
    },
    "official_description": "An Excel/OpenDocument Spreadsheets file reader for DuckDB",
    "official_version": "0.1.0",
    "language": "Rust",
    "maintainers": [
      "redraiment"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/rusty_sheet/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "scrooge",
    "repository": "https://github.com/pdet/Scrooge-McDuck",
    "owner": "pdet",
    "repo_name": "Scrooge-McDuck",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [
      {
        "keyword": "maintained",
        "source": "readme",
        "context": "dmap for the next version of Scrooge is currently maintained as a discussion. You can find it [here](https://g"
      }
    ],
    "repository_archived": false,
    "last_push": "2025-04-14T11:16:07Z",
    "description": null,
    "readme_content": "# Scrooge McDuck Extension\n\nScrooge McDuck is a third-party financial extension for [DuckDB](https://www.duckdb.org). The main goal of this extension is to support a set of aggregation functions and data scanners for financial data. It currently supports access to the logs of Ethereum nodes and stock information from Yahoo Finance. \n\nThis extension is still under development, with no official version released yet.\n\nYou can find more details on the [supported scanners](https://github.com/pdet/Scrooge-McDuck/wiki/Data-Scanners), [custom functions](https://github.com/pdet/Scrooge-McDuck/wiki/Custom-Functions), and [usage](https://github.com/pdet/Scrooge-McDuck/wiki/Usage) in the Scrooge wiki.\n\n> **Disclaimer:**  This extension is in no way affiliated with the [DuckDB Foundation](https://duckdb.org/foundation/) or [DuckDB Labs](https://duckdblabs.com/). Therefore, any binaries produced and distributed of this extension are unsigned.\n\n## Roadmap\nA roadmap for the next version of Scrooge is ",
    "analysis_timestamp": "2025-09-27T14:44:09.325178",
    "metadata": {
      "extension": {
        "name": "scrooge",
        "description": "Provides functionality for financial data-analysis, including data scanners for the Ethereum Blockchain and Yahoo Finance",
        "version": "0.0.2",
        "language": "C++",
        "excluded_platforms": "windows_amd64_rtools;windows_amd64_mingw",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "pdet"
        ]
      },
      "repo": {
        "github": "pdet/Scrooge-McDuck",
        "ref": "222e094570f307208258b8faf90dd401fa152acd"
      },
      "docs": {
        "hello_world": "-- Set the RPC Provider\nSET eth_node_url = 'https://mempool.merkle.io/rpc/eth/pk_mbs_0b647b195065b3294a5254838a33d062';\n-- Query Transfer events of USDT from blocks 20034078 - 20034100 while parallelizing on one block per thread\nFROM read_eth(\n    'USDT',\n    'Transfer',\n    20034078,\n    20034100, \n    blocks_per_thread = 1\n);\n",
        "extended_description": "Scrooge McDuck is a third-party financial extension for DuckDB. \nThis extension's main goal is to support a set of aggregation functions and data scanners for financial data. \nIt currently supports access to the logs of Ethereum nodes and stock information from Yahoo Finance.\nMore information on the supported scanners and functions can be found on Scrooge's [wiki page](https://github.com/pdet/Scrooge-McDuck/wiki).\nYou can also find a ROI example of Ether on the [following blogpost](https://pdet-blog.github.io/2024/06/30/ethereum.html)\n"
      }
    },
    "official_description": "Provides functionality for financial data-analysis, including data scanners for the Ethereum Blockchain and Yahoo Finance",
    "official_version": "0.0.2",
    "language": "C++",
    "maintainers": [
      "pdet"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/scrooge/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "sheetreader",
    "repository": "https://github.com/polydbms/sheetreader-duckdb",
    "owner": "polydbms",
    "repo_name": "sheetreader-duckdb",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "test",
        "source": "readme",
        "context": "FROM sheetreader('test.xlsx');"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "D CREATE TABLE test AS FROM sheetreader("
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "'test.xlsx',"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2024-10-15T17:10:39Z",
    "description": null,
    "readme_content": "# SheetReader DuckDB extension\n\n`sheetreader` is a DuckDB extension that allows reading XLSX files into DuckDB tables with SheetReader, our blazingly fast XLSX parser (https://github.com/polydbms/sheetreader-core).\n\n---\n\nThis repository is based on https://github.com/duckdb/extension-template.\n\n## Table of Contents\n\n- [SheetReader DuckDB extension](#sheetreader-duckdb-extension)\n  - [Table of Contents](#table-of-contents)\n  - [Usage](#usage)\n    - [Parameters](#parameters)\n  - [More information on SheetReader](#more-information-on-sheetreader)\n  - [Benchmarks](#benchmarks)\n  - [Building yourself](#building-yourself)\n    - [Running the extension](#running-the-extension)\n\n## Usage\n\nBefore using SheetReader, you need to install it from the [community extensions](https://community-extensions.duckdb.org/extensions/sheetreader.html) and load it into your DuckDB-environment:\n\n```sql\nINSTALL sheetreader FROM community;\nLOAD sheetreader;\n```\n\nNow, you can run your first query:\n\n```sql\nD SELECT ",
    "analysis_timestamp": "2025-09-27T14:44:09.428187",
    "metadata": {
      "extension": {
        "name": "sheetreader",
        "description": "Fast XLSX file importer",
        "version": "0.1.0",
        "language": "C++",
        "build": "cmake",
        "excluded_platforms": "windows_amd64_rtools;windows_amd64_mingw",
        "license": "MIT",
        "maintainers": [
          "freddie-freeloader"
        ]
      },
      "repo": {
        "github": "polydbms/sheetreader-duckdb",
        "ref": "887013792794aaac8bffd040fcb2439dd797ad53"
      },
      "docs": {
        "hello_world": "-- Create table from XLSX file & use default values for parameters\nCREATE TABLE data AS FROM sheetreader('data.xlsx');\n\n-- Example usage of available named parameters\nCREATE TABLE data2 AS FROM sheetreader(\n    'data2.xlsx',\n    sheet_index = 1,\n    threads = 16,\n    skip_rows = 0,\n    has_header = true,\n    types = [BOOLEAN, VARCHAR],\n    coerce_to_string = true,\n    force_types = true\n);\n",
        "extended_description": "`sheetreader` is a DuckDB extension that allows reading XLSX files into DuckDB tables with SheetReader, our blazingly fast XLSX parser (https://github.com/polydbms/sheetreader-core).\n\n#### Parameters\n\n| Name | Description | Type | Default |\n|:----|:-----------|:----:|:-------|\n| `sheet_index` | Index of the sheet to read. Starts at 1. | `INTEGER` | `1` |\n| `sheet_name` | Name of the sheet to read. <br> Only either `sheet_index` or `sheet_name` can be set.  | `VARCHAR` | `\"\"` |\n| `threads` | Number of threads to use, while parsing | `INTEGER` | Half of available cores; minimum 1 |\n| `skip_rows` | Number of rows to skip | `INTEGER` | `0` |\n| `has_header` | Force to treat first row as header row. <br> <ul> <li> If successful, the cell contents are used for column names. </li> <li> If set to `false` (which is the default), the extension will still try to treat the first row as header row. <br> The difference is that it will not fail, if the first row is not usable. </li> </ul> | `BOOLEAN` | `false` |\n| `types` | List of types for all columns <ul> <li> Types currently available:<br> `VARCHAR`,`BOOLEAN`,`DOUBLE`, `DATE`.</li> <li> Useful in combination with `coerce_to_string` and `force_types`. </li> </ul> | `LIST(VARCHAR)` | Uses types determined by first & second row (after skipped rows) |\n| `coerce_to_string` | Coerce all cells in column of type `VARCHAR` to string (i.e. `VARCHAR`). | `BOOLEAN` | `false` |\n| `force_types` | Use `types` even if they are not compatible with types determined by first/second row. <br> Cells, that are not of the column type, are set to `NULL` or coerced to string, if option is set. | `BOOLEAN` | `false` |\n\n#### More Information\n\nSheetReader was published in the [Information Systems Journal](https://www.sciencedirect.com/science/article/abs/pii/S0306437923000194)\n\n```bibtex\n@article{DBLP:journals/is/GavriilidisHZM23,\n  author       = {Haralampos Gavriilidis and\n                  Felix Henze and\n                  Eleni Tzirita Zacharatou and\n                  Volker Markl},\n  title        = {SheetReader: Efficient Specialized Spreadsheet Parsing},\n  journal      = {Inf. Syst.},\n  volume       = {115},\n  pages        = {102183},\n  year         = {2023},\n  url          = {https://doi.org/10.1016/j.is.2023.102183},\n  doi          = {10.1016/J.IS.2023.102183},\n  timestamp    = {Mon, 26 Jun 2023 20:54:32 +0200},\n  biburl       = {https://dblp.org/rec/journals/is/GavriilidisHZM23.bib},\n  bibsource    = {dblp computer science bibliography, https://dblp.org}\n}\n```\n"
      }
    },
    "official_description": "Fast XLSX file importer",
    "official_version": "0.1.0",
    "language": "C++",
    "maintainers": [
      "freddie-freeloader"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/sheetreader/description.yml",
    "deprecation_score": 4.0,
    "recommendation": "REVIEW - Some deprecation indicators found"
  },
  {
    "extension": "shellfs",
    "repository": "https://github.com/query-farm/shellfs",
    "owner": "query-farm",
    "repo_name": "shellfs",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-26T22:18:56Z",
    "description": "DuckDB extension allowing shell commands to be used for input and output.",
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:09.533956",
    "metadata": {
      "docs": {
        "extended_description": "For more information regarding usage, see the [documentation](https://query.farm/duckdb_extension_shellfs.html).\n"
      },
      "extension": {
        "build": "cmake",
        "description": "Allow shell commands to be used for input and output",
        "excluded_platforms": "wasm_mvp;wasm_eh;wasm_threads",
        "language": "C++",
        "license": "MIT",
        "maintainers": [
          "rustyconover"
        ],
        "name": "shellfs",
        "requires_toolchains": "python3",
        "version": 2025091601
      },
      "repo": {
        "github": "query-farm/shellfs",
        "ref": "ee2ce42e3689fc6be35f88cfefc7cf80f2e7648e"
      }
    },
    "official_description": "Allow shell commands to be used for input and output",
    "official_version": 2025091601,
    "language": "C++",
    "maintainers": [
      "rustyconover"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/shellfs/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "snowflake",
    "repository": "https://github.com/iqea-ai/duckdb-snowflake",
    "owner": "iqea-ai",
    "repo_name": "duckdb-snowflake",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "- Usage examples"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "## Usage Examples"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "//github.com/your-org/duckdb-snowflake/releases/latest/download/snowflake.duckdb_extension"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "Test that the driver is found:"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "-- Test connection"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-26T16:25:35Z",
    "description": "A powerful DuckDB extension that enables seamless querying of Snowflake databases using Arrow ADBC drivers with runtime loading capabilities.",
    "readme_content": "# DuckDB Snowflake Extension\n\nA powerful DuckDB extension that enables seamless querying of Snowflake databases using Arrow ADBC drivers. This extension provides efficient, columnar data transfer between DuckDB and Snowflake, making it ideal for analytics, ETL pipelines, and cross-database operations.\n\n## Quick Start\n\n### Installation\n\n```sql\n-- Install and load the extension\nINSTALL snowflake FROM community;\nLOAD snowflake;\n```\n\n### Basic Usage\n\n```sql\n-- 1. Create a Snowflake profile\nCREATE SECRET my_snowflake_secret (\n    TYPE snowflake,\n    ACCOUNT 'your_account.snowflakecomputing.com',\n    USER 'your_username',\n    PASSWORD 'your_password',\n    DATABASE 'your_database',\n    WAREHOUSE 'your_warehouse'\n);\n\n-- 2.1 Query Snowflake data using pass through query\nSELECT * FROM snowflake_scan(\n    'SELECT * FROM customers WHERE state = ''CA''',\n    'my_snowflake_secret'\n);\n\n-- 2.2 Query Snowflake data using local duckdb SQL syntax\nATTACH '' AS snow_db (TYPE snowflake, SECRET my_snowflake_",
    "analysis_timestamp": "2025-09-27T14:44:09.640185",
    "metadata": {
      "extension": {
        "name": "snowflake",
        "description": "Integrates DuckDB with Snowflake, allowing direct querying and management of Snowflake databases using Arrow ADBC drivers",
        "version": "0.1.0",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "iqea-ai"
        ]
      },
      "repo": {
        "github": "iqea-ai/duckdb-snowflake",
        "ref": "75ab20e7349beaff184fcd3f98efbd90bcd7d812",
        "ref_next": "75ab20e7349beaff184fcd3f98efbd90bcd7d812"
      },
      "install_notes": "**Important:** This extension requires the Apache Arrow ADBC Snowflake driver to function properly.\n\nThe driver is not included in the extension package and must be downloaded and installed separately.\n\nFor complete installation instructions including platform-specific driver setup, please refer to:\nhttps://github.com/iqea-ai/duckdb-snowflake#adbc-driver-setup\n\nQuick reference for driver placement:\n- Linux: ~/.duckdb/extensions/v1.3.2/linux_amd64/\n- macOS: ~/.duckdb/extensions/v1.3.2/osx_arm64/ (or osx_amd64)\n- Windows: C:\\Users\\<username>\\.duckdb\\extensions\\v1.3.2\\windows_amd64\\\n",
      "docs": {
        "hello_world": "-- Install and load the extension\nINSTALL snowflake FROM community;\nLOAD snowflake;\n\n-- Create a Snowflake profile\nCREATE SECRET my_snowflake_secret (\n    TYPE snowflake,\n    ACCOUNT 'your_account.snowflakecomputing.com',\n    USER 'your_username',\n    PASSWORD 'your_password',\n    DATABASE 'your_database',\n    WAREHOUSE 'your_warehouse'\n);\n\n-- Query Snowflake data using pass through query\nSELECT * FROM snowflake_scan(\n    'SELECT * FROM customers WHERE state = ''CA''',\n    'my_snowflake_secret'\n);\n\n-- Attach Snowflake database for direct SQL access\nATTACH '' AS snow_db (TYPE snowflake, SECRET my_snowflake_secret, READ_ONLY);\nSELECT * FROM snow_db.schema.customers WHERE state = 'CA';\n",
        "extended_description": "This community-maintained extension allows DuckDB to connect to Snowflake using Arrow ADBC drivers. \nIt provides both pass-through querying and direct database attachment capabilities for seamless Snowflake integration.\n\n**Prerequisites:** The Apache Arrow ADBC Snowflake driver must be installed separately before using this extension.\nFor detailed setup and usage instructions, visit the [extension repository](https://github.com/iqea-ai/duckdb-snowflake).\n"
      }
    },
    "official_description": "Integrates DuckDB with Snowflake, allowing direct querying and management of Snowflake databases using Arrow ADBC drivers",
    "official_version": "0.1.0",
    "language": "C++",
    "maintainers": [
      "iqea-ai"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/snowflake/description.yml",
    "deprecation_score": 5.0,
    "recommendation": "POSSIBLY DEPRECATED - Manual review recommended"
  },
  {
    "extension": "splink_udfs",
    "repository": "https://github.com/moj-analytical-services/splink_udfs",
    "owner": "moj-analytical-services",
    "repo_name": "splink_udfs",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "work in progress",
        "source": "readme",
        "context": "The `splink_udfs` extension is work in progress. It aims to offer a variety of function"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "ndex ignores non-ascii chacters.  This means, for example, that `soundex('\u00c9milie')` returns M400, which is"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "ks from a string using Unicode normalization. For example, `J\u00fcrgen` becomes `Jurgen`. This function does no"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "For full example code, see [here](https://github.com/moj-analytica"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "## Testing"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "This extension uses [SQLLogicTests](https://duckdb.org/dev/sqllogictest/intro.html)"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "To run the tests:"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-24T10:21:04Z",
    "description": null,
    "readme_content": "# Splink UDFs Extension for DuckDB\n\nThe `splink_udfs` extension is work in progress. It aims to offer a variety of function\n\n\n\nThis repo is based on the [DuckDB Extension Template](https://github.com/duckdb/extension-template)\n## Installation\n\nThis is a custom DuckDB extension and not (yet) part of the official community extensions.\n\nOnce built and compiled locally, you can load it like this:\n\n```sql\n.load '/path/to/splink_udfs.duckdb_extension';\n```\n\nIf you're using the DuckDB CLI or embedded DuckDB in your project, simply run:\n\n```sql\nSELECT soundex('Robert'); -- returns 'R163'\n```\n\n## API\n\n### `soundex(VARCHAR) \u2192 VARCHAR`\n\nComputes the Soundex code of a string. Always returns a 4-character string (e.g., `S540`, `J200`, `0000` for empty input).\n\nNote that soundex ignores non-ascii chacters.  This means, for example, that `soundex('\u00c9milie')` returns M400, which is the same as `soundex('milie')`.\n\nIf you have diacritics or other special characters, you should wrap you call like `sounde",
    "analysis_timestamp": "2025-09-27T14:44:09.748513",
    "metadata": {
      "extension": {
        "name": "splink_udfs",
        "description": "Phonetic, text normalization and address matching functions for record linkage.",
        "version": "0.0.9",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "RobinL"
        ]
      },
      "repo": {
        "github": "moj-analytical-services/splink_udfs",
        "ref": "e8e5804e4f18eb9c5b7aa8c96088349555be9add"
      },
      "docs": {
        "hello_world": "LOAD splink_udfs;\nSELECT soundex(unaccent('J\u00fcrgen'));  -- returns 'J625'\n",
        "extended_description": "The splink_udfs extension provides functions for data cleaning and phonetic matching.\n\nIncludes `soundex(str)`, `strip_diacritics(str)`, `unaccent(str)`,\n`ngrams(list,n)`, `double_metaphone(str)`\nand faster versions of `levenshtein` and `damerau_levenshtein`.\n"
      }
    },
    "official_description": "Phonetic, text normalization and address matching functions for record linkage.",
    "official_version": "0.0.9",
    "language": "C++",
    "maintainers": [
      "RobinL"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/splink_udfs/description.yml",
    "deprecation_score": 7.0,
    "recommendation": "POSSIBLY DEPRECATED - Manual review recommended"
  },
  {
    "extension": "st_read_multi",
    "repository": "https://github.com/yutannihilation/duckdb-ext-st-read-multi",
    "owner": "yutannihilation",
    "repo_name": "duckdb-ext-st-read-mul",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": null,
    "description": "",
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:09.857076",
    "metadata": {
      "extension": {
        "name": "st_read_multi",
        "description": "Read multiple geospatial files",
        "version": "0.0.3",
        "language": "Rust",
        "build": "cargo",
        "license": "MIT",
        "excluded_platforms": "wasm_mvp;wasm_eh;wasm_threads;linux_amd64_musl;windows_amd64_mingw",
        "requires_toolchains": "rust;python3",
        "maintainers": [
          "yutannihilation"
        ]
      },
      "repo": {
        "github": "yutannihilation/duckdb-ext-st-read-multi",
        "ref": "2a8d498a6581feda50524ed3e9fb761d7a5a21ad"
      },
      "docs": {
        "hello_world": "LOAD spatial;\n\nSELECT * REPLACE (ST_GeomFromWkb(geometry) as geometry) FROM ST_Read_Multi('path/to/*.geojson');\n",
        "extended_description": "Read multiple geospatial files. Currently, only GeoJSON and GeoPackages are supported.\n"
      }
    },
    "official_description": "Read multiple geospatial files",
    "official_version": "0.0.3",
    "language": "Rust",
    "maintainers": [
      "yutannihilation"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/st_read_multi/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "stochastic",
    "repository": "https://github.com/query-farm/stochastic",
    "owner": "query-farm",
    "repo_name": "stochastic",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-26T22:19:06Z",
    "description": "A DuckDB extension that add comprehensive statistical distribution functions to DuckDB, enabling advanced statistical analysis, probability calculations, and random sampling directly within SQL queries.",
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:09.959172",
    "metadata": {
      "docs": {
        "extended_description": "For more information regarding usage, see the [documentation](https://query.farm/duckdb_extension_stochastic.html).\n"
      },
      "extension": {
        "build": "cmake",
        "description": "Add comprehensive statistical distribution functions to DuckDB, enabling advanced statistical analysis, probability calculations, and random sampling directly within SQL queries.",
        "language": "C++",
        "license": "Apache-2.0",
        "maintainers": [
          "rustyconover"
        ],
        "name": "stochastic",
        "version": 2025091601
      },
      "repo": {
        "github": "query-farm/stochastic",
        "ref": "d9228f3d99e839d2a5b052ca98bdebd646875870"
      }
    },
    "official_description": "Add comprehensive statistical distribution functions to DuckDB, enabling advanced statistical analysis, probability calculations, and random sampling directly within SQL queries.",
    "official_version": 2025091601,
    "language": "C++",
    "maintainers": [
      "rustyconover"
    ],
    "license": "Apache-2.0",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/stochastic/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "substrait",
    "repository": "https://github.com/substrait-io/duckdb-substrait-extension",
    "owner": "substrait-io",
    "repo_name": "duckdb-substrait-extension",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "### Examples"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-06-29T02:00:00Z",
    "description": null,
    "readme_content": "# DuckDB Substrait Extension\n\nThe DuckDB Substrait Extension is a [DuckDB Community Extension](https://duckdb.org/community_extensions/) that provides [Substrait](https://substrait.io) support to [DuckDB](https://www.duckdb.org).\nWith this extension, DuckDB can produce Substrait plans from DuckDB queries as well as consume Substrait plans and execute them with DuckDB.\n\n## Building\n\nTo build the extension, first clone this repository and initialize git submodules by running:\n\n```sh\ngit submodule update --init\n```\n\nThen run:\n\n```sh\nmake\n```\n\nTo use the newly-built extension, run the bundled `duckdb` shell:\n\n```sh\n ./build/release/duckdb\n```\n\nAnd load the extension like so:\n\n```sql\nLOAD 'build/release/extension/substrait/substrait.duckdb_extension';\n```\n\n## Usage\n\nThis extension provides four new functions to DuckDB:\n\n- `get_substrait`: Converts the provided query into a binary Substrait plan\n- `get_substrait_json`: Converts the provided query into a Substrait plan in JSON\n- `from_substra",
    "analysis_timestamp": "2025-09-27T14:44:10.063922",
    "metadata": {
      "extension": {
        "name": "substrait",
        "description": "Allows conversion execution of Substrait query plans",
        "version": "1.2.1",
        "language": "C++",
        "build": "cmake",
        "license": "Apache-2.0",
        "maintainers": [
          "anshuldata",
          "cgkiran",
          "EpsilonPrime"
        ],
        "excluded_platforms": "windows_amd64_rtools;windows_amd64_mingw;windows_amd64"
      },
      "repo": {
        "github": "substrait-io/duckdb-substrait-extension",
        "ref": "ec9f8725df7aa22bae7217ece2f221ac37563da4"
      },
      "docs": {
        "hello_world": ".mode line\nCALL get_substrait('SELECT count(exercise) AS exercise FROM crossfit WHERE difficulty_level <= 5');\n"
      },
      "redirect_from": [
        "/docs/extensions/substrait"
      ]
    },
    "official_description": "Allows conversion execution of Substrait query plans",
    "official_version": "1.2.1",
    "language": "C++",
    "maintainers": [
      "anshuldata",
      "cgkiran",
      "EpsilonPrime"
    ],
    "license": "Apache-2.0",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/substrait/description.yml",
    "deprecation_score": 1.0,
    "recommendation": "MONITOR - Minor concerns detected"
  },
  {
    "extension": "tarfs",
    "repository": "https://github.com/Maxxen/duckdb_tarfs",
    "owner": "Maxxen",
    "repo_name": "duckdb_tarfs",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "## Example usage"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "For example, given a tar file ab.tar containing two csv's, a."
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "ing the `tar://` and `http://` prefixes. Heres an example:"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "om/duckdb/community-extensions). To install the latest version simply run the following SQL statement fr"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "the extension installed, you can upgrade to the latest version by running the following SQL statement."
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "For more examples, see the [tests](test/sql/tarfs.sql) included in this repository."
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2024-08-26T11:01:47Z",
    "description": null,
    "readme_content": "# TARFS DuckDB Extension\n\nThis repository is based on https://github.com/duckdb/extension-template, check it out if you want to build and ship your own DuckDB extension.\n\n---\n\nThis extension, `tarfs`, provides a duckdb file-system abstraction to read and glob files within __uncompressed__ tar archives.\n\n## Install from the community repository\n\nThis extension is (soon) available from the [DuckDB community extension repository](https://github.com/duckdb/community-extensions). To install the latest version simply run the following SQL statement from within a running DuckDB process.\n```sql\n    INSTALL tarfs FROM 'community';\n```\n\nIf you already have an older version of the extension installed, you can upgrade to the latest version by running the following SQL statement.\n```sql\n    FORCE INSTALL tarfs FROM 'community';\n```\n\nFor more information regarding community extensions, see the [blog post](https://duckdb.org/2024/07/05/community-extensions.html)\n\n## Example usage\n\nFor example, given ",
    "analysis_timestamp": "2025-09-27T14:44:10.167846",
    "metadata": {
      "extension": {
        "name": "tarfs",
        "description": "glob, open and read files within `.tar` archives",
        "version": "1.0.0",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "Maxxen"
        ]
      },
      "repo": {
        "github": "Maxxen/duckdb_tarfs",
        "ref": "6d468b45f38f16d58e49032edd76aa76c2a2b078"
      },
      "docs": {
        "hello_world": "SELECT filename FROM read_blob('tar://data/csv/tar/ab.tar/*');\n",
        "extended_description": "This extension provides a duckdb file-system abstraction to read and glob files within __uncompressed__ tar archives.\nFor more information and information regarding usage, limitations and performance, see the [tarfs README](https://github.com/Maxxen/duckdb_tarfs).\n"
      }
    },
    "official_description": "glob, open and read files within `.tar` archives",
    "official_version": "1.0.0",
    "language": "C++",
    "maintainers": [
      "Maxxen"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/tarfs/description.yml",
    "deprecation_score": 8.0,
    "recommendation": "LIKELY DEPRECATED - High confidence"
  },
  {
    "extension": "textplot",
    "repository": "https://github.com/query-farm/textplot",
    "owner": "query-farm",
    "repo_name": "textplo",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": null,
    "description": "",
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:10.272941",
    "metadata": {
      "docs": {
        "extended_description": "For more information regarding usage, see the [documentation](https://query.farm/duckdb_extension_textplot.html).\n"
      },
      "extension": {
        "build": "cmake",
        "description": "Enables text-based data visualization directly in SQL queries, including ASCII/Unicode bar charts, density plots, and sparklines for lightweight analytics and dashboards.",
        "language": "C++",
        "license": "Apache-2.0",
        "maintainers": [
          "rustyconover"
        ],
        "name": "textplot",
        "version": 2025091602
      },
      "repo": {
        "github": "query-farm/textplot",
        "ref": "a703a5f37370f37b834b47f63318681ef8350989"
      }
    },
    "official_description": "Enables text-based data visualization directly in SQL queries, including ASCII/Unicode bar charts, density plots, and sparklines for lightweight analytics and dashboards.",
    "official_version": 2025091602,
    "language": "C++",
    "maintainers": [
      "rustyconover"
    ],
    "license": "Apache-2.0",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/textplot/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "tributary",
    "repository": "https://github.com/query-farm/tributary",
    "owner": "query-farm",
    "repo_name": "tributary",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-26T22:19:37Z",
    "description": "A DuckDB Extension for Kafka",
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:10.375029",
    "metadata": {
      "docs": {
        "extended_description": "For more information regarding usage, see the [documentation](https://query.farm/duckdb_extension_tributary.html).\n"
      },
      "extension": {
        "build": "cmake",
        "description": "Enable DuckDB to interact with Apache Kafka",
        "excluded_platforms": "wasm_mvp;wasm_eh;wasm_threads;windows_amd64_mingw;",
        "language": "C++",
        "license": "MIT",
        "maintainers": [
          "rustyconover"
        ],
        "name": "tributary",
        "version": 2025091601
      },
      "repo": {
        "github": "query-farm/tributary",
        "ref": "d1409bccd6b1fdc85c84020780ed79d1e90dd675"
      }
    },
    "official_description": "Enable DuckDB to interact with Apache Kafka",
    "official_version": 2025091601,
    "language": "C++",
    "maintainers": [
      "rustyconover"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/tributary/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "tsid",
    "repository": "https://github.com/quackscience/duckdb-extension-tsid",
    "owner": "quackscience",
    "repo_name": "duckdb-extension-tsid",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": null,
    "description": null,
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:10.477026",
    "metadata": {
      "extension": {
        "name": "tsid",
        "description": "DuckDB Time-Sortable ID generator",
        "version": "0.0.1",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "lmangani"
        ]
      },
      "repo": {
        "github": "quackscience/duckdb-extension-tsid",
        "ref": "42203135d324143cc3e5d69def36d89b4370ae06"
      },
      "docs": {
        "hello_world": "-- Generate a new time-sortable ID (accepts an optional seed string)\nD SELECT tsid();\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              tsid()              \u2502\n\u2502             varchar              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 675716e86985495e9cf575f0b9c4a8db \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- Extract timestamp from a TSID\nD SELECT tsid_to_timestamp('675716e86985495e9cf575f0b9c4a8db');\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 tsid_to_timestamp('675716e86985495e9cf575f0b9c4a8db') \u2502\n\u2502                       timestamp                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 2024-12-09 16:12:24.44259                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- Verify TSID ordering\nD SELECT \n      a.id as id1,\n      b.id as id2,\n      tsid_to_timestamp(a.id) as ts1,\n      tsid_to_timestamp(b.id) as ts2\n  FROM \n      (SELECT tsid('a') as id FROM range(1)) a,\n      (SELECT tsid('b') as id FROM range(1)) b;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502               id1                \u2502               id2                \u2502            ts1             \u2502            ts2             \u2502\n\u2502             varchar              \u2502             varchar              \u2502         timestamp          \u2502         timestamp          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 6757176b9d4640b299be06ff79ed1373 \u2502 6757176b9d704dcf8a1dce8bb6da51bf \u2502 2024-12-09 16:14:35.659653 \u2502 2024-12-09 16:14:35.660354 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"
      },
      "extended_description": "The TSID Extension is experimental, use at your own risk!\n"
    },
    "official_description": "DuckDB Time-Sortable ID generator",
    "official_version": "0.0.1",
    "language": "C++",
    "maintainers": [
      "lmangani"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/tsid/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "ulid",
    "repository": "https://github.com/Maxxen/duckdb_ulid",
    "owner": "Maxxen",
    "repo_name": "duckdb_ulid",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "atures from the extension directly in DuckDB, for example by creating a new ULID using the `ulid()` scalar"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "./build/release/test/unittest"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "- `unittest` is the test runner of duckdb. Again, the extension is already"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "## Running the tests"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2024-07-09T09:35:50Z",
    "description": null,
    "readme_content": "# DuckDB ULID\n\nThis repository is based on https://github.com/duckdb/extension-template, check it out if you want to build and ship your own DuckDB extension.\n\n---\n\nThis extension adds a new `ULID` data type to DuckDB, based on [this specification](https://github.com/ulid/spec).\nA `ULID` is similar to a `UUID` except that it also contains a timestamp component, which makes it more suitable for use cases where the order of creation is important.\n\nThe extension provides the following functions:\n\n- `ulid()`: Returns a new `ULID` value based on the current system time.\n- `ulid_timestamp(ulid)`: Returns the timestamp component of a `ULID` value.\n- `ulid_epoch_ms(ulid)`: Returns the timestamp component of a `ULID` value in milliseconds since the Unix epoch.\n\nAdditionally, the extension provides cast functions to convert between `ULID` and the `VARCHAR` and `UHUGEINT` types.\nA pair of `ULID`s will always sort the same regardless if it is cast to `VARCHAR` or `UHUGEINT`.\n\nYou can also cast bac",
    "analysis_timestamp": "2025-09-27T14:44:10.986445",
    "metadata": {
      "extension": {
        "name": "ulid",
        "description": "ULID data type for DuckDB",
        "version": "1.0.0",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "Maxxen"
        ]
      },
      "repo": {
        "github": "Maxxen/duckdb_ulid",
        "ref": "b8368f646d57aa1bc73a8fee37621fcb87e4ccd2"
      },
      "docs": {
        "hello_world": "SELECT ulid() AS result;\n",
        "extended_description": "This extension adds a new `ULID` data type to DuckDB. \nA [ULID](https://github.com/ulid/spec) is similar to a UUID except that it also contains a timestamp component, which makes it more suitable for use cases where the order of creation is important. \nAdditionally, the string representation is lexicographically sortable while preserving the sort order of the timestamps.\n"
      }
    },
    "official_description": "ULID data type for DuckDB",
    "official_version": "1.0.0",
    "language": "C++",
    "maintainers": [
      "Maxxen"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/ulid/description.yml",
    "deprecation_score": 6.0,
    "recommendation": "POSSIBLY DEPRECATED - Manual review recommended"
  },
  {
    "extension": "vortex",
    "repository": "https://github.com/vortex-data/duckdb-vortex",
    "owner": "vortex-data",
    "repo_name": "duckdb-vortex",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "cy management, just skip this step. Note that the example"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "this will depend on the client you're using. Some examples:"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "./build/release/test/unittest"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "- `unittest` is the test runner of duckdb. Again, the extension is already"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "## Running the tests"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-26T20:53:25Z",
    "description": "DuckDB extension allowing reading/writing of vortex files",
    "readme_content": "# VortexDuckdb\n\nThis repository is based on https://github.com/duckdb/extension-template, check it out if you want to build and ship\nyour own DuckDB extension.\n\n---\n\nThis extension, VortexDuckdb, allow you to ... <extension_goal>.\n\n## Building\n\n### Install required system dependencies\n\n#### MacOS\n\n```shell\nbrew install pkg-config\n```\n\n### Managing dependencies\n\nDuckDB extensions uses VCPKG for dependency management. Enabling VCPKG is very simple: follow\nthe [installation instructions](https://vcpkg.io/en/getting-started) or just run the following:\n\n```shell\ngit clone https://github.com/Microsoft/vcpkg.git\n./vcpkg/bootstrap-vcpkg.sh\nexport VCPKG_TOOLCHAIN_PATH=`pwd`/vcpkg/scripts/buildsystems/vcpkg.cmake\n```\n\nNote: VCPKG is only required for extensions that want to rely on it for dependency management. If you want to develop an\nextension without dependencies, or want to do your own dependency management, just skip this step. Note that the example\nextension uses VCPKG to build with a dep",
    "analysis_timestamp": "2025-09-27T14:44:11.090195",
    "metadata": {
      "extension": {
        "name": "vortex",
        "description": "Provides write and scan functions for Vortex files",
        "version": "0.53.0",
        "language": "C++,Rust",
        "build": "cmake",
        "license": "Apache-2.0",
        "maintainers": [
          "joseph-isaacs",
          "0ax1",
          "gatesn"
        ],
        "excluded_platforms": "wasm_mvp;wasm_eh;wasm_threads;windows_amd64_rtools;windows_amd64_mingw;windows_amd64;linux_amd64_musl",
        "requires_toolchains": "rust"
      },
      "repo": {
        "github": "vortex-data/duckdb-vortex",
        "ref": "8c592713f9d970a8a2004eebf2db1fd2099a42dd"
      },
      "docs": {
        "hello_world": "write a vortex file\n`COPY (SELECT * from generate_series(0, 4)) TO 'FILENAME.vortex' (FORMAT VORTEX);`\n\nscan a vortex file\n`select * from read_vortex('...');`\n"
      }
    },
    "official_description": "Provides write and scan functions for Vortex files",
    "official_version": "0.53.0",
    "language": "C++,Rust",
    "maintainers": [
      "joseph-isaacs",
      "0ax1",
      "gatesn"
    ],
    "license": "Apache-2.0",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/vortex/description.yml",
    "deprecation_score": 5.0,
    "recommendation": "POSSIBLY DEPRECATED - Manual review recommended"
  },
  {
    "extension": "webbed",
    "repository": "https://github.com/teaguesterling/duckdb_webbed",
    "owner": "teaguesterling",
    "repo_name": "duckdb_webbed",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "| Function | Description | Example |"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "| Function | Description | Example |"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "| Function | Description | Example |"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "- 100% test coverage"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "| Alias for xml_valid | `SELECT xml_well_formed('<test/>')` |"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "\"alt\": \"Test Image\","
      }
    ],
    "active_indicators": [
      {
        "keyword": "production ready",
        "source": "readme",
        "context": "### \ud83d\udee0 **Production Ready**"
      }
    ],
    "repository_archived": false,
    "last_push": "2025-08-13T02:24:15Z",
    "description": null,
    "readme_content": "# DuckDB XML Extension\n\nA comprehensive XML and HTML processing extension for DuckDB that enables SQL-native analysis of structured documents with intelligent schema inference and powerful XPath-based data extraction.\n\n## Features Overview\n\n### \ud83d\udd0d **XML & HTML Processing**\n- Parse and validate XML/HTML documents\n- Extract data using XPath expressions\n- Convert between XML, HTML, and JSON formats\n- Read files directly into DuckDB tables\n\n### \ud83d\udcca **Smart Schema Inference** \n- Automatically flatten XML documents into relational tables\n- Intelligent type detection (dates, numbers, booleans)\n- Configurable element and attribute handling\n\n### \ud83d\udee0 **Production Ready**\n- Built on libxml2 for robust parsing\n- Comprehensive error handling\n- Memory-safe RAII implementation\n- 100% test coverage\n\n---\n\n## Quick Start\n\n```sql\n-- Load the extension\nLOAD webbed;\n\n-- Read XML files directly\nSELECT * FROM 'data.xml';\nSELECT * FROM 'config/*.xml';\n\n-- Parse and extract from XML content\nSELECT xml_extract_text(",
    "analysis_timestamp": "2025-09-27T14:44:11.194202",
    "metadata": {
      "extension": {
        "name": "webbed",
        "description": "Comprehensive processing extension for web markup languages (XML and HTML) that enables SQL-native analysis of structured documents with intelligent schema inference, XPath-based data extraction, and powerful HTML table parsing capabilities.",
        "version": "1.0.2",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "requires_toolchains": "vcpkg",
        "maintainers": [
          "teaguesterling"
        ],
        "vcpkg_commit": "dd3097e305afa53f7b4312371f62058d2e665320"
      },
      "repo": {
        "github": "teaguesterling/duckdb_webbed",
        "ref": "d17300c27f5e5534919c32030cc1d5d4a2429812"
      },
      "docs": {
        "hello_world": "-- Load the extension\nLOAD webbed;\n\n-- Read XML files directly into tables\nSELECT * FROM 'data.xml';\nSELECT * FROM read_xml('config/*.xml');\n\n-- Parse and extract from XML content using XPath\nSELECT xml_extract_text('<book><title>Database Guide</title></book>', '//title');\n-- Result: \"Database Guide\"\n\n-- Parse and extract from HTML content\nSELECT html_extract_text('<html><body><h1>Welcome</h1></body></html>', '//h1');\n-- Result: \"Welcome\"\n\n-- Extract HTML tables directly into DuckDB\nSELECT * FROM html_extract_tables('<table><tr><th>Name</th><th>Age</th></tr><tr><td>John</td><td>25</td></tr></table>');\n\n-- Extract links and images from HTML pages\nSELECT html_extract_links('<a href=\"https://example.com\">Click here</a>');\nSELECT html_extract_images('<img src=\"photo.jpg\" alt=\"Photo\" width=\"800\">');\n\n-- Convert between XML and JSON formats\nSELECT xml_to_json('<person><name>John</name><age>30</age></person>');\nSELECT json_to_xml('{\"name\":\"John\",\"age\":\"30\"}');\n",
        "extended_description": "DuckDB XML is a comprehensive extension that brings powerful XML and HTML processing capabilities to DuckDB, enabling SQL-native analysis of structured documents. The extension provides three core areas of functionality:\n\n**XML Processing & Analysis**: Parse, validate, and extract data from XML documents using full XPath 1.0 expressions. Functions include `xml_extract_text()`, `xml_extract_elements()`, `xml_extract_attributes()`, `xml_valid()`, and `xml_stats()` for comprehensive document analysis. The extension handles namespaces, comments, CDATA sections, and provides utilities like `xml_pretty_print()` and `xml_minify()`.\n\n**HTML Processing & Web Scraping**: Advanced HTML parsing capabilities with specialized functions for web data extraction. Extract text content with `html_extract_text()`, parse HTML tables into structured data with `html_extract_tables()`, extract links with metadata using `html_extract_links()`, and extract images with attributes using `html_extract_images()`. Perfect for web scraping and HTML document analysis workflows.\n\n**Smart Schema Inference & File Reading**: Automatically flatten XML/HTML documents into relational tables with intelligent type detection for dates, numbers, booleans, and nested structures. Functions like `read_xml()` and `read_html()` provide direct file-to-table conversion with configurable options for error handling, maximum file sizes, and schema customization.\n\n**Key XML Functions**:\n- `read_xml(pattern)` - Read XML files with automatic schema inference\n- `xml_extract_text(xml, xpath)` - XPath-based text extraction\n- `xml_extract_elements(xml, xpath)` - Extract structured elements\n- `xml_extract_attributes(xml, xpath)` - Extract attributes as structs\n- `xml_to_json(xml)` / `json_to_xml(json)` - Format conversions\n- `xml_stats(xml)` - Document statistics and analysis\n- `xml_validate_schema(xml, xsd)` - XSD schema validation\n\n**Key HTML Functions**:\n- `read_html(pattern)` - Read HTML files into tables\n- `html_extract_tables(html)` - Extract HTML tables as structured data\n- `html_extract_links(html)` - Extract all links with metadata\n- `html_extract_images(html)` - Extract images with attributes\n- `html_extract_text(html, xpath)` - XPath-based HTML text extraction\n- `parse_html(content)` - Parse HTML strings into structured format\n\nBuilt on libxml2 for robust, standards-compliant parsing with comprehensive error handling, memory-safe RAII implementation, and 100% test coverage. The extension supports mixed file systems, configurable schema inference, and efficient processing of large document collections.\n"
      }
    },
    "official_description": "Comprehensive processing extension for web markup languages (XML and HTML) that enables SQL-native analysis of structured documents with intelligent schema inference, XPath-based data extraction, and powerful HTML table parsing capabilities.",
    "official_version": "1.0.2",
    "language": "C++",
    "maintainers": [
      "teaguesterling"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/webbed/description.yml",
    "deprecation_score": 4.0,
    "recommendation": "REVIEW - Some deprecation indicators found"
  },
  {
    "extension": "webmacro",
    "repository": "https://github.com/quackscience/duckdb-extension-webmacro",
    "owner": "quackscience",
    "repo_name": "duckdb-extension-webmacro",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": null,
    "description": null,
    "readme_content": null,
    "analysis_timestamp": "2025-09-27T14:44:11.305152",
    "metadata": {
      "extension": {
        "name": "webmacro",
        "description": "Load DuckDB Macros from the web",
        "version": "0.0.2",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "lmangani"
        ]
      },
      "repo": {
        "github": "quackscience/duckdb-extension-webmacro",
        "ref": "3f980d8f79df0da8da42e7d5f0bc07ddc74f816d"
      },
      "docs": {
        "hello_world": "-- Create a DuckDB Scalar or Table macro statement and save it to a gist;\n\n-- Load your remote macro onto your system using the gist url\n\nD SELECT load_macro_from_url('https://gist.githubusercontent.com/lmangani/518215a68e674ac662537d518799b893/raw/5f305480fdd7468f4ecda3686011bab8e8e711bf/bsky.sql') as res;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   res                   \u2502\n\u2502                 varchar                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Successfully loaded macro: search_posts \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n-- Use your new macro and have fun:\nD SELECT * FROM search_posts('qxip.bsky.social', text := 'quack');\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  author_handle   \u2502 display_name \u2502      post_text       \u2502 \u2026 \u2502 replies \u2502 reposts \u2502 likes \u2502 quotes \u2502\n\u2502     varchar      \u2502   varchar    \u2502       varchar        \u2502   \u2502  int64  \u2502  int64  \u2502 int64 \u2502 int64  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 qxip.bsky.social \u2502 qxip         \u2502 This is super cool\u2026  \u2502 \u2026 \u2502       1 \u2502       0 \u2502     1 \u2502      0 \u2502\n\u2502 qxip.bsky.social \u2502 qxip         \u2502 github.com/quacksc\u2026  \u2502 \u2026 \u2502       0 \u2502       1 \u2502     2 \u2502      0 \u2502\n\u2502 qxip.bsky.social \u2502 qxip         \u2502 #DuckDB works grea\u2026  \u2502 \u2026 \u2502       2 \u2502       3 \u2502    24 \u2502      0 \u2502\n\u2502 qxip.bsky.social \u2502 qxip         \u2502 github.com/quacksc\u2026  \u2502 \u2026 \u2502       1 \u2502       0 \u2502     0 \u2502      0 \u2502\n\u2502 qxip.bsky.social \u2502 qxip         \u2502 The latest #Quackp\u2026  \u2502 \u2026 \u2502       0 \u2502       0 \u2502     2 \u2502      0 \u2502\n\u2502 qxip.bsky.social \u2502 qxip         \u2502 The #DuckDB Ecosys\u2026  \u2502 \u2026 \u2502       0 \u2502       0 \u2502     5 \u2502      0 \u2502\n\u2502 qxip.bsky.social \u2502 qxip         \u2502 Ladies and Gents, \u2026  \u2502 \u2026 \u2502       1 \u2502       0 \u2502     4 \u2502      0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 7 rows                                                                      9 columns (7 shown) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
        "extended_description": "The HTTP Client Extension is experimental, use at your own risk!\n"
      }
    },
    "official_description": "Load DuckDB Macros from the web",
    "official_version": "0.0.2",
    "language": "C++",
    "maintainers": [
      "lmangani"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/webmacro/description.yml",
    "deprecation_score": 0.0,
    "recommendation": "ACTIVE - No significant deprecation indicators"
  },
  {
    "extension": "wireduck",
    "repository": "https://github.com/hyehudai/wireduck",
    "owner": "hyehudai",
    "repo_name": "wireduck",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "## Examples"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "for example:"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "files directly from e.g. HTTP or S3 sources. For example"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "./build/release/test/unittest"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "- `unittest` is the test runner of duckdb. Again, the extension is already"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "## Running the tests"
      }
    ],
    "active_indicators": [
      {
        "keyword": "maintained",
        "source": "readme",
        "context": "The roadmap for the next version is maintained as a discussion. you can find it [here](https://g"
      }
    ],
    "repository_archived": false,
    "last_push": "2025-09-23T21:22:03Z",
    "description": "Duckdb extension to read pcap files",
    "readme_content": "\nThis repository is based on https://github.com/duckdb/extension-template, check it out if you want to build and ship your own DuckDB extension.\n\n---\n# DuckDB Wireduck Extension\n#### Dissection is the first step to analysis.  ><(((('>\n\n![Description](./docs/wireduck.jpg)\n\n\n## What is this tool good for ?\nThis extension, Wireduck, allow reading PCAP files using duckdb.\n\n[Wireshark](https://www.wireshark.org/) is the leading open source tool for network traffic analysis, [tshark](https://www.wireshark.org/docs/man-pages/tshark.html), Wireshark's CLI, allows filterting and fetching netework data.\nHowerver, when analytics, aggregation, joining and other data wrangleing tasks are in order things gets a little more complex. This is where this extension can help by harnessing the argonomity of duckdb and SQL.\n\nIn addiiton, while duckdb supports leading data format (parquet ,json, delta, etc) wireshark supports over 3000 protocols. from IoT to Telcom to financial protocols.\nSo any new dissecto",
    "analysis_timestamp": "2025-09-27T14:44:11.808998",
    "metadata": {
      "extension": {
        "name": "wireduck",
        "description": "Read and dissect PCAP files from DuckDB",
        "version": "0.0.2",
        "language": "c++",
        "build": "cmake",
        "license": "MIT",
        "excluded_platforms": "osx_amd64;osx_arm64;windows_amd64;wasm",
        "maintainers": [
          "hyehudai"
        ]
      },
      "repo": {
        "github": "hyehudai/wireduck",
        "ref": "19c4018cc8ebad08547d621bcdc25df86294ca2b"
      },
      "docs": {
        "hello_world": "-- Basic PCAP reader for local files.\nD select count(*) , sum (\"tcp.len\") , \"tcp.srcport\" ,\"tcp.dstport\"   from read_pcap('~/wireduck/fix.pcap', protocols:=['ip','tcp'],climit:=100)  group by  \"tcp.srcport\" ,\"tcp.dstport\" ;;\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 count_star() \u2502 sum(\"tcp.len\") \u2502 tcp.srcport \u2502 tcp.dstport \u2502\n\u2502    int64     \u2502     int128     \u2502    int64    \u2502    int64    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502          429 \u2502         259678 \u2502       11001 \u2502       53867 \u2502\n\u2502           56 \u2502          19702 \u2502       53867 \u2502       11001 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n",
        "extended_description": "### pcap dissector extention\nWireduck runs tshark behind the scenes utilizing wireshark's glossary to be able to parse any packet from any supported protocol to its fields. \nenabeling network data analysis and analytics.\n\n### Features\n- read_pcap table function.\n- support any protocol supported by wireshark.\n- allow push down filters to wireshark using cfilter climit  parameters\n\n### Prerequities\ntshark (installed as part of wireshark) should be installed.\nvalidate its exists via\n```\ntshark --version\n```\n> For examples and instructions check out [Readme](https://github.com/hyehudai/wireduck)\n\n    \n> Note: Wireduck is still experimental.\n"
      }
    },
    "official_description": "Read and dissect PCAP files from DuckDB",
    "official_version": "0.0.2",
    "language": "c++",
    "maintainers": [
      "hyehudai"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/wireduck/description.yml",
    "deprecation_score": 4.0,
    "recommendation": "REVIEW - Some deprecation indicators found"
  },
  {
    "extension": "yaml",
    "repository": "https://github.com/teaguesterling/duckdb_yaml",
    "owner": "teaguesterling",
    "repo_name": "duckdb_yaml",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "-- Type detection example"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "# Multi-document example"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "# Sequence example"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "# To run tests"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "make test"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "## Testing"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-11T19:55:25Z",
    "description": " A DuckDB to read and work with YAML files in a similar way to JSON files (also an exploration of AI-guided development) Resources",
    "readme_content": "[![DuckDB Community Extension](https://img.shields.io/badge/yaml-DuckDB_Community_Extension-blue?logo=duckdb)](https://duckdb.org/community_extensions/extensions/yaml.html)\n\n# YAML Extension for DuckDB\n\nThis extension allows DuckDB to read YAML files directly into tables and provides full YAML type support with conversion functions. It enables seamless integration of YAML data within SQL queries.\n\n## Installation\n\n### From Community Extensions\n\n```sql\nINSTALL yaml FROM community;\nLOAD yaml;\n```\n\n### From GitHub Release\n\n```sql\n-- Install directly from GitHub releases\nINSTALL yaml FROM 'https://github.com/teaguesterling/duckdb_yaml/releases/download/v0.1.0/yaml.duckdb_extension';\nLOAD yaml;\n```\n\n### From Source\n\n```bash\ngit clone https://github.com/teaguesterling/duckdb_yaml\ncd duckdb_yaml\nmake\n\n# To run tests\nmake test\n```\n\n## AI-written Extension\nClaude.ai wrote 99% of the code in this project as an experiment. The original working version was written over the course of a weekend and ",
    "analysis_timestamp": "2025-09-27T14:44:11.923700",
    "metadata": {
      "extension": {
        "name": "yaml",
        "description": "Read YAML files into DuckDB with native YAML type support, comprehensive extraction functions, and seamless JSON interoperability",
        "version": "1.0.3",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "teaguesterling"
        ]
      },
      "repo": {
        "github": "teaguesterling/duckdb_yaml",
        "ref": "main"
      },
      "docs": {
        "hello_world": "-- Load the extension\nLOAD yaml;\n\n-- Query YAML files directly\nSELECT * FROM 'config.yaml';\nSELECT * FROM 'data/*.yml' WHERE active = true;\n\n-- Create tables with YAML columns\nCREATE TABLE configs(id INTEGER, config YAML);\nINSERT INTO configs VALUES (1, E'server: production\\nport: 8080\\nfeatures: [logging, metrics]');\n\n-- Extract data using YAML functions\nSELECT \n    yaml_extract_string(config, '$.server') AS environment,\n    yaml_extract(config, '$.port') AS port,\n    yaml_extract(config, '$.features[0]') AS first_feature\nFROM configs;\n\n-- Convert between YAML and JSON\nSELECT yaml_to_json(config) AS json_config FROM configs;\nSELECT value_to_yaml({name: 'John', age: 30}) AS yaml_person;\n\n-- Write query results to YAML\nCOPY (SELECT * FROM users) TO 'output.yaml' (FORMAT yaml, STYLE block);\n",
        "extended_description": "The YAML extension brings comprehensive YAML support to DuckDB, enabling seamless integration of YAML data within SQL queries. \n\n**Key Features:**\n\n- **Native YAML Type**: Full YAML type support with automatic casting between YAML, JSON, and VARCHAR\n- **File Reading**: Read YAML files with `read_yaml()` and `read_yaml_objects()` functions supporting multi-document files, top-level sequences, and robust error handling\n- **Direct File Querying**: Query YAML files directly using `FROM 'file.yaml'` syntax\n- **Extraction Functions**: Query YAML data with `yaml_extract()`, `yaml_type()`, `yaml_exists()`, and path-based extraction\n- **Type Detection**: Comprehensive automatic type detection for temporal types (DATE, TIME, TIMESTAMP), optimal numeric types, and boolean values\n- **Column Type Specification**: Explicitly define column types when reading YAML files for schema consistency\n- **YAML Output**: Write query results to YAML files using `COPY TO` with configurable formatting styles\n- **Multi-Document Support**: Handle files with multiple YAML documents separated by `---`\n- **Error Recovery**: Continue processing valid documents even when some contain errors\n- **JSON Interoperability**: Seamless conversion between YAML and JSON formats\n\n**Example Use Cases:**\n\n- Configuration file management and querying\n- Log file analysis and processing  \n- Data migration between YAML and relational formats\n- Integration with YAML-based CI/CD pipelines\n- Processing Kubernetes manifests and Helm charts\n\nThe extension is built using yaml-cpp and follows DuckDB's extension development best practices, ensuring reliable performance and cross-platform compatibility.\n\n**Note**: This extension was written primarily using Claude and Claude Code as an exercise in AI-driven development.\n"
      }
    },
    "official_description": "Read YAML files into DuckDB with native YAML type support, comprehensive extraction functions, and seamless JSON interoperability",
    "official_version": "1.0.3",
    "language": "C++",
    "maintainers": [
      "teaguesterling"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/yaml/description.yml",
    "deprecation_score": 6.0,
    "recommendation": "POSSIBLY DEPRECATED - Manual review recommended"
  },
  {
    "extension": "zipfs",
    "repository": "https://github.com/isaacbrodsky/duckdb-zipfs",
    "owner": "isaacbrodsky",
    "repo_name": "duckdb-zipfs",
    "status": "analyzed",
    "deprecation_indicators": [],
    "warning_indicators": [
      {
        "keyword": "example",
        "source": "readme",
        "context": "SELECT * FROM 'zip://examples/a.zip/a.csv';"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "torageaccount.blob.core.windows.net/yourcontainer/examples/a.zip/a.csv';"
      },
      {
        "keyword": "example",
        "source": "readme",
        "context": "SELECT * FROM 'zip://examples/a.zip/*.csv';"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "[![Extension Test](https://github.com/isaacbrodsky/duckdb-zipfs/act"
      },
      {
        "keyword": "test",
        "source": "readme",
        "context": "make test_release"
      }
    ],
    "active_indicators": [],
    "repository_archived": false,
    "last_push": "2025-09-27T01:00:01Z",
    "description": "DuckDB extension to read files within zip archives.",
    "readme_content": "[![Extension Test](https://github.com/isaacbrodsky/duckdb-zipfs/actions/workflows/MainDistributionPipeline.yml/badge.svg)](https://github.com/isaacbrodsky/duckdb-zipfs/actions/workflows/MainDistributionPipeline.yml)\n[![DuckDB Version](https://img.shields.io/static/v1?label=duckdb&message=v1.4.0&color=blue)](https://github.com/duckdb/duckdb/releases/tag/v1.4.0)\n[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)\n\nThis is a [DuckDB](https://duckdb.org) extension that adds support for reading files from within [zip archives](https://en.wikipedia.org/wiki/ZIP_(file_format)).\n\n# Get started\n\nLoad from the [community extensions repository](https://community-extensions.duckdb.org/extensions/zipfs.html):\n```SQL\nINSTALL zipfs FROM community;\nLOAD zipfs;\n```\n\nTo read a file:\n```SQL\nSELECT * FROM 'zip://examples/a.zip/a.csv';\n```\n\nTo read a file from azure blob storage (or other file system):\n```SQL\nSELECT * FROM 'zip://az://yourstorageaccount.blob.core.windows.net/yourcontai",
    "analysis_timestamp": "2025-09-27T14:44:12.032863",
    "metadata": {
      "extension": {
        "name": "zipfs",
        "description": "Read files within zip archives",
        "version": "1.4.0",
        "language": "C++",
        "build": "cmake",
        "license": "MIT",
        "maintainers": [
          "isaacbrodsky"
        ]
      },
      "repo": {
        "github": "isaacbrodsky/duckdb-zipfs",
        "ref": "189d9ab4696bb340867f278dcadf1e35810365b3"
      },
      "docs": {
        "hello_world": "SELECT * FROM 'zip://my_zip.zip/my_file.csv';\n",
        "extended_description": "The zipfs extension adds support for reading files from within zip archives.\n"
      }
    },
    "official_description": "Read files within zip archives",
    "official_version": "1.4.0",
    "language": "C++",
    "maintainers": [
      "isaacbrodsky"
    ],
    "license": "MIT",
    "description_yml_url": "https://github.com/duckdb/community-extensions/blob/main/extensions/zipfs/description.yml",
    "deprecation_score": 5.0,
    "recommendation": "POSSIBLY DEPRECATED - Manual review recommended"
  }
]